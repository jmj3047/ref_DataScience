{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Part4_9_Transformer_Seq2Seq_tensorflow.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO68Vc5W0P8oJcgaQm+rw1r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Tensorflow\n","- `Tensorflow`가 예전에는 쓰기 어려운 모델이었음 (코딩할 줄 아는 사람들만 사용)\n","- 그래서 `pytorch`가 많이 쓰이다 보니, `Tensorflow`에서도 쉽게 사용할 수 있는 `Keras` 만듦\n","- `Tensorflow 2.0`에서는 `keras`와 합쳐진 `tf.keras.Model`이나 `Sequential` 많이 사용\n","- `Tensorflow`에서 train step, test step을 사용하는 class 구조는 `pytorch lightening`과 비슷\n","  - `pytorch lightening` : `pytorch`를 더 쉽게 사용하기 위한 library\n","- Optimizer : Tensorflow addon\n","  - https://www.tensorflow.org/addons/overview?hl=ko\n","  - https://github.com/tensorflow/addons\n","    - 여러 tensorflow 개발자들이 다양한 optimizer 구현 코드 업로드"],"metadata":{"id":"8gmIaEsDowHC"}},{"cell_type":"markdown","source":["## Hydra\n","- Facebook에서 제공하는 범용적인 configuration management tool\n","- 'hydra config' 검색 : https://hydra.cc/docs/intro/\n","- Omegaconf library를 기반으로 만들어짐\n","  - Documentation : https://omegaconf.readthedocs.io/en/2.1_branch/\n","  - https://github.com/omry/omegaconf : 이 개발자가 facebook에 가서 만든 게 hydra\n","  - MLP 같은 작은 모델은 `__init__(self, input_dim: int, h1_dim: int, h2_dim: int, out_dim: int)` 이런 식으로 써도 되지만, 모델이 커질수록 `init` 안에 들어가야 할 *argument 많아지고 관리가 어려워짐\n","    - 그래서 configuration tool을 이용해서 관리하는 것이 권장\n","    - tensorflow에 hyperparameter도 같은 역할이고 이건 tensorflow와 연동이 되는 장점이 있지만 wandB 등 다른 tool과 연동이 잘 안 되는 단점\n","    - omegaconf가 structure 관리에도 유리\n","\n","## Efficient Network\n","- https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet\n","\n","## Tensorflow Text Generation\n","- https://www.tensorflow.org/text/tutorials/nmt_with_attention"],"metadata":{"id":"Tg5_VZBezJlZ"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"bfadOzkbuIB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","sys.path.append('/content/drive/MyDrive/#fastcampus')\n","drive_project_root = '/content/drive/MyDrive/#fastcampus'\n","!pip install -r '/content/drive/MyDrive/#fastcampus/requirements.txt'"],"metadata":{"id":"4AAPJkUPpFvb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip install tensorflow_addons"],"metadata":{"id":"WNUrJmSfA8Ll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip install wandb"],"metadata":{"id":"wVE8r_8EBA9l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip install omegaconf"],"metadata":{"id":"tp5T9_vf0XfV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Optional, List, Dict, Tuple\n","\n","import io\n","import re\n","import unicodedata\n","import time\n","from datetime import datetime\n","import random\n","\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import matplotlib.pyplot as ticker\n","from omegaconf import OmegaConf, DictConfig    # DictConfig is for time checking\n","\n","import hydra\n","from hydra.core.config_store import ConfigStore\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","import wandb"],"metadata":{"id":"wmIGtqQXpfJr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from config_utils_tf import flatten_dict, register_config, get_optimizer_element, get_callbacks"],"metadata":{"id":"T8mcCpw73M-i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["GPU 확인"],"metadata":{"id":"G8_oGfQKp2cT"}},{"cell_type":"code","source":["tf.config.list_physical_devices()"],"metadata":{"id":"NMr3t8-QpzX0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"L76O6F6_p3Ud"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["https://www.tensorflow.org/</br>\n","- https://www.tensorflow.org/overview/?hl=ko</br>\n","- 튜토리얼 : https://www.tensorflow.org/tutorials?hl=ko\n","- API > Tensorflow : 각 함수에 대한 설명\n","  - 구글에 'Tensorflow API 한글' 검색하면 번역본도 볼 수 있음\n","\n","초보자용 vs 전문가용\n","- 수업에서는 전문가용으로 할 예정\n","- 초보자용에서 사용하는 Sequential 버전(순차적으로 build 하는 방법)에는 한계가 있기 때문\n","- 실제 현업/연구에서는 Sequential 거의 안 씀"],"metadata":{"id":"eV6g35xTqKhF"}},{"cell_type":"markdown","source":["## define gpu\n","- https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy\n","- This strategy is typically used for training on one machine with multiple GPUs.\n","- 아래 코드 결과 보면 GPU 0번 잡아서 가져옴"],"metadata":{"id":"2lfmx_jAp5ac"}},{"cell_type":"code","source":["# mirrored_strategy = tf.distribute.MirroredStrategy()"],"metadata":{"id":"N0sq47Enq1fU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data download\n","\n","- code is from : https://www.tensorflow.org/text/tutorials/nmt_with_attention"],"metadata":{"id":"L7L9eTkdq1qI"}},{"cell_type":"code","source":["data_root = os.path.join(drive_project_root, \"data\", \"anki_spa_eng\")\n","# data_root = os.path.join(\"/drive/MyDrive/#fastcampus\", \"data\", \"anki_spa_eng\")\n","\n","if not os.path.exists(data_root):\n","    # os.mkdir(data_root)\n","    os.makedirs(data_root)\n","    \n","data_path = os.path.join(data_root, \"spa-eng.zip\")"],"metadata":{"id":"18ofA9fMDswE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_to_zip = tf.keras.utils.get_file(\n","    data_path,\n","    # 데이터 다운로드 받아진 거 보면 왼쪽은 영어 오른쪽은 스페인어\n","    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n","    extract=True,\n","    cache_dir = data_root  # Once you download the data, this would block to download the same data again\n",")\n","\n","path_to_file = os.path.join(\n","    os.path.dirname(path_to_zip),\n","    \"datasets\",\n","    \"spa-eng\",\n","    \"spa.txt\",\n",")\n","\n","print(path_to_file)"],"metadata":{"id":"oMYUxMWGnTi_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preprocessing\n","- Optional(int) : input integer or None"],"metadata":{"id":"7KskxT7Doo4z"}},{"cell_type":"code","source":["def unicode_to_ascii(s):\n","    # unicode normalize with NFD mode -> return list -> join : convert list to string\n","    # mn : https://www.compart.com/en/unicode/category/Mn\n","    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")\n","\n","def preprocess_sentence(w):\n","    # convert it to ascii \n","    w = unicode_to_ascii(w.lower().strip())\n","\n","    # make space between words and punctuation\n","    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","    w = re.sub(r'[\" \"]+', \" \", w)\n","    \n","    # replace every thing to space without \"a-z, A-Z, [.?!,¿]\"\n","    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n","    w = w.strip()\n","\n","    # add \"start\" and \"end\" token at the front and back of the model\n","    w = \"<start> \" + w + \" <end>\"  # warning! SPACE!!\n","    return w\n","\n","def create_dataset(path: str, num_examples: Optional[int]=None):\n","    lines = io.open(path, encoding=\"UTF-8\").read().strip().split(\"\\n\")\n","\n","    # 데이터에 tab(\\t)으로 나뉘어 영어-스페인어가 pair식으로 있었음\n","    word_pairs = [[preprocess_sentence(w) for w in l.split(\"\\t\")] for l in lines[:num_examples]]\n","\n","    return zip(*word_pairs)\n","\n","en, sp = create_dataset(path_to_file)\n","print(en[-1])\n","print(sp[-1])"],"metadata":{"id":"9SdXQsAror63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define Tokenizer & Final use data\n","\n","def tokenize(lang):\n","    lang_tokenizer = Tokenizer(filters=\"\")\n","    lang_tokenizer.fit_on_texts(lang)\n","\n","    # we cannot put string into model (neither pytorch nor tensorflow)\n","    # we should convert it to int or float type\n","    tensor = lang_tokenizer.texts_to_sequences(lang)\n","    tensor = pad_sequences(tensor, padding=\"post\")\n","\n","    return tensor, lang_tokenizer\n","\n","def load_dataset(path, num_examples=None):\n","    tar_lang, src_lang = create_dataset(path, num_examples)  # en, sp\n","\n","    src_tensor, src_tokenizer = tokenize(src_lang)\n","    tar_tensor, tar_tokenizer = tokenize(tar_lang)\n","\n","    return src_tensor, tar_tensor, src_tokenizer, tar_tokenizer\n","\n","# call language dataset\n","# num_examples = 30000 # RNN\n","num_examples = 100000  # Transformer는 학습데이터가 많아야 성능이 좋음\n","src_tensor, tar_tensor, src_tokenizer, tar_tokenizer = load_dataset(\n","    path_to_file, num_examples\n",")\n","\n","max_tar_len, max_src_len = tar_tensor.shape[1], src_tensor.shape[1]\n","\n","src_vocab_size = len(src_tokenizer.word_index) + 1\n","tar_vocab_size = len(tar_tokenizer.word_index) + 1\n","\n","print(src_vocab_size, tar_vocab_size)"],"metadata":{"id":"mLMPEBAH5bK0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["check\n","- 1 : start\n","- 2 : end\n","- 0 : padding"],"metadata":{"id":"0cYKkYt6_AHn"}},{"cell_type":"code","source":["print(tar_tensor[-1])\n","print(tar_tokenizer.word_index)"],"metadata":{"id":"ayJCT8gi-vQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in tar_tensor[-1]:\n","    if i == 0:\n","        break\n","    print(tar_tokenizer.index_word[i])"],"metadata":{"id":"o9XxfFUp_FuJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Model"],"metadata":{"id":"b7K30vaZ_zRY"}},{"cell_type":"code","source":["class GRUEncoder(tf.keras.Model):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.enc_emb = tf.keras.layers.Embedding(\n","            cfg.data.src.vocab_size,\n","            cfg.model.enc.embed_size\n","        )\n","        self.enc_gru = tf.keras.layers.GRU(\n","            cfg.model.enc.rnn.units,\n","            return_state=True,\n","            return_sequences=True,\n","            recurrent_initializer=\"glorot_uniform\"\n","        )\n","    \n","    # state : RNN's state\n","    def call(self, src_tokens, state=None, training=False):\n","        embed_enc = self.enc_emb(src_tokens)\n","        enc_outputs, enc_states = self.enc_gru(\n","            embed_enc, initial_state=state\n","        )\n","        return enc_outputs, enc_states\n","\n","class GRUDecoder(tf.keras.Model):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.dec_emb = tf.keras.layers.Embedding(\n","            cfg.data.tar.vocab_size,\n","            cfg.model.dec.embed_size\n","        )\n","        self.dec_gru = tf.keras.layers.GRU(\n","            cfg.model.dec.rnn.units,\n","            return_state=True,\n","            return_sequences=True,\n","            recurrent_initializer=\"glorot_uniform\"\n","        )\n","        self.fc = tf.keras.layers.Dense(cfg.data.tar.vocab_size)\n","    \n","    # state : RNN's state\n","    def call(self, tar_tokens, state=None, training=False):\n","        embed_dec = self.dec_emb(tar_tokens)\n","        dec_outputs, dec_states = self.dec_gru(\n","            embed_dec, initial_state=state\n","        )\n","        final_outputs = self.fc(dec_outputs)\n","        return final_outputs, dec_states, None   # None은 추후 attention 등 추가 시 interface 통일 위함"],"metadata":{"id":"iwqYLh1s_2Eg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Attention 모델 정의"],"metadata":{"id":"YXqMlasHb208"}},{"cell_type":"code","source":["# attention은 decoder에 붙이는 것이기 때문에 layer로 정의\n","class BahdanauAttention(tf.keras.layers.Layer):\n","    def __init__(self, cfg:DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        # needs 3 different fully connected layers\n","        self.fc1 = tf.keras.layers.Dense(cfg.model.attention.latent_dim)   # fully connected for key\n","        self.fc2 = tf.keras.layers.Dense(cfg.model.attention.latent_dim)   # fully connected for query\n","        self.fc_score = tf.keras.layers.Dense(1)      # fully connected for weighted score\n","\n","    def call(self, query, value):\n","\n","        # querry = decoder hidden, value = encoder output\n","        # querry : hidden이기 때문에 차원을 맞춰주기 위해 expand dims 사용\n","        query_with_time_axis = tf.expand_dims(query, 1)   # [batch, 1(length), hidden_dim] -> 보통 decoder에서 length는 1\n","\n","        score = self.fc_score(\n","            tf.nn.tanh(\n","                self.fc1(query_with_time_axis) + self.fc2(value)  # score\n","            )\n","        )  # [batch, length, hidden_dim] -> [batch, length, 1]\n","\n","        attention_weights = tf.nn.softmax(score, axis=1)  # [batch_size, length, 1]\n","\n","        context_vector = attention_weights * value  # [batch_size, hidden]\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","        return context_vector, attention_weights\n","\n","class AttentionalGRUDecoder(tf.keras.Model):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.dec_emb = tf.keras.layers.Embedding(\n","            cfg.data.tar.vocab_size,\n","            cfg.model.dec.embed_size\n","        )\n","        self.dec_gru = tf.keras.layers.GRU(\n","            cfg.model.dec.rnn.units,\n","            return_state=True,\n","            return_sequences=True,\n","            recurrent_initializer=\"glorot_uniform\"\n","        )\n","        self.attention = BahdanauAttention(cfg)\n","        self.fc = tf.keras.layers.Dense(cfg.data.tar.vocab_size)\n","\n","    def call(self, tar_tokens, hidden, enc_output):\n","        # enc_output: [batch, length, hidden_dim]\n","        context_vector, attention_weights = self.attention(hidden, enc_output)\n","        \n","        x = self.dec_emb(tar_tokens)\n","\n","        # embedding된 target token과 context vecotr를 concat으로 합치기\n","        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","        # 이 때는 이미 결합이 되었었기 때문에 attention에서 반영되었다고 보고 굳이 state 넣지 않음\n","        dec_outputs, dec_states = self.dec_gru(x)\n","\n","        # [batch_size * 1, embedding_dim + hidden_dim]\n","        dec_outputs = tf.reshape(dec_outputs, (-1, dec_outputs.shape[2]))\n","\n","        # [batch_size, vocab_size]\n","        final_outputs = self.fc(dec_outputs)\n","\n","        return final_outputs, dec_states, attention_weights"],"metadata":{"id":"Ez1VW9R_cBVD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Transformer\n","- 3개의 Layer 정의\n","  - Positional Embedding\n","  - Transformer Encoder\n","  - Transformer Decoder (encoder와 decoder를 잇는 attention도 존재!)"],"metadata":{"id":"n7qkSwY1TzOQ"}},{"cell_type":"code","source":["# 1. Positional Embedding\n","class PositionalEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, sequence_size, vocab_size, embed_dim):\n","        super().__init__()\n","        self.sequence_size = sequence_size\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","\n","        self.token_embedding = tf.keras.layers.Embedding(\n","            input_dim = self.vocab_size,\n","            output_dim = self.embed_dim\n","        )\n","        self.position_embedding = tf.keras.layers.Embedding(\n","            input_dim = self.sequence_size,\n","            output_dim = self.embed_dim\n","        )\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embedding(inputs)\n","        embedded_positions = self.position_embedding(positions)\n","        return embedded_tokens + embedded_positions\n","    \n","    def compute_mask(self, inputs, mask=None):\n","        # pad masking\n","        return tf.math.not_equal(inputs, 0)\n","\n","# 2. Transformer Encoder\n","class TransformerEncoder(tf.keras.layers.Layer):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.embed_dim = cfg.model.enc.embed_dim  # for positional encoding\n","\n","        # transformer\n","        self.dense_dim = cfg.model.enc.tr.dense_dim\n","        self.num_heads = cfg.model.enc.tr.num_heads\n","        self.supports_masking = cfg.model.enc.tr.supports_masking\n","\n","        self.attention = tf.keras.layers.MultiHeadAttention(\n","            num_heads=self.num_heads, key_dim=self.embed_dim\n","            )\n","        \n","        self.dense_proj = tf.keras.Sequential([\n","            tf.keras.layers.Dense(self.dense_dim, activation=\"relu\"),\n","            tf.keras.layers.Dense(self.embed_dim)\n","        ])\n","\n","        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n","        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n","\n","        self.positional_embedding = PositionalEmbedding(\n","            cfg.data.src.max_len,\n","            cfg.data.src.vocab_size,\n","            cfg.model.enc.embed_dim\n","        )\n","\n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update({\n","            \"cfg\": self.cfg,\n","            \"attention\": self.attention,\n","            \"dense_proj\": self.dense_proj,\n","            \"layernorm_1\": self.layernorm_1,\n","            \"layernorm_2\": self.layernorm_2,\n","            \"positional_embedding\": self.positional_embedding,\n","        })\n","        return config\n","\n","    def call(self, inputs, padding_mask=None, training=False):\n","        inputs = self.positional_embedding(inputs)\n","        if padding_mask is not None:\n","            padding_mask = tf.cast(\n","                padding_mask[:, tf.newaxis, tf.newaxis, :],\n","                dtype=\"int32\"\n","            )\n","        attention_output = self.attention(\n","            query=inputs,  # positional embedding 된 input\n","            value=inputs,\n","            key=inputs,\n","            attention_mask=padding_mask,\n","            training=training\n","        )\n","        proj_input = self.layernorm_1(inputs + attention_output)  # skip connect + norm\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)  # skip connect + norm\n","\n","# 3. Transformer Decoder (encoder와 decoder를 잇는 attention도 존재!)\n","class TransformerDecoder(tf.keras.layers.Layer):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.embed_dim = cfg.model.dec.embed_dim  # for positional encoding\n","\n","        # transformer\n","        self.latent_dim = cfg.model.dec.tr.latent_dim\n","        self.num_heads = cfg.model.dec.tr.num_heads\n","        self.supports_masking = cfg.model.dec.tr.supports_masking\n","\n","        self.attention_1 = tf.keras.layers.MultiHeadAttention(\n","            num_heads=self.num_heads, key_dim=self.embed_dim\n","            )\n","        \n","        self.attention_2 = tf.keras.layers.MultiHeadAttention(\n","            num_heads=self.num_heads, key_dim=self.embed_dim\n","            )\n","        \n","        self.dense_proj = tf.keras.Sequential([\n","            tf.keras.layers.Dense(self.latent_dim, activation=\"relu\"),\n","            tf.keras.layers.Dense(self.embed_dim)\n","        ])\n","\n","        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n","        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n","        self.layernorm_3 = tf.keras.layers.LayerNormalization()  # attention이 하나 더 붙기 때문에 encoder보다 하나 더 필요\n","\n","        self.positional_embedding = PositionalEmbedding(\n","            cfg.data.src.max_len,\n","            cfg.data.src.vocab_size,\n","            cfg.model.dec.embed_dim\n","        )\n","\n","        self.dropout = tf.keras.layers.Dropout(cfg.model.dropout_prob)\n","        self.out_dense = tf.keras.layers.Dense(cfg.data.tar.vocab_size)\n","\n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update({\n","            \"cfg\": self.cfg,\n","            \"attention_1\": self.attention_1,\n","            \"attention_2\": self.attention_2,\n","            \"dense_proj\": self.dense_proj,\n","            \"layernorm_1\": self.layernorm_1,\n","            \"layernorm_2\": self.layernorm_2,\n","            \"layernorm_3\": self.layernorm_3,\n","            \"positional_embedding\": self.positional_embedding,\n","            \"dropout\": self.dropout,\n","            \"out_dense\": self.out_dense,\n","        })\n","        return config\n","    \n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = tf.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = tf.range(sequence_length)[:, tf.newaxis]\n","        j = tf.range(sequence_length)\n","        mask = tf.cast(i >= j, dtype=\"int32\")\n","        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        mult = tf.concat(\n","            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n","            axis=0,\n","        )\n","        return tf.tile(mask, mult)\n","\n","    def call(self, inputs, encoder_outputs, padding_mask=None, training=False):\n","        inputs = self.positional_embedding(inputs)\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","\n","        if padding_mask is not None:\n","            padding_mask = tf.cast(\n","                padding_mask[:, tf.newaxis, tf.newaxis, :],\n","                dtype=\"int32\"\n","            )\n","            padding_mask = tf.minimum(padding_mask, causal_mask)\n","\n","        # masked dec self-attention\n","        attention_output_1 = self.attention_1(\n","            query=inputs,  # positional embedding 된 input\n","            value=inputs,\n","            key=inputs,\n","            attention_mask=causal_mask,\n","            training=training\n","        )\n","\n","        out_1 = self.layernorm_1(inputs + attention_output_1)  # skip connect + norm\n","\n","        # migrate with encoder\n","        attention_output_2 = self.attention_2(\n","            query=out_1,           # query: decoder 부분\n","            value=encoder_outputs, # value : encoder 부분\n","            key=encoder_outputs,   # key : encoder 부분\n","            attention_mask=padding_mask,\n","            training=training\n","        )\n","\n","        out_2 = self.layernorm_2(out_1 + attention_output_2)  # skip connect + norm\n","\n","        proj_output = self.dense_proj(out_2)\n","\n","        out_3 = self.layernorm_3(out_2 + proj_output)  # skip connect + norm\n","        out_3 = self.dropout(out_3, training=training)\n","\n","        return self.out_dense(out_3)  # vocab size로 바꾸기"],"metadata":{"id":"4ktkwPsBT160"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Configuration 정의"],"metadata":{"id":"uDuzP0sY4b0_"}},{"cell_type":"markdown","source":["### data configuration"],"metadata":{"id":"8r1ww_KV6p-r"}},{"cell_type":"code","source":["data_anki_spa_eng_cfg ={\n","    \"name\": \"anki_spa_eng_cfg\",\n","    \"src\":{\n","        \"vocab_size\": src_vocab_size,\n","        \"max_len\": max_src_len,\n","    },\n","    \"tar\":{\n","        \"vocab_size\": tar_vocab_size,\n","        \"max_len\": max_tar_len,\n","    },\n","    \"train_val_test_split_ratio\": [0.8, 0.1, 0.1],\n","    \"train_val_shuffle\": True,\n","}"],"metadata":{"id":"NGVZjvXZ6qAO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### model configuration"],"metadata":{"id":"LId0Hw-W6qJr"}},{"cell_type":"code","source":["model_translate_rnn_seq2seq_cfg = {\n","    \"name\": \"RNNSeq2Seq\",\n","    \"enc\": {\n","        \"embed_size\": 256,\n","        \"rnn\": {\n","            \"units\": 1024,\n","        }\n","    },\n","    \"dec\": {\n","        \"embed_size\": 256,\n","        \"rnn\": {\n","            \"units\": 1024,\n","        }\n","    }\n","}\n","\n","model_translate_attention_based_seq2seq_cfg = {\n","    \"name\": \"AttentionBasedSeq2Seq\",\n","    \"enc\": {\n","        \"embed_size\": 256,\n","        \"rnn\": {\n","            \"units\": 1024,\n","        }\n","    },\n","    \"dec\": {\n","        \"embed_size\": 256,\n","        \"rnn\": {\n","            \"units\": 1024,\n","        }\n","    },\n","    \"attention\": {\n","        \"latent_dim\" : 1024,\n","    }\n","}\n","\n","model_translate_transformer_based_seq2seq_cfg = {\n","    \"name\": \"TransformerBasedSeq2Seq\",\n","    \"dropout_prob\": 0.5,\n","    \"enc\": {\n","        \"embed_dim\": 256,\n","        \"tr\": {\n","            \"dense_dim\": 2048,\n","            \"num_heads\": 8,\n","            \"supports_masking\": True,\n","        }\n","    },\n","    \"dec\": {\n","        \"embed_dim\": 256,\n","        \"tr\": {\n","            \"latent_dim\": 2048,\n","            \"num_heads\": 8,\n","            \"supports_masking\": True,\n","        }\n","    },\n","}"],"metadata":{"id":"nALBOsFe3voa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### optimizer configuration"],"metadata":{"id":"DW0a1cVelHKl"}},{"cell_type":"code","source":["adam_warmup_lr_sch_opt_cfg = {\n","    \"optimizer\": {\n","        \"name\": \"Adam\",\n","        \"other_kwargs\": {},\n","    },\n","    \"lr_scheduler\": {\n","        \"name\": \"LinearWarmupLRSchedule\",\n","        \"kwargs\": {\n","            \"lr_peak\": 1e-3,\n","            \"warmup_end_steps\": 1500,\n","        }\n","    }\n","}\n","\n","# RAdam은 scheduler 필요 없었음\n","radam_no_lr_sch_opt_cfg = {\n","    \"optimizer\": {\n","        \"name\": \"RectifiedAdam\",\n","        \"learning_rate\": 1e-3,\n","        \"other_kwargs\": {},\n","    },\n","    \"lr_scheduler\": None\n","}\n","\n","# train_cfg\n","train_cfg: dict = {\n","    \"train_batch_size\": 128,\n","    \"val_batch_size\": 32,\n","    \"test_batch_size\": 32,\n","    \"max_epochs\": 50,\n","    \"distribute_strategy\": \"MirroredStrategy\",   # colab(notebook)이 아니고 다른 server에서 하면 다른 strategy 필요\n","    # teacher_forcing : 처음에 적용했다가 없애주는 게 가장 좋은 방법이라고 알려져 있음\n","    \"teacher_forcing_ratio\": 0.5,\n","}\n","\n","_merged_cfg_presets = {\n","    \"rnn_translate_spa_eng_radam\": {\n","        \"data\": data_anki_spa_eng_cfg,\n","        \"model\": model_translate_rnn_seq2seq_cfg,\n","        \"opt\": radam_no_lr_sch_opt_cfg,\n","        \"train\": train_cfg,\n","    },\n","    \"attention_based_translate_spa_eng_radam\": {\n","        \"data\": data_anki_spa_eng_cfg,\n","        \"model\": model_translate_attention_based_seq2seq_cfg,\n","        \"opt\": radam_no_lr_sch_opt_cfg,\n","        \"train\": train_cfg,      \n","    },\n","    \"transformer_based_translate_spa_eng_radam\": {\n","        \"data\": data_anki_spa_eng_cfg,\n","        \"model\": model_translate_transformer_based_seq2seq_cfg,\n","        \"opt\": radam_no_lr_sch_opt_cfg,\n","        \"train\": train_cfg,      \n","    }\n","}\n","\n","### hydra composition ###\n","# clear hydra instance -> Jupyter 환경에서 할 때는 일단 instance clear 하기\n","hydra.core.global_hydra.GlobalHydra.instance().clear()\n","\n","# register preset configs\n","register_config(_merged_cfg_presets)\n","\n","# initialization\n","hydra.initialize(config_path=None)    # yaml을 쓰고 있고 외부에서 하면 config_path 지정해야 함\n","\n","# using_config_key = \"cnn_fashion_mnist_radam\"\n","# using_config_key = \"attention_based_translate_spa_eng_radam\"\n","using_config_key = \"transformer_based_translate_spa_eng_radam\"\n","cfg = hydra.compose(using_config_key)\n","\n","# define & override log _cfg\n","model_name = cfg.model.name\n","run_dirname = \"dnn-tutorial-spa_eng-translate-runs-tf\"\n","run_name = f\"{datetime.now().isoformat(timespec='seconds')}-{using_config_key}-{model_name}\"\n","log_dir = os.path.join(drive_project_root, \"runs\", run_dirname, run_name)\n","\n","log_cfg = {\n","    \"run_name\": run_name,\n","    # callback을 못 쓰니 filepath 등 지정 필요\n","    \"checkpoint_filepath\": os.path.join(log_dir, \"model\"),\n","    \"tensorboard_log_dir\": log_dir,\n","    \"callbacks\": {\n","        \"TensorBoard\": {\n","            \"log_dir\": log_dir,\n","            \"update_freq\": 50,\n","        },\n","        \"EarlyStopping\": {\n","            \"patience\": 30,\n","            \"verbose\": True,\n","        }\n","    },\n","    \"wandb\": {\n","        \"project\": \"dnn-tutorial-spa_eng-translate-runs-tf\",\n","        \"name\": run_name,\n","        \"tags\": [\"dnn-tutorial-spa_eng-translate-runs-tf\"],\n","        \"reinit\": True,\n","        \"sync_tensorboard\": True,\n","    },\n","}\n","\n","# unlock struct of config & set log config\n","OmegaConf.set_struct(cfg, False)\n","cfg.log = log_cfg\n","\n","# relock config\n","OmegaConf.set_struct(cfg, True)\n","print(OmegaConf.to_yaml(cfg))\n","\n","# save yaml\n","# with open(os.path.join(log_dir, \"config.yaml\")) as f:\n","# with open(\"config.yaml\", \"w\") as f:\n","#     OmegaConf.save(cfg, f)\n","\n","# This would open the file we saved above\n","# and tell you the result of the model and its configs (weights, ...)\n","# You can check it whenever you want\n","# OmegaConf.load()"],"metadata":{"id":"StvxdanulHNa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_distribute_strategy(strategy_name: str, **kwargs):\n","    return getattr(tf.distribute, strategy_name)(**kwargs)\n","\n","distribute_strategy = get_distribute_strategy(cfg.train.distribute_strategy)"],"metadata":{"id":"hlbgAzj0lHQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dataset batchfy 및 train/val/test splits\n","# from_tensor_slices : numpy array 형태와 비슷\n","dataset = tf.data.Dataset.from_tensor_slices((src_tensor, tar_tensor))\n","total_n = len(src_tensor)\n","\n","print(cfg.data.train_val_test_split_ratio)\n","train_size = int(total_n * cfg.data.train_val_test_split_ratio[0])\n","val_size = int(total_n * cfg.data.train_val_test_split_ratio[1])\n","test_size = total_n - (train_size + val_size)\n","\n","# split (train, val), (test) dataset\n","test_dataset = dataset.skip(train_size + val_size)\n","train_val_dataset = dataset.take(train_size + val_size)\n","\n","if cfg.data.train_val_shuffle:  # True\n","    train_val_dataset = train_val_dataset.shuffle(buffer_size=1024)\n","\n","train_dataset = train_val_dataset.take(train_size)\n","val_dataset = train_val_dataset.skip(train_size)\n","\n","train_n, val_n, test_n = len(train_dataset), len(val_dataset), len(test_dataset)\n","print(train_n, val_n, test_n)\n","assert train_n + val_n + test_n == total_n   # 문제가 없는지 확인\n","\n","# batchfy (dataloader)\n","train_batch_size = cfg.train.train_batch_size\n","val_batch_size = cfg.train.val_batch_size \n","test_batch_size = cfg.train.test_batch_size\n","\n","train_dataloader = train_dataset.batch(train_batch_size, drop_remainder=True)\n","val_dataloader = val_dataset.batch(val_batch_size, drop_remainder=True)\n","test_dataloader = test_dataset.batch(test_batch_size, drop_remainder=True)"],"metadata":{"id":"dzDsYhtQ3vrS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## define model\n","\n","LinearWarmupLRScheduler 하는 이유\n","- SGD는 다른 optimizer 대비 learning rate 값에 매우 민감\n","  - learning rate를 잘 setting 해야 성능이 좋게 나옴 (Adam보다 더 좋게 나오기도 함)\n","- 따라서 optimizer와 함께 learning rate도 tuning 하는 게 원래는 좋음\n","- 그러나 학습 속도가 너무 느려지는 단점\n","\n","warmup을 하기 어려운 상황이면?\n","- Rectified Adam으로 먼저 테스트 해 보고, optimizer는 조절해도 거의 결과 비슷하게 나오니, 모델링 부분을 업데이트 해 보기\n","- Rectified Adam에도 tuning 할 수 있는 요소 많음\n","  - https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/RectifiedAdam"],"metadata":{"id":"04O0P4wLPmC2"}},{"cell_type":"code","source":["# 모델 정의\n","def get_seq2seq_model(cfg: DictConfig):\n","    if cfg.model.name == \"RNNSeq2Seq\":\n","        encoder = GRUEncoder(cfg)\n","        decoder = GRUDecoder(cfg)\n","    elif cfg.model.name == \"AttentionBasedSeq2Seq\":\n","        encoder = GRUEncoder(cfg)\n","        decoder = AttentionalGRUDecoder(cfg)\n","    elif cfg.model.name == \"TransformerBasedSeq2Seq\":\n","        encoder = TransformerEncoder(cfg)\n","        decoder = TransformerDecoder(cfg)\n","    else:\n","        raise NotImplementedError()\n","    return encoder, decoder"],"metadata":{"id":"P1kMS7uKq1wU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss 정의\n","def loss_function(\n","    real,\n","    pred,\n","    loss_object=tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction=\"none\"\n","    )\n","):\n","    # delete [pad] loss part with masks. \n","    mask = tf.math.logical_not(\n","        tf.math.equal(real, 0)\n","    )\n","    _loss = loss_object(real, pred)\n","\n","    mask = tf.cast(mask, dtype=_loss.dtype)\n","    _loss *= mask\n","\n","    return tf.reduce_mean(_loss)\n"],"metadata":{"id":"jMhwWH_rgyR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get model\n","encoder, decoder = get_seq2seq_model(cfg)  # 이때 encoder, decoder는 layer들임\n","\n","# model을 한 번 더 말아줄 것\n","encoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","encoder_outputs = encoder(encoder_inputs)\n","\n","decoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","decoder_outputs = decoder(decoder_inputs, encoder_outputs)\n","\n","# keras 모델 형태로 바꾸기\n","transformer = tf.keras.Model(\n","    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",")\n","\n","transformer.summary()\n","\n","# get optimizer\n","optimizer, scheduler = get_optimizer_element(\n","    cfg.opt.optimizer, cfg.opt.lr_scheduler\n",")"],"metadata":{"id":"D116PxC6h9XS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["callbacks = get_callbacks(cfg.log)"],"metadata":{"id":"lSbWZOHRSsGW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Custom Train/Eval Steps"],"metadata":{"id":"Mp2knX5ltEqq"}},{"cell_type":"code","source":["@tf.function\n","def _step(src, tar, enc_hidden, teacher_forcing_ratio=0.5):\n","\n","    if cfg.model.name == \"RNNSeq2Seq\":\n","        return _rnn_step(src, tar, enc_hidden, teacher_forcing_ratio)\n","    elif cfg.model.name == \"AttentionBasedSeq2Seq\":\n","        return _attentional_rnn_step(src, tar, enc_hidden, teacher_forcing_ratio)\n","    else:\n","        raise NotImplementedError()\n","\n","@tf.function\n","def _attentional_rnn_step(src, tar, enc_hidden, teacher_forcing_ratio=0.5):\n","    enc_output, enc_hidden = encoder(src, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    # add start token\n","    dec_input = tf.expand_dims(\n","        [tar_tokenizer.word_index[\"<start>\"]] * src.shape[0],   # multiply with batch_size\n","        1\n","    )  # [Batch, 1]\n","\n","    outputs = []\n","    loss = 0\n","\n","    # sequence 길이만큼 루프! (autoregressive or teacher-forcing)\n","    for t in range(1, tar.shape[1]):\n","        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","        \n","        outputs.append(predictions)            # [batch_size, vocab_size]\n","        final_outs = tf.argmax(predictions, 1) # [batch_size]\n","        ground_truth = tar[:, t]               # [batch_size]\n","\n","        loss += loss_function(ground_truth, predictions)\n","\n","        # random.random() : pick random number between 0~1\n","        if random.random() < teacher_forcing_ratio:  # teacher forcing case\n","            dec_input = tf.expand_dims(ground_truth, 1)\n","        else:                                        # no teacher forcing case\n","            dec_input = tf.expand_dims(final_outs, 1)\n","    \n","    return loss, outputs\n","\n","# 최적화 이슈가 있는 경우 tensorflow에서는 @ decorator 사용\n","@tf.function\n","def _rnn_step(src, tar, enc_hidden, teacher_forcing_ratio=0.5):\n","\n","    enc_output, enc_hidden = encoder(src, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    # add start token\n","    dec_input = tf.expand_dims(\n","        [tar_tokenizer.word_index[\"<start>\"]] * src.shape[0], # multiply with batch_size\n","        1\n","    )  # [Batch, 1]\n","\n","    outputs = []\n","    loss = 0\n","\n","    # sequence 길이만큼 루프! (autoregressive or teacher-forcing)\n","    for t in range(1, tar.shape[1]):\n","        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden) # prediction : [Batch, 1, target voca size]\n","\n","        outputs.append(predictions[:, 0])   # [Batch, voca size]\n","        final_outs = tf.argmax(predictions, 2) # [Batch, 1]\n","\n","        ground_truth = tf.expand_dims(tar[:, t], 1)  # for teacher-forcing : [B] -> [B, 1]\n","\n","        loss += loss_function(ground_truth, predictions)\n","\n","        # random.random() : pick random number between 0~1\n","        if random.random() < teacher_forcing_ratio: # teacher forcing case\n","            dec_input = ground_truth\n","        else:                                        # no teacher forcing case\n","            dec_input = final_outs \n","    \n","    return loss, outputs\n","\n","@tf.function\n","def train_step(src, tar, enc_hidden, teacher_forcing_ratio=0.5):\n","    with tf.GradientTape() as tape:\n","        loss, outputs = _step(src, tar, enc_hidden, teacher_forcing_ratio)\n","    \n","    batch_loss = (loss / int(tar.shape[1])) # divide with seq_len\n","\n","    variables = encoder.trainable_variables + decoder.trainable_variables\n","    gradients = tape.gradient(loss, variables)\n","    optimizer.apply_gradients(zip(gradients, variables))\n","\n","    return batch_loss, outputs\n","\n","\n","# test에서는 teacher forcing이 있을 수 없음 - 순차적으로 적용해서 맞아야 하기 때문에 (test set은 순서 중요)\n","@tf.function\n","def eval_step(src, tar, enc_hidden):\n","    loss, outputs = _step(src, tar, enc_hidden, 0.0)\n","    batch_loss = (loss / int(tar.shape[1])) # divide with seq_len\n","    return batch_loss, outputs"],"metadata":{"id":"5RgOKjuJtLmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer.compile(\n","    optimizer,\n","    loss=loss_function,\n","    metrics=[]\n",")\n","\n","# get_callbacks\n","callbacks = get_callbacks(cfg.log)"],"metadata":{"id":"r9O78rqYeixa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decode_tr_sequence(transformer, sentence: str):\n","    sentence = preprocess_sentence(sentence)\n","\n","    inputs = [src_tokenizer.word_index[i] for i in sentence.split(\" \")]\n","    inputs = pad_sequences([inputs], maxlen=max_src_len, padding=\"post\")\n","\n","    inputs = tf.convert_to_tensor(inputs)\n","\n","    result = \"\"\n","\n","    # autoregressive inference of decoder\n","    dec_inputs = tf.cast(\n","        tf.expand_dims([tar_tokenizer.word_index[\"<start>\"]], 0),   # start token\n","        tf.int64\n","    )\n","\n","    for t in range(max_tar_len):\n","        dec_outputs = transformer([inputs, dec_inputs])  # [batch, length, vocab size]\n","\n","        predicted_id = tf.expand_dims(\n","            tf.argmax(\n","                tf.math.softmax(dec_outputs[:, t, :]),   # [batch, vocab size]\n","                axis=1,\n","                ),\n","                0,   # [batch]\n","        )  # [1, batch]\n","\n","        # prep next steps\n","        dec_inputs = tf.concat([dec_inputs, predicted_id], 1)\n","\n","        sampled_token = tar_tokenizer.index_word[predicted_id.numpy()[0, 0]]\n","\n","        if sampled_token == \"<end>\":\n","            break\n","        result += sampled_token + \" \"\n","        \n","    return result\n","    \n","# sample test\n","print(decode_tr_sequence(transformer, u\"Esta es mi vida.\"))"],"metadata":{"id":"r4yxf78re2rz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## wandb setup\n","\n","- https://docs.wandb.ai/guides/integrations/tensorflow\n","- sync_tensorboard=True : tensorflow에 적혀있는 걸 wandb에 업로드"],"metadata":{"id":"W3kBknhvHV3r"}},{"cell_type":"code","source":["# flatten_dict(cfg)   # 전부 flatten 하게 바꿔주는 함수 -> nested 구조를 모두 under bar 형태로 바꿈"],"metadata":{"id":"SpD4-l8og5RW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wandb.init(\n","    config= flatten_dict(cfg),\n","    **cfg.log.wandb\n",")"],"metadata":{"id":"WxPeYZkVHWBV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/\n","\n","def format_dataset(_src, _tar):\n","    return ({\n","        # input값\n","        \"encoder_inputs\": _src,\n","        \"decoder_inputs\": _tar[:, :-1], # end token 제외하고 사용\n","    }, _tar[:, 1:])  # 실제 true 값 : start toekn 제외하고 사용\n","\n","transformer.fit(\n","    train_dataloader.map(format_dataset),\n","    validation_data=val_dataloader.map(format_dataset),\n","    epochs=cfg.train.max_epochs,\n","    callbacks=callbacks\n",")"],"metadata":{"id":"WyH4HKy2jsgZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test"],"metadata":{"id":"wsGp72ElmwjF"}},{"cell_type":"code","source":["print(decode_tr_sequence(transformer, u\"Esta es mi vida.\")) # this is my life .\n","print(decode_tr_sequence(transformer, u'hace mucho frio aqui.')) # it s very cold ."],"metadata":{"id":"hpo6zVSAmy-4"},"execution_count":null,"outputs":[]}]}
