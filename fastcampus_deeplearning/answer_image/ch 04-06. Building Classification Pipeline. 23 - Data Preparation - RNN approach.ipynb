{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "verified-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "built-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "model = keras.models.load_model(\n",
    "    'ucf11_weights/10-0.87.hdf5',\n",
    "    custom_objects={'KerasLayer':hub.KerasLayer} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "roman-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              5919312   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 11)                14091     \n",
      "=================================================================\n",
      "Total params: 5,933,403\n",
      "Trainable params: 5,872,795\n",
      "Non-trainable params: 60,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hybrid-flour",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"feature_extractor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              5919312   \n",
      "=================================================================\n",
      "Total params: 5,919,312\n",
      "Trainable params: 5,858,704\n",
      "Non-trainable params: 60,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(256, 256, 3)),\n",
    "        model.layers[0]\n",
    "    ], name='feature_extractor'\n",
    ")\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "virgin-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('UCF11_updated_npy')\n",
    "os.mkdir('UCF11_updated_npy/train')\n",
    "os.mkdir('UCF11_updated_npy/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "breathing-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 10\n",
    "SAVE_DIR = 'UCF11_updated_npy/'\n",
    "train_df = pd.read_csv('ucf11_train_vid.csv')\n",
    "valid_df = pd.read_csv('ucf11_valid_vid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "developed-stranger",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [00:21<00:00, 10.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, elem in tqdm(train_df.iterrows(),\n",
    "                    total=len(train_df)):\n",
    "    label = elem['label']\n",
    "    cap = cv2.VideoCapture(\n",
    "        elem['file_path']\n",
    "    )\n",
    "    \n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        frame_ = frame.copy()\n",
    "        frame_ = cv2.cvtColor(frame_, cv2.COLOR_BGR2RGB)\n",
    "        frame_ = cv2.resize(frame_, (256, 256))\n",
    "        frame_ = frame_.astype('float32')\n",
    "        frame_ = frame_ / 255.\n",
    "        \n",
    "        frames.append(frame_)\n",
    "        if len(frames) == max_frames:\n",
    "            break\n",
    "    cap.release()\n",
    "    \n",
    "    frames = np.array(frames)\n",
    "    features = feature_extractor.predict(frames)\n",
    "    \n",
    "    file_name = SAVE_DIR + f'train/{label}_{i}.npy'\n",
    "    np.save(file_name, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "focal-moral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n"
     ]
    }
   ],
   "source": [
    "print(len(glob(SAVE_DIR + 'train/*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "present-space",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:05<00:00, 10.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, elem in tqdm(valid_df.iterrows(),\n",
    "                    total=len(valid_df)):\n",
    "    label = elem['label']\n",
    "    cap = cv2.VideoCapture(\n",
    "        elem['file_path']\n",
    "    )\n",
    "    \n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        frame_ = frame.copy()\n",
    "        frame_ = cv2.cvtColor(frame_, cv2.COLOR_BGR2RGB)\n",
    "        frame_ = cv2.resize(frame_, (256, 256))\n",
    "        frame_ = frame_.astype('float32')\n",
    "        frame_ = frame_ / 255.\n",
    "        \n",
    "        frames.append(frame_)\n",
    "        if len(frames) == max_frames:\n",
    "            break\n",
    "    cap.release()\n",
    "    \n",
    "    frames = np.array(frames)\n",
    "    features = feature_extractor.predict(frames)\n",
    "    \n",
    "    file_name = SAVE_DIR + f'valid/{label}_{i}.npy'\n",
    "    np.save(file_name, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "looking-means",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(glob(SAVE_DIR + 'valid/*')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('fpn-tf2': conda)",
   "language": "python",
   "name": "python37664bitfpntf2condae5b522716c70413d8087b855565880dc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
