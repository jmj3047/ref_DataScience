{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part6_2_이미지처리실습_dataAugmentation_callback.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huTEunV4upZs"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from glob import glob\n",
        "\n",
        "import math\n",
        "import random \n",
        "\n",
        "import cv2                                 # image를 읽기 위한 open cv library\n",
        "import xml.etree.ElementTree as et         # xml 파일을 parsing 하기 위한 library\n",
        "from matplotlib.patches import Rectangle   # Bounding box를 그리기 위함\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import activations\n",
        "\n",
        "import albumentations as A    # CoarseDropout 인지 안 된다는 문제 발생 -> pip install 아래 세 가지 코드 실행 필요\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "drive_project_root = 'drive/MyDrive/data/'\n",
        "sys.path.append(drive_project_root)\n",
        "\n",
        "image_root = 'drive/MyDrive/data/images/'\n",
        "anno_root = 'drive/MyDrive/data/annotations/'\n",
        "\n",
        "image_dir = image_root\n",
        "bbox_dir = anno_root + 'xmls/'    # bounding box\n",
        "seg_dir = anno_root + 'trimaps/'  # segmentation map\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/albumentations-team/albumentations.git  # Data Agumentation"
      ],
      "metadata": {
        "id": "iwb_m9WYurzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall opencv-python"
      ],
      "metadata": {
        "id": "ZK2kDyKv0iZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python"
      ],
      "metadata": {
        "id": "ZG6KO9OmutZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 1. Data Augmentation\n",
        "- 보통 training단계에서 많이 사용됨\n",
        "- 데이터 양을 늘리기 위해 원본 이미지를 여러 가지 방식으로 변환하는 것\n",
        "- 결함이 있는 데이터에 대해서도 robust한 모델을 만들기 위함\n",
        "- 3rd party library 사용\n",
        "  - 많은 사람들이 사용하는 것 추천 - Albumentations : made by kaggle masters"
      ],
      "metadata": {
        "id": "86nnOglW1YZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Augmentation:\n",
        "    def __init__(self, size, mode='train'):\n",
        "        if mode == 'train':\n",
        "            # Declare an augmentation pipeline\n",
        "            # 여러 번 호출할 예정이라 transform이 아닌 self.transform으로 저장함\n",
        "            self.transform = A.Compose([\n",
        "                # A.RandomCrop(width=256, height=256),  # resize: 외부에서 따로 할 예정\n",
        "                # 좌우반전 (test 이미지에서 상하반전은 별로 없지만 좌우반전된 이미지는 많이 있을 것 같아서 추가함)\n",
        "                # p : 해당 변화를 적용되는 정도 (확률)\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.ShiftScaleRotate(\n",
        "                    p=0.5,\n",
        "                    shift_limit=0.05,  # 이미지 상하좌우 이동 (가로 길이가 최대 몇% 넘어가도 되는 지)\n",
        "                    scale_limit=0.05,  # 이미지 확대/축소 (최대 5%)\n",
        "                    rotate_limit=15,   # 이미지 회전 (최대 15도)\n",
        "                ),\n",
        "                A.CoarseDropout(                 # 이미지에 구멍 뚫기\n",
        "                    p=0.5,\n",
        "                    max_holes=8,                 # 최대 구멍 개수\n",
        "                    max_height=int(0.1 * size),  # 가로 최대 길이 : 이미지의 10%\n",
        "                    max_width=int(0.1 * size),\n",
        "                ),\n",
        "                A.RandomBrightnessContrast(p=0.2),\n",
        "            ])\n",
        "\n",
        "    def __call__(self, **kwargs):\n",
        "        if self.transform:   # train mode인 경우\n",
        "            augmented = self.transform(**kwargs)\n",
        "            img = augmented['image']\n",
        "            return img"
      ],
      "metadata": {
        "id": "Sb1B9ExX1aa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eEHkNpa81aeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0obFOy4r1ahg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 2. Data Loader"
      ],
      "metadata": {
        "id": "PCrxUznpvesV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, batch_size, csv_path, image_size,\n",
        "                 fold, mode='train', shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.shuffle = shuffle\n",
        "        self.fold = fold\n",
        "        self.mode = mode\n",
        "        \n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        \n",
        "        if self.mode == 'train':\n",
        "            self.df = self.df[self.df['fold'] != self.fold]\n",
        "        elif self.mode == 'val':\n",
        "            self.df = self.df[self.df['fold'] == self.fold]\n",
        "        \n",
        "        #### Remove invalid files\n",
        "        #### https://github.com/tensorflow/models/issues/3134\n",
        "        invalid_filenames = [\n",
        "            'Egyptian_Mau_14',\n",
        "            'Egyptian_Mau_139',\n",
        "            'Egyptian_Mau_145',\n",
        "            'Egyptian_Mau_156',\n",
        "            'Egyptian_Mau_167',\n",
        "            'Egyptian_Mau_177',\n",
        "            'Egyptian_Mau_186',\n",
        "            'Egyptian_Mau_191',\n",
        "            'Abyssinian_5',\n",
        "            'Abyssinian_34',\n",
        "            'chihuahua_121',\n",
        "            'beagle_116'\n",
        "        ]\n",
        "        self.df = self.df[~self.df['file_name']. \\\n",
        "                          isin(invalid_filenames)]\n",
        "\n",
        "        self.transform = Augmentation(image_size, mode)  ### Augmentation 적용\n",
        "\n",
        "        self.on_epoch_end()\n",
        "            \n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.df) / self.batch_size)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        strt = idx * self.batch_size\n",
        "        fin = (idx + 1) * self.batch_size\n",
        "        data = self.df.iloc[strt:fin]\n",
        "        \n",
        "        batch_x, batch_y = self.get_data(data)\n",
        "        \n",
        "        return np.array(batch_x), np.array(batch_y)\n",
        "        \n",
        "    def get_data(self, data):\n",
        "        batch_x = []\n",
        "        batch_y = []\n",
        "        \n",
        "        for _, r in data.iterrows():\n",
        "            file_name = r['file_name']\n",
        "            \n",
        "            image = cv2.imread(f'{image_root}{file_name}.jpg')\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "\n",
        "            if self.mode == 'train':   ### Augmentation 적용\n",
        "                # augmentation 중에는 image가 uint8인 경우에만 적용되는 것들이 있음\n",
        "                # -> image를 먼저 uint8로 변환하기\n",
        "                image = image.astype('uint8')\n",
        "                image = self.transform(image=image)\n",
        "\n",
        "            image = image.astype('float32')\n",
        "            image = image / 255.\n",
        "            \n",
        "            label = int(r['species']) - 1\n",
        "            \n",
        "            batch_x.append(image)\n",
        "            batch_y.append(label)\n",
        "        \n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "NaSI_YXXvf1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = drive_project_root+'kfolds.csv'\n",
        "\n",
        "train_generator = DataGenerator(\n",
        "    fold=1,\n",
        "    mode='train',\n",
        "    csv_path=csv_path,\n",
        "    batch_size=128,\n",
        "    image_size=256,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "valid_generator = DataGenerator(\n",
        "    fold=1,\n",
        "    mode='val',\n",
        "    csv_path=csv_path,\n",
        "    batch_size=128,\n",
        "    image_size=256,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "9R100_8AvBLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- CoarseDropout이 적용된 결과 0.5%의 확률로 특정 이미지에 hole들이 뚫려있음\n",
        "- 랜덤하게 적용되기 때문에 아래 코드 다시 돌려보면 CoarseDropout 적용된 이미지가 계속 달라짐\n",
        "- 회전된 이미지도 볼 수 있음"
      ],
      "metadata": {
        "id": "QCCWYxag3Ps4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = ['Cat', 'Dog']\n",
        "\n",
        "for batch in train_generator:\n",
        "    X, y = batch\n",
        "    plt.figure(figsize=(10,10))\n",
        "\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i+1)\n",
        "        plt.imshow(X[i])\n",
        "        plt.title(class_name[y[i]])\n",
        "        plt.axis('off')\n",
        "    break"
      ],
      "metadata": {
        "id": "rQYPhopG3Pwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 3. Modeling"
      ],
      "metadata": {
        "id": "J26BZZXrutgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sequential_model(input_shape):\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            # Input\n",
        "            layers.Input(input_shape),\n",
        "\n",
        "            # 1st Conv block\n",
        "            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n",
        "            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n",
        "            layers.MaxPool2D(),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Dropout(0.5),\n",
        "\n",
        "            # 2nd Conv block\n",
        "            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n",
        "            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n",
        "            layers.MaxPool2D(),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Dropout(0.3),\n",
        "        \n",
        "            # Classfier\n",
        "            layers.GlobalMaxPool2D(),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# input_shape = (256, 256, 3)\n",
        "input_shape = (16, 16, 3)    # memory error 때문에 input size 바꿔봄\n",
        "model = get_sequential_model(input_shape)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics='accuracy'\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "eykE-MYdvBH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 4. Callback functions\n",
        "- 특정 상황에서 호출하는 함수\n",
        "  - on_train_begin : 학습이 시작될 때 호출\n",
        "  - on_epoch_end : 매 epoch이 끝날 때마다 호출\n",
        "- 자주 쓰이는 callback 함수 3가지 : Early Stopping, Reduce on Plateau,ModelCheckpoint\n",
        "  - 만약 early stopping (patience: 3)과 reduce on plateau (patience: 10)를 같이 쓰면, 어차피 3일 때 early stopping이 될 것이기 때문에 실제로 reduce on plateau가 불리는 일은 없음"
      ],
      "metadata": {
        "id": "zJWSNuvXvBW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Early Stopping\n",
        "- 성능이 나아지지 않으면 학습 중단"
      ],
      "metadata": {
        "id": "Jalab9mDvBds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    # validation loss가 3 epoch 동안 줄어들지(min) 않으면 학습 멈추기\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    mode=\"min\",\n",
        "    restore_best_weights=False\n",
        ")"
      ],
      "metadata": {
        "id": "pbEB5_B7vBjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Reduce on plateau\n",
        "- metric 성능이 나아지지 않으면 learning rate를 줄이기"
      ],
      "metadata": {
        "id": "CABJk3qjvBnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    # validation loss이 10 epoch 동안 작아지지 않으면 learning rate를 0.1배로 줄이기\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    min_lr=0.001  # 하지만 learning rate가 0.001보다는 작아지면 안됨\n",
        ")"
      ],
      "metadata": {
        "id": "9hcQ4riovBsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Model Checkpoint"
      ],
      "metadata": {
        "id": "aSG2kPGhvBxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = '{drive_project_root}{epoch:02d}-{val_loss:.2f}.hdf5'\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath,\n",
        "    monitor='val_loss',  # validation loss가 작아질 때마다 저장\n",
        "    verbose=1,\n",
        "    save_best_only=True,     # best 외 불필요한 건 저장X\n",
        "    save_weights_only=False, # weight 파일만 따로 저장할지\n",
        "    mode='min'\n",
        ")"
      ],
      "metadata": {
        "id": "Cvz48eofvB3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 5. Model fitting"
      ],
      "metadata": {
        "id": "aBoqObm1vB8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=10,\n",
        "    callbacks=[\n",
        "        early_stopping,\n",
        "        reduce_on_plateau,\n",
        "        model_checkpoint\n",
        "    ],\n",
        "    verbose=1   # 학습되는 과정 보여주기\n",
        ")"
      ],
      "metadata": {
        "id": "h6GfQLeuvCBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- training/validation의 loss, accuracy 확인"
      ],
      "metadata": {
        "id": "owKMc42-vCXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "id": "SzpPxygqvCab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 6. Visualization"
      ],
      "metadata": {
        "id": "HjjMavqhvCg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['loss'], label='train')\n",
        "plt.plot(history['val_loss'], label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title(\"Loss\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['accuracy'], label='train')\n",
        "plt.plot(history['val_accuracy'], label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s6GRSGWBvDJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}