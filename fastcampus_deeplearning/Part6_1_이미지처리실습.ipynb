{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Part6_1_이미지처리실습.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOYYBMvBnpkqTS49homBYSz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["Google mount"],"metadata":{"id":"BVCOfFxMEwf6"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import sys\n","\n","drive_project_root = '/content/drive/MyDrive/#fastcampus'\n","sys.path.append(drive_project_root)\n","\n","!ls"],"metadata":{"id":"RlSsaeCIEx8A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset EDA\n","\n","### data\n","- Google 'oxford pet dataset'\n","- Download 'groundtruth data'"],"metadata":{"id":"JTtUbB7PEx_Z"}},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","sns.set_style('whitegrid')"],"metadata":{"id":"kzE1sXTZEyCe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('drive/MyDrive/data/annotations/list.txt', skiprows=6, delimiter=\" \", header=None)\n","df.columns = ['file_name', 'id', 'species', 'breed']\n","df"],"metadata":{"id":"2ZGd69uLEyFP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 숫자 분포 확인"],"metadata":{"id":"p6t5J7jTEyHw"}},{"cell_type":"code","source":["value_counts = df['species'].value_counts().sort_index()   # 1: 고양이, 2: 강아지\n","\n","plt.bar(range(len(value_counts)), value_counts.values, align='center')\n","plt.xticks(range(len(value_counts)), value_counts.index.values)\n","plt.show()"],"metadata":{"id":"CqApcNI4EyKB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(value_counts)\n","print('\\nrange: ',range(len(value_counts)))\n","print('\\nvalues: ',value_counts.values)"],"metadata":{"id":"6xKDMNmoEyMz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 각 class에 대해 대략 200장 씩 이미지가 있다는 것 확인"],"metadata":{"id":"zpduYQfBEyPN"}},{"cell_type":"code","source":["value_counts = df['id'].value_counts().sort_index()\n","\n","plt.bar(range(len(value_counts)), value_counts.values, align='center')\n","plt.xticks(range(len(value_counts)), value_counts.index.values)\n","plt.tight_layout()    # x label이 겹치지 않게 출력\n","plt.show()"],"metadata":{"id":"MgPRMSx_FH1F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 고양이와 개 각각에 대한 class 구성\n","- 고양이는 12가지, 강아지는 25가지 종류가 있음을 확인"],"metadata":{"id":"R0U0FJ8fFH3n"}},{"cell_type":"code","source":["value_counts = df[df['species'] == 1]['breed'].value_counts().sort_index()  # 고양이만\n","\n","plt.bar(range(len(value_counts)), value_counts.values, align='center')\n","plt.xticks(range(len(value_counts)), value_counts.index.values)\n","plt.tight_layout()    # x label이 겹치지 않게 출력\n","plt.show()"],"metadata":{"id":"1h1s49YsFH56"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["value_counts = df[df['species'] == 2]['breed'].value_counts().sort_index()  # 강아지만\n","\n","plt.bar(range(len(value_counts)), value_counts.values, align='center')\n","plt.xticks(range(len(value_counts)), value_counts.index.values)\n","plt.tight_layout()    # x label이 겹치지 않게 출력\n","plt.show()"],"metadata":{"id":"zIAMWNzlFH8k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 파일들을 읽기 위한 library"],"metadata":{"id":"xG6H2XKuFH-r"}},{"cell_type":"code","source":["import os\n","from glob import glob"],"metadata":{"id":"Z_Cdm5nhFIBU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_dir = 'drive/MyDrive/data/images/'\n","bbox_dir = 'drive/MyDrive/data/annotations/xmls/'  # bounding box\n","seg_dir = 'drive/MyDrive/data/annotations/trimaps/'  # segmentation map"],"metadata":{"id":"ObdY2V2fFIDy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_files = glob(image_dir + '*.jpg')  # 경로 읽기\n","print(len(image_files))\n","\n","image_files[:10]   # 경로가 제대로 읽혔는지 확인"],"metadata":{"id":"B1TG82hxFIGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seg_files = glob(seg_dir + '*.png')\n","print(len(seg_files))\n","\n","seg_files[:10]   # 경로가 제대로 읽혔는지 확인"],"metadata":{"id":"0KNidZiIFIIv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bbox_files = glob(bbox_dir + '*.xml')\n","print(len(bbox_files))     # image_files, seg_files보다 적음 -> 모든 이미지에 대해 head ROI가 제공되는 것은 아니라는 것\n","\n","bbox_files[:10]"],"metadata":{"id":"s-5My9srFYwm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Head ROI 시각화"],"metadata":{"id":"7srLVczqFYzO"}},{"cell_type":"code","source":["pip install opencv-python"],"metadata":{"id":"2o9ASfnBFY1t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2    # image를 읽기 위한 open cv library\n","import xml.etree.ElementTree as et         # xml 파일을 parsing 하기 위한 library\n","from matplotlib.patches import Rectangle   # Bounding box를 그리기 위함"],"metadata":{"id":"6_--vHYyFY3_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["cv2.Rectangle(image, pt1 : 시작점 좌표, pt2 : 종료점 좌표, color, thickness, lineType, shift)"],"metadata":{"id":"PEI6E8bpFY6k"}},{"cell_type":"code","source":["# 임의의 이미지 파일 경로 하나 가져와서 이에 해당하는 bounding box의 경로 찾기\n","image_path = image_files[80]\n","bbox_path = image_path.replace(image_dir, bbox_dir).replace('jpg', 'xml')\n","\n","# image 파일을 open cv로 읽기\n","# 주의점 : RGB가 아니라 BGR 형식으로 읽힘\n","image = cv2.imread(image_path)                 # path에 한국어 경로 있으면 안 읽힐 수 있음\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # BGR 형식을 RGB로 바꿔줄 것\n","\n","# xml파일 parsing 하기\n","tree = et.parse(bbox_path)\n","\n","# bounding box 좌표는 object (bounding box) tag 아래 있었음\n","xmin = float(tree.find('./object/bndbox/xmin').text)\n","xmax = float(tree.find('./object/bndbox/xmax').text)\n","ymin = float(tree.find('./object/bndbox/ymin').text)\n","ymax = float(tree.find('./object/bndbox/ymax').text)\n","\n","# 가로, 세로 길이\n","rect_x = xmin\n","rect_y = ymin\n","rect_w = xmax - xmin\n","rect_h = ymax - ymin\n","\n","# bounding box 객체 만들기 : Head ROI\n","rect = Rectangle((rect_x, rect_y), rect_w, rect_h, fill=False, color='red')\n","plt.axes().add_patch(rect)\n","plt.imshow(image)\n","\n","plt.show()"],"metadata":{"id":"a1HGhembFY8p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SEG map\n","\n","- 보통 3가지 채널이 아닌 하나의 채널에 정보가 모두 저장되어 있음 (grayscale)"],"metadata":{"id":"toXonnZfFY_A"}},{"cell_type":"code","source":["image_path = image_files[90]\n","seg_path = image_path.replace(image_dir, seg_dir).replace('jpg', 'png')\n","\n","image = cv2.imread(image_path)\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","seg_map = cv2.imread(seg_path, cv2.IMREAD_GRAYSCALE)  # Grayscale 이미지를 읽어온다는 것 알려줌\n","\n","# side by side 출력\n","plt.figure(figsize=(10, 10))\n","plt.subplot(1,2,1)\n","plt.imshow(image)\n","plt.subplot(1,2,2)\n","plt.imshow(seg_map)\n","\n","plt.show()"],"metadata":{"id":"ype4LHSbFZBj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 이미지 분류 (k-fold)\n","\n","- validation set으로 index 줘서 fold column 만들어 놓으면 향후 작업하기 편함\n","- fold별로 데이터가 균등하게 뽑혔는지 항상 주의\n","  - 요크셔테리어가 전혀 없는 fold 학습하는 모델은 요크셔테리어 분류 못함\n","  - ★ 방법 : sklearn의 StratifiedKFold 사용"],"metadata":{"id":"X4Eo0mriFZD7"}},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold"],"metadata":{"id":"eCE3v67eFlMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# fold column 생성 후 -1로 초기화\n","df['fold'] = -1\n","\n","for idx, (train, val) in enumerate(kf.split(df), 1):\n","    print(train, val, len(val))\n","    df.loc[val, 'fold'] = idx     # validation으로 쓰인 fold index 저장 (1~5)"],"metadata":{"id":"UnnNpRjcFlPU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[:5]\n","\n","print(len(df[df['fold']==1]))  # 첫 번째 fold에 대한 validation set\n","print(len(df[df['fold']!=1]))  # 첫 번째 fold에 대한 train set"],"metadata":{"id":"jW6lOFqPFlQ_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 강아지와 고양이 품종이 균등하게 분포되어 있는지 시각화로 확인"],"metadata":{"id":"M0wG8KL6GHsI"}},{"cell_type":"code","source":["value_counts = df[df['fold'] != 5]['id'].value_counts().sort_index()   # 5번째 fold의 training data\n","\n","plt.bar(range(len(value_counts)), value_counts.values, align='center')\n","plt.xticks(range(len(value_counts)), value_counts.index.values)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"ZIib4_q2FlUF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- StratifiedKFold 사용하기"],"metadata":{"id":"VUWqvwebFlZ7"}},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","df['fold'] = -1\n","\n","for idx, (train, val) in enumerate(skf.split(df, df['id']), 1):  # 'id' (품종)을 최대한 균등하게 하겠다\n","    print(train, val, len(val))\n","    df.loc[val, 'fold'] = idx"],"metadata":{"id":"MawaCYE1FZGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["value_counts = df[df['fold'] != 5]['id'].value_counts().sort_index()   # 5번째 fold의 training data\n","\n","plt.bar(range(len(value_counts)), value_counts.values, align='center')\n","plt.xticks(range(len(value_counts)), value_counts.index.values)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"vpALgaqyFILZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 추후 학습을 위해 저장"],"metadata":{"id":"5p0Aidu9FINg"}},{"cell_type":"code","source":["df.to_csv('kfolds.csv', index=False)"],"metadata":{"id":"YSwUooZ1EyRu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","# Data Loader\n","\n","- keras로 data loader를 작성할 때는 sequence를 사용하는데, 일반 generator를 사용하는 것보다 multi-processing에 더 적합하기 때문 (keras 공식문서에서도 sequence 사용을 권장)\n","- sequence 함수\n","  - 반드시 있어야 하는 것 : len, getitem\n","    - len : 한 epoch에 몇 개의 batch가 있는지\n","    - getitem : 하나의 batch 생성\n","  - optional : on_epoch_end"],"metadata":{"id":"2clg529EGZOI"}},{"cell_type":"markdown","source":["### Oxford pet data에 대한 sequence 함수 작성하기"],"metadata":{"id":"KJfnYmHXGZQe"}},{"cell_type":"code","source":["import math\n","import random \n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from tensorflow import keras"],"metadata":{"id":"Xj2HC7wBGZSz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataGenerator(keras.utils.Sequence):\n","    # fold : 5가지 중 어떤 fold를 사용할지\n","    def __init__(self, batch_size, csv_path, fold, image_size, mode='train', shuffle=True):\n","        self.batch_size = batch_size\n","        self.image_size = image_size\n","        self.fold = fold\n","        self.mode = mode\n","        self.shuffle = shuffle\n","        \n","        self.df = pd.read_csv(csv_path)\n","        \n","        # 필요한 데이터만 남기기\n","        if self.mode == 'train':\n","            self.df = self.df[self.df['fold'] != self.fold]  # training\n","        elif self.mode == 'val':\n","            self.df = self.df[self.df['fold'] == self.fold]  # validation\n","            \n","        # Remove invalid files\n","        invalid_filenames = [\n","            'Egyptian_Mau_14',\n","            'Egyptian_Mau_139',\n","            'Egyptian_Mau_145',\n","            'Egyptian_Mau_156',\n","            'Egyptian_Mau_167',\n","            'Egyptian_Mau_177',\n","            'Egyptian_Mau_186',\n","            'Egyptian_Mau_191',\n","            'Abyssinian_5',\n","            'Abyssinian_34',\n","            'chihuahua_121',\n","            'beagle_116'            \n","        ]\n","        self.df = self.df[-self.df['file_name']. \\\n","                         isin(invalid_filenames)]\n","        \n","        # 학습을 시작하는 첫 epoch에서도 shuffle을 하고 싶은 경우\n","        self.on_epoch_end()  # 원치 않는 경우 이 부분 코드는 빼기\n","        \n","    def __len__(self):\n","        # 나눠 떨어지지 않는 경우 남는 데이터가 생김\n","        # -> 올림 필요\n","        return math.ceil(len(self.df) / self.batch_size)\n","    \n","    # idx : 몇 번째 batch를 return 하고 싶은지\n","    # i.e. 첫 번째 : 0\n","    def __getitem__(self, idx):\n","        strt = idx * self.batch_size\n","        fin = (idx + 1) * self.batch_size\n","        data = self.df.iloc[strt:fin]\n","        \n","        batch_x, batch_y = self.get_data(data)\n","        return np.array(batch_x), np.array(batch_y)\n","    \n","    # data 내 모든 이미지와 label return\n","    def get_data(self, data):\n","        \n","        batch_x = []\n","        batch_y = []\n","        \n","        # r : csv 파일의 값들\n","        for _, r in data.iterrows():\n","            file_name = r['file_name']\n","            image = cv2.imread(f'drive/MyDrive/data/images/{file_name}.jpg')\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            \n","            # input image들의 size가 각각 다 다르기 때문에 같은 size로 resize 해줘야 함\n","            # if not, 하나의 batch로 묶어서 array 만들기 불가\n","            image = cv2.resize(image, (self.image_size, self.image_size))\n","            \n","            # rescale : 0~255 px -> 0~1\n","            image = image / 255.\n","            \n","            # 개와 고양이를 분류하는 이진분류\n","            # 현재 데이터 : 고양이 1, 개 2 -> -1 -> 고양이 0, 개 1\n","            label = int(r['species']) - 1\n","            \n","            batch_x.append(image)\n","            batch_y.append(label)\n","            \n","        return batch_x, batch_y\n","            \n","    # callback 함수\n","    # 매 epoch이 끝날 때마다 도는 함수\n","    # ex) shuffle 하는 함수를 넣으면 한 epoch이 끝날 때마다 데이터 자동 shuffle\n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            # frac : 몇 퍼센트의 데이터를 shuffle 할지 (1 -> 100% : 전체 데이터)\n","            # drop=True : 기존 인덱스를 버리고 재배열\n","            self.df = self.df.sample(frac=1).reset_index(drop=True)"],"metadata":{"id":"gmI7Sc3CGZVZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["csv_path = 'kfolds.csv'\n","train_generator = DataGenerator(\n","    batch_size=9,\n","    csv_path=csv_path,\n","    fold=1,\n","    image_size=256,  # 256×256\n","    mode='train',\n","    shuffle=True\n",")"],"metadata":{"id":"SjRY-MP-GZXU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["데이터 개수 확인\n","- 전체 데이터 : 7,390개\n","- 5-fold + train mode -> 전체 데이터의 80% 정도가 있어야 함 (5.8천 여 개)"],"metadata":{"id":"ZtsWFdWSGZZ5"}},{"cell_type":"code","source":["print(len(train_generator))\n","print(len(train_generator) * 9)   # 9 : batch size"],"metadata":{"id":"4It9yWZ8Gnws"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["data generator가 이미지를 제대로 load 하는 지 확인"],"metadata":{"id":"9lhxItsqGnzE"}},{"cell_type":"code","source":["class_name = ['Cat', 'Dog']  # 고양이 0, 강아지 1\n","\n","for batch in train_generator:\n","    # X: image, y: label\n","    X, y = batch\n","    plt.figure(figsize=(10, 10))\n","    \n","    for i in range(9):   # batch size가 9개 였으니 9개 이미지 살펴볼 예정\n","        ax = plt.subplot(3, 3, i+1)   # 총 3*3개 plot, i+1 번째에 그리기\n","        plt.imshow(X[i])\n","        plt.title(class_name[y[i]])\n","        plt.axis('off')\n","    \n","    # 첫 번째 batch만 확인할 예정\n","    break"],"metadata":{"id":"p_O65JsqGn1h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for batch in train_generator:\n","    # X: image, y: label\n","    X, y = batch\n","    print(y)\n","    break"],"metadata":{"id":"_2Wnl3wFGn3z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","# Model 구현"],"metadata":{"id":"cI63hNv4Gn6R"}},{"cell_type":"markdown","source":["### Sequential 모델 구현\n","\n","- simple한 모델들만 구현 가능\n","- sequential class 단독으로 사용하기 보단, model의 block 단위를 간단하게 구현할 때 사용"],"metadata":{"id":"fM6Sqnk1Gn8g"}},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import activations\n","\n","import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '1'"],"metadata":{"id":"WsWdyTaEGn-1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_sequential_model(input_shape):\n","    \n","    # layer를 순서대로 쌓기\n","    model = keras.Sequential(\n","        [\n","            layers.Input(input_shape),  # input\n","            \n","            # 1st Conv block\n","            # convolution을 적용하면 image size가 2px 씩 작아짐\n","            # 여러 번 거치면 완전 작아짐\n","            # 이를 방지하기 위해 padding 사용 (same : input과 output의 크기가 일치)\n","            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),  # filter size 64, kerner size 3*3\n","            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n","            layers.MaxPool2D(),\n","            layers.BatchNormalization(),\n","            layers.Dropout(0.5),\n","            \n","            # CNN에서 많이 쓰이는 heuristic\n","            # MaxPooling 거쳐서 이미지 사이즈가 반으로 감소\n","            # 그만큼 다음 layer에서 filter 사이즈를 키움 (64 -> 128)\n","            # VGG 때부터 많이 쓰인 방식\n","            \n","            # 2nd Conv block\n","            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n","            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n","            layers.MaxPool2D(),\n","            layers.BatchNormalization(),\n","            layers.Dropout(0.3),\n","            \n","            # MaxPooling\n","            # - 각각의 filter에 대해 주어진 kernel 안에서 최대값 return -> kernel 사이즈가 작아짐\n","            # GlobalMaxPooling\n","            # - 한 필터에서 하나의 값 가져옴 -> 128개의 필더가 있으면 총 128개 값 return\n","            #   각 필터의 대표값을 뽑을 수 있고 parameter 수가 감소하니 연산속도 빨라짐\n","            \n","            # Classifier\n","            layers.GlobalMaxPool2D(),\n","            layers.Dense(128, activation='relu'),\n","            layers.Dense(1, activation='sigmoid')  # 이진분류 (개, 고양이)            \n","        ]\n","    )\n","    \n","    return model\n","\n","input_shape = (256, 256, 3)\n","model = get_sequential_model(input_shape)\n","\n","model.summary()"],"metadata":{"id":"PZ70QeXbGZcZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Functional API 모델 구현\n","\n","- keras 공식 모델이 저장되어 있는 keras applications에 있는 모델들\n","- Sequential과 달리 multi input/output, layer sharing 등 특별한 제약 없이 다양한 기능 사용 가능"],"metadata":{"id":"Xy2ApJfuG0ER"}},{"cell_type":"code","source":["def get_functional_model(input_shape):\n","    \n","    # Sequential과 달리 사용자가 직접 모든 layer의\n","    # 결과를 저장하고 다음 레이어에 넘겨줘야 함\n","    inputs = keras.Input(input_shape)\n","    \n","    # 1st Conv block\n","    x = layers.Conv2D(64, 3, strides=1, activation='relu', padding='same')(inputs)\n","    x = layers.Conv2D(64, 3, strides=1, activation='relu', padding='same')(x)\n","    x = layers.MaxPool2D()(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Dropout(0.5)(x)\n","\n","    # 2nd Conv block\n","    x = layers.Conv2D(128, 3, strides=1, activation='relu', padding='same')(x)\n","    x = layers.Conv2D(128, 3, strides=1, activation='relu', padding='same')(x)\n","    x = layers.MaxPool2D()(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Dropout(0.3)(x)\n","\n","    # Classifier\n","    x = layers.GlobalMaxPool2D()(x)\n","    x = layers.Dense(128, activation='relu')(x)\n","    outputs = layers.Dense(1, activation='sigmoid')(x)  # 이진분류 (개, 고양이)\n","    \n","    model = keras.Model(inputs, outputs)\n","    \n","    return model\n","\n","input_shape = (256, 256, 3)\n","model = get_functional_model(input_shape)\n","\n","model.summary()"],"metadata":{"id":"QERLWd59G0J-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Subclassing\n","\n","- pytorch 경험자들은 이 방법이 가장 수월할 듯\n","- keras의 model class를 상속받아서 필요한 method를 override\n","  - functional API와 달리, model.fit, model.evaluate, model.predict를 override 해서 customize 가능\n","  - override 할 필요가 없는 경우 굳이 model subclassing보다는 functional API 사용하는 것으로 충분"],"metadata":{"id":"N00zsok7G0MI"}},{"cell_type":"code","source":["class SimpleCNN(keras.Model):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        \n","        # keras에서는 하나의 block을 하나의 layer로 생각함\n","        # -> 모델에는 3가지 layer만 있는 것처럼 인지됨\n","        # -> 나중에 model.summary() 해보면 결과가 다른 모델 대비 간단한 이유\n","        self.conv_block_1 = keras.Sequential(\n","            [\n","                layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n","                layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n","                layers.MaxPool2D(),\n","                layers.BatchNormalization(),\n","                layers.Dropout(0.5)          \n","            ], name='conv_block_1'\n","        )\n","        \n","        self.conv_block_2 = keras.Sequential(\n","            [\n","                layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n","                layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n","                layers.MaxPool2D(),\n","                layers.BatchNormalization(),\n","                layers.Dropout(0.3)\n","            ], name='conv_block_2'\n","        )\n","        \n","        self.classifier = keras.Sequential(\n","            [\n","                layers.GlobalMaxPool2D(),\n","                layers.Dense(128, activation='relu'),\n","                layers.Dense(1, activation='sigmoid')  # 이진분류 (개, 고양이)                   \n","            ], name='classifier'\n","        )\n","    \n","    # 모델 호출 시 작동할 함수\n","    # 위에서 작성한 layer들이 어떤 순서로 불려야 하는지 모델 순서 정하기\n","    def call(self, input_tensor, training=False):\n","        x = self.conv_block_1(input_tensor)\n","        x = self.conv_block_2(x)\n","        x = self.classifier(x)\n","        return x"],"metadata":{"id":"as_-HEyHG0OV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# None : batch axis 부분\n","# -> batch 값은 모델의 구조를 정하는데 중요하지 않아 일반적으로 적용\n","input_shape = (None, 256, 256, 3)\n","\n","model = SimpleCNN()\n","model.build(input_shape)\n","model.summary()"],"metadata":{"id":"Cozf7xhgG0Q3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model compiling\n","\n","- keras에서 학습에 사용할 optimizer, loss, 평가에 사용할 metric을 정해주는 과정"],"metadata":{"id":"LL6hmrWPG0TG"}},{"cell_type":"code","source":["model.compile(\n","    optimizer='adam',\n","    loss='binary_crossentropy',\n","    metrics='accuracy'\n",")"],"metadata":{"id":"vbCc8sxxG_Ki"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","# Summary"],"metadata":{"id":"tWXuM1D1G_M9"}},{"cell_type":"code","source":["import os\n","import math\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import activations\n","\n","os.environ['CUDA_VISIBLE_DEVICES'] = '1'"],"metadata":{"id":"iCk1XaeIG_Pb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_sequential_model(input_shape):\n","    model = keras.Sequential(\n","        [\n","            # Input\n","            layers.Input(input_shape),\n","\n","            # 1st Conv block\n","            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n","            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n","            layers.MaxPool2D(),\n","            layers.BatchNormalization(),\n","            layers.Dropout(0.5),\n","\n","            # 2nd Conv block\n","            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n","            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n","            layers.MaxPool2D(),\n","            layers.BatchNormalization(),\n","            layers.Dropout(0.3),\n","        \n","            # Classfier\n","            layers.GlobalMaxPool2D(),\n","            layers.Dense(128, activation='relu'),\n","            layers.Dense(1, activation='sigmoid')\n","        ]\n","    )\n","\n","    return model\n","\n","input_shape = (256, 256, 3)\n","model = get_sequential_model(input_shape)\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='binary_crossentropy',\n","    metrics='accuracy'\n",")\n","\n","model.summary()"],"metadata":{"id":"9wjAdYrKG_Rp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataGenerator(keras.utils.Sequence):\n","    def __init__(self, batch_size, csv_path, image_size,\n","                 fold, mode='train', shuffle=True):\n","        self.batch_size = batch_size\n","        self.image_size = image_size\n","        self.shuffle = shuffle\n","        self.fold = fold\n","        self.mode = mode\n","        \n","        self.df = pd.read_csv(csv_path)\n","        \n","        if self.mode == 'train':\n","            self.df = self.df[self.df['fold'] != self.fold]\n","        elif self.mode == 'val':\n","            self.df = self.df[self.df['fold'] == self.fold]\n","        \n","        #### Remove invalid files\n","        #### https://github.com/tensorflow/models/issues/3134\n","        invalid_filenames = [\n","            'Egyptian_Mau_14',\n","            'Egyptian_Mau_139',\n","            'Egyptian_Mau_145',\n","            'Egyptian_Mau_156',\n","            'Egyptian_Mau_167',\n","            'Egyptian_Mau_177',\n","            'Egyptian_Mau_186',\n","            'Egyptian_Mau_191',\n","            'Abyssinian_5',\n","            'Abyssinian_34',\n","            'chihuahua_121',\n","            'beagle_116'\n","        ]\n","        self.df = self.df[~self.df['file_name']. \\\n","                          isin(invalid_filenames)]\n","        self.on_epoch_end()\n","            \n","    def __len__(self):\n","        return math.ceil(len(self.df) / self.batch_size)\n","        \n","    def __getitem__(self, idx):\n","        strt = idx * self.batch_size\n","        fin = (idx + 1) * self.batch_size\n","        data = self.df.iloc[strt:fin]\n","        \n","        batch_x, batch_y = self.get_data(data)\n","        \n","        return np.array(batch_x), np.array(batch_y)\n","        \n","    def get_data(self, data):\n","        batch_x = []\n","        batch_y = []\n","        \n","        for _, r in data.iterrows():\n","            file_name = r['file_name']\n","            \n","            image = cv2.imread(f'drive/MyDrive/data/images/{file_name}.jpg')\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            \n","            image = cv2.resize(image, (self.image_size, self.image_size))\n","            image = image / 255.\n","            \n","            label = int(r['species']) - 1\n","            \n","            batch_x.append(image)\n","            batch_y.append(label)\n","        \n","        return batch_x, batch_y\n","\n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            self.df = self.df.sample(frac=1).reset_index(drop=True)"],"metadata":{"id":"N59-73gJG_UI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["csv_path = 'kfolds.csv'\n","\n","train_generator = DataGenerator(\n","    fold=1,\n","    mode='train',\n","    csv_path=csv_path,\n","    batch_size=128,\n","    image_size=256,\n","    shuffle=True\n",")\n","\n","valid_generator = DataGenerator(\n","    fold=1,\n","    mode='val',\n","    csv_path=csv_path,\n","    batch_size=128,\n","    image_size=256,\n","    shuffle=True\n",")"],"metadata":{"id":"K1lKF0HyGZel"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Callback functions\n","\n","- 특정 상황에서 호출된 함수\n","  - on_train_begin : 학습이 시작될 때 호출\n","  - on_epoch_end : 매 epoch이 끝날 때마다 호출\n","- 아래에서 자주 쓰이는 callback 함수 3가지를 보고자 함\n","- 만약 early stopping (patience: 3)과 reduce on plateau (patience: 10)를 같이 쓰면, 어차피 3일 때 early stopping이 될 것이기 때문에 실제로 reduce on plateau가 불리는 일은 없음"],"metadata":{"id":"InyGD1fWHGta"}},{"cell_type":"markdown","source":["### Early Stopping\n","\n","- 성능이 나아지지 않으면 학습 중단\n","- 아래 코드 : validation loss가 3 epoch 동안 줄어들지(min) 않으면 학습 멈추기"],"metadata":{"id":"gUtsZVQUHGwS"}},{"cell_type":"code","source":["early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=3,\n","    verbose=1,\n","    mode=\"min\",\n","    restore_best_weights=False\n",")"],"metadata":{"id":"y3HTw4F6HG2n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Reduce on plateau\n","\n","- 지정한 epoch동안 지정한 metric 성능이 나아지지 않으면 learning rate를 줄임\n","- 아래 코드\n","  - validation loss이 10 epoch 동안 작아지지 않으면 learning rate를 0.1배로 줄이자\n","  - 하지만 learning rate는 0.001보다는 작아지면 안 된다"],"metadata":{"id":"MSD1tE-IHG5H"}},{"cell_type":"code","source":["reduce_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n","    monitor='val_loss',\n","    factor=0.1,\n","    patience=10,\n","    verbose=1,\n","    mode='min',\n","    min_lr=0.001\n",")"],"metadata":{"id":"8JMTaAwxGZg5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 모델 저장"],"metadata":{"id":"z4QWr9zaHODH"}},{"cell_type":"code","source":["filepath = 'drive/MyDrive/data/{epoch:02d}-{val_loss:.2f}.hdf5'\n","\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","    filepath,\n","    monitor='val_loss',  # validation loss가 작아질 때마다 저장\n","    verbose=1,\n","    save_best_only=True,     # best 외 불필요한 건 저장X\n","    save_weights_only=False, # weight 파일만 따로 저장할지\n","    mode='min'\n",")"],"metadata":{"id":"bgSQqaHVHOF-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(\n","    train_generator,\n","    validation_data=valid_generator,\n","    epochs=10,\n","    callbacks=[\n","        early_stopping,\n","        reduce_on_plateau,\n","        model_checkpoint\n","    ],\n","    verbose=1\n",")"],"metadata":{"id":"cXTfqWwYHOI1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- training/validation의 loss, accuracy 확인"],"metadata":{"id":"tIUpwvV3GZjc"}},{"cell_type":"code","source":["history.history"],"metadata":{"id":"CictSXIvH9a_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 시각화"],"metadata":{"id":"-Tip0SQaH9dX"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","history = history.history\n","\n","plt.figure(figsize=(15, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(history['loss'], label='train')\n","plt.plot(history['val_loss'], label='val')\n","plt.legend()\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.title(\"Loss\")\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history['accuracy'], label='train')\n","plt.plot(history['val_accuracy'], label='val')\n","plt.legend()\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.title(\"Accuracy\")\n","plt.show()"],"metadata":{"id":"m1PbRVV9H9fx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","# Data Augmentation\n","\n","- 데이터 양을 늘리기 위해 원본 이미지를 여러 가지 방식으로 변환하는 것\n","- 결함이 있는 데이터에 대해서도 robust한 모델을 만들기 위함\n","- 3rd party library 사용함\n","  - 많은 사람들이 사용하는 것 추천 - Albumentations : made by kaggle masters"],"metadata":{"id":"Ew-YcuncH9ih"}},{"cell_type":"markdown","source":["- 이 코드로 albumentations install 하니까 CoarseDropout을 인지하지 못하는 문제는 사라졌지만 cv2가 import되지 않는 문제 발생\n","- cv2를 uninstall 했다가 다시 install 하니까 모든 문제 해결됨"],"metadata":{"id":"WXJfnlVPVvQE"}},{"cell_type":"code","source":["pip install git+https://github.com/albumentations-team/albumentations.git"],"metadata":{"id":"UKR8Wu8qICW6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip uninstall opencv-python"],"metadata":{"id":"zBIBjyXRu-uZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install opencv-python"],"metadata":{"id":"tfBIXL4jvQ-n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import math\n","import random\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import activations\n","\n","import albumentations as A\n","\n","os.environ['CUDA_VISIBLE_DEVICES'] = '1'"],"metadata":{"id":"O4QsFVLmDQKO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# augmentation : 보통 training단계에서 많이 사용됨\n","\n","class Augmentation:\n","    def __init__(self, size, mode='train'):\n","        if mode == 'train':\n","            # Declare an augmentation pipeline\n","            # 여러 번 호출할 예정이라 transform이 아닌 self.transform으로 저장함\n","            self.transform = A.Compose([\n","                # A.RandomCrop(width=256, height=256),  # resize를 외부에서 따로 할 예정\n","                \n","                # 좌우반전 (test 이미지에서 상하반전은 별로 없지만 좌우반전된 이미지는 많이 있을 것 같아서 추가함)\n","                # p : 해당 변화를 적용할 확률\n","                A.HorizontalFlip(p=0.5),\n","\n","                # Shift : 이미지를 상하좌우로 움직이는 것\n","                # Scale : 이미지를 확대/축소하는 것\n","                # Rotate : 이미지를 회전하는 것\n","                A.ShiftScaleRotate(\n","                    p=0.5,\n","                    shift_limit=0.05,  # 이미지의 가로 길이가 최대 몇% 넘어가도 되는 지\n","                    scale_limit=0.05,  # 이미지를 최대 몇% 확대/축소할지\n","                    rotate_limit=15,\n","                ),\n","\n","                # 이미지에 구멍을 뚫는 것\n","                A.CoarseDropout(\n","                    p=0.5,\n","                    max_holes=8,  # 최대 구멍 개수\n","                    max_height=int(0.1 * size),  # 가로 최대 길이 : 이미지의 10%\n","                    max_width=int(0.1 * size),\n","                ),\n","\n","                A.RandomBrightnessContrast(p=0.2),\n","            ])\n","\n","    def __call__(self, **kwargs):\n","        if self.transform:   # train mode인 경우\n","            augmented = self.transform(**kwargs)\n","            img = augmented['image']\n","            return img"],"metadata":{"id":"czVqSStmDVzW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- DataGenerator 코드에 Augmentation 코드 추가하기"],"metadata":{"id":"xnE_GFpaDZ-q"}},{"cell_type":"code","source":["class DataGenerator(keras.utils.Sequence):\n","    def __init__(self, batch_size, csv_path, image_size,\n","                 fold, mode='train', shuffle=True):\n","        self.batch_size = batch_size\n","        self.image_size = image_size\n","        self.shuffle = shuffle\n","        self.fold = fold\n","        self.mode = mode\n","        \n","        self.df = pd.read_csv(csv_path)\n","        \n","        if self.mode == 'train':\n","            self.df = self.df[self.df['fold'] != self.fold]\n","        elif self.mode == 'val':\n","            self.df = self.df[self.df['fold'] == self.fold]\n","        \n","        #### Remove invalid files\n","        #### https://github.com/tensorflow/models/issues/3134\n","        invalid_filenames = [\n","            'Egyptian_Mau_14',\n","            'Egyptian_Mau_139',\n","            'Egyptian_Mau_145',\n","            'Egyptian_Mau_156',\n","            'Egyptian_Mau_167',\n","            'Egyptian_Mau_177',\n","            'Egyptian_Mau_186',\n","            'Egyptian_Mau_191',\n","            'Abyssinian_5',\n","            'Abyssinian_34',\n","            'chihuahua_121',\n","            'beagle_116'\n","        ]\n","        self.df = self.df[~self.df['file_name']. \\\n","                          isin(invalid_filenames)]\n","\n","        self.transform = Augmentation(image_size, mode)  ##########\n","\n","        self.on_epoch_end()\n","            \n","    def __len__(self):\n","        return math.ceil(len(self.df) / self.batch_size)\n","        \n","    def __getitem__(self, idx):\n","        strt = idx * self.batch_size\n","        fin = (idx + 1) * self.batch_size\n","        data = self.df.iloc[strt:fin]\n","        \n","        batch_x, batch_y = self.get_data(data)\n","        \n","        return np.array(batch_x), np.array(batch_y)\n","        \n","    def get_data(self, data):\n","        batch_x = []\n","        batch_y = []\n","        \n","        for _, r in data.iterrows():\n","            file_name = r['file_name']\n","            \n","            image = cv2.imread(f'drive/MyDrive/data/images/{file_name}.jpg')\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            \n","            image = cv2.resize(image, (self.image_size, self.image_size))\n","\n","            if self.mode == 'train':   ##########\n","                # augmentation 중에는 image가 uint8인 경우에만 적용되는 것들이 있음\n","                # -> image를 먼저 uint8로 변환하기\n","                image = image.astype('uint8')\n","                image = self.transform(image=image)\n","\n","            image = image.astype('float32')\n","            image = image / 255.\n","            \n","            label = int(r['species']) - 1\n","            \n","            batch_x.append(image)\n","            batch_y.append(label)\n","        \n","        return batch_x, batch_y\n","\n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            self.df = self.df.sample(frac=1).reset_index(drop=True)"],"metadata":{"id":"xKYjv4szDaDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["csv_path = 'kfolds.csv'\n","\n","train_generator =  DataGenerator(\n","    fold=1,\n","    mode='train',\n","    csv_path=csv_path,\n","    batch_size=128,\n","    image_size=256,\n","    shuffle=True\n",")\n","\n","valid_generator =  DataGenerator(\n","    fold=1,\n","    mode='val',\n","    csv_path=csv_path,\n","    batch_size=128,\n","    image_size=256,\n","    shuffle=True\n",")"],"metadata":{"id":"V8gFXspuDaFl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- CoarseDropout이 적용된 결과 0.5%의 확률로 특정 이미지에 hole들이 뚫려있음\n","- 랜덤하게 적용되기 때문에 아래 코드 다시 돌려보면 CoarseDropout 적용된 이미지가 계속 달라짐\n","- 회전된 이미지도 볼 수 있음"],"metadata":{"id":"EW0YiwVrTrNi"}},{"cell_type":"code","source":["class_name = ['Cat', 'Dog']\n","\n","for batch in train_generator:\n","    X, y = batch\n","    plt.figure(figsize=(10,10))\n","\n","    for i in range(9):\n","        ax = plt.subplot(3, 3, i+1)\n","        plt.imshow(X[i])\n","        plt.title(class_name[y[i]])\n","        plt.axis('off')\n","    break"],"metadata":{"id":"Juc9k7WfQsgm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 학습에 적용"],"metadata":{"id":"OhvvA_srSc4v"}},{"cell_type":"code","source":["def get_sequential_model(input_shape):\n","    model = keras.Sequential(\n","        [\n","            # Input\n","            layers.Input(input_shape),\n","\n","            # 1st Conv block\n","            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n","            layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n","            layers.MaxPool2D(),\n","            layers.BatchNormalization(),\n","            layers.Dropout(0.5),\n","\n","            # 2nd Conv block\n","            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n","            layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n","            layers.MaxPool2D(),\n","            layers.BatchNormalization(),\n","            layers.Dropout(0.3),\n","        \n","            # Classfier\n","            layers.GlobalMaxPool2D(),\n","            layers.Dense(128, activation='relu'),\n","            layers.Dense(1, activation='sigmoid')\n","        ]\n","    )\n","\n","    return model\n","\n","input_shape = (256, 256, 3)\n","model = get_sequential_model(input_shape)\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='binary_crossentropy',\n","    metrics='accuracy'\n",")\n","\n","model.summary()"],"metadata":{"id":"0kwM3sg-Sc7d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(\n","    train_generator,\n","    validation_data=valid_generator,\n","    epochs=10,\n","    verbose=1\n",")"],"metadata":{"id":"6kD2rZPMSdDk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","# Transfer Learning\n","\n","- 배경\n","  - dataset의 고양이와 개 비율 = 2:5\n","    - 모든 data를 강아지로 찍으면 성능이 70% 정도\n","  - 위에서 만든 모델의 성능 : validation data 70% accuracy\n","  - 즉, 모델 학습을 했음에도 불구하고 찍었을 때와 큰 차이가 없음\n","  - 그냥 학습을 했을 때와 data augmentation 적용했을 때도 최종 모델 성능 차이가 거의 없었음\n","  - 모델 바꿀 필요 있음 -> Transfer Learning\n","- Transfer Learning\n","  - 특정 분야에서 학습된 모델을 유사하거나 전혀 새로운 분야에 사용하는 것\n","    - 수십만 장의 image 학습하고 유의미한 feature 추출\n","    - 이를 oxford pet data 분류에 사용\n","  - 학습데이터가 적을 때 유용 + 학습 속도, 최종 결과도 모두 좋음 -> 항상 모델을 pre train 하는 것 추천\n","- pre trained된 모델을 가져올 수 있는 곳\n","  - https://github.com/keras-team/keras-applications\n","  - https://keras.io/api/applications/\n","  - VGG, ResNet, EfficientNet, etc.\n","  - 이 중 image net 분류에 대해 성능(Top-1 accuracy 부분)이 좋게 적혀 있는 모델일수록 내가 하려는 task에 쓸 때도 성능이 좋음\n","  - 주의 : 모델의 Size가 클수록 학습속도 느림\n","    - 느려도 상관 없는지 vs real-time이 중요한지\n","  - accuracy와 size의 trade off 잘 고려해서 선택할 것"],"metadata":{"id":"OkWUvFWzSdF6"}},{"cell_type":"code","source":["import os\n","import math\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import activations\n","from tensorflow.keras.applications import EfficientNetB0\n","\n","import albumentations as A\n","\n","os.environ['CUDA_VISIBLE_DEVICES'] = '1'"],"metadata":{"id":"FFqriBRdoytK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### EfficientNet\n","\n","- 모델을 불러서 내가 사용하려는 것에 맞게 변환하기\n","- `model.summary()` 결과\n","  - efficientnetb0가 하나의 layer처럼 사용됨\n","  - 위에 쓴 모델은 parameter 수가 27만 개 정도 됐는데 parameter 수도 훨씬 많아짐 (400만)\n","  - 마지막 dense : 실제 분류하는 layer"],"metadata":{"id":"eNfAHw-TrV16"}},{"cell_type":"code","source":["def get_model(input_shape):\n","\n","    inputs = keras.Input(input_shape)\n","\n","    # Feature extract\n","    base_model = EfficientNetB0(\n","        input_shape=input_shape,\n","\n","        # 만약 아무 것도 안 쓰면 transfer을 사용하는 게 아니라 모델 구현체만 가져다 학습에사용하겠다는 의미\n","        weights='imagenet',   # imagenet의 pre trained된 weight값 사용\n","        \n","        # github 링크에서 모델 코드 보면 if include_top: 부분이 있음\n","        # 해당 모델이 image를 분류하기 위해 사용한 layer들\n","        # = image에서 feature를 추출하는 layer 외에 그 feature를 가지고 분류하는 layer 부분임\n","        # = 내가 사용하려는 task랑 크게 관련은 없음 + 무거움\n","        # -> 이걸 가져다 쓰지 않고 (False) 내 task에 맞게 따로 구현하고자 함\n","        include_top=False,\n","\n","        pooling='avg'  # Gloabl average pooling\n","    )\n","\n","    x = base_model(inputs)  # image의 feature 추출\n","    outputs = layers.Dense(1, activation='sigmoid')(x)  # 이진분류\n","    model = keras.Model(inputs, outputs)\n","\n","    return model\n","\n","input_shape = (256, 256, 3)\n","model = get_model(input_shape)\n","\n","# Transfer learning 할 때는 보통 사용하는 learning rate(0.001)보다 작은 값 사용\n","adam = keras.optimizers.Adam(lr=0.0001)\n","\n","model.compile(\n","    optimizer=adam,\n","    loss='binary_crossentropy',\n","    metrics='accuracy'\n",")\n","\n","model.summary()"],"metadata":{"id":"iwUd_3Ilo2SC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Augmentation:\n","    def __init__(self, size, mode='train'):\n","        if mode == 'train':\n","            self.transform = A.Compose([\n","                A.HorizontalFlip(p=0.5),\n","                A.ShiftScaleRotate(\n","                    p=0.5,\n","                    shift_limit=0.05,  # 이미지의 가로 길이가 최대 몇% 넘어가도 되는 지\n","                    scale_limit=0.05,  # 이미지를 최대 몇% 확대/축소할지\n","                    rotate_limit=15,\n","                ),\n","\n","                # 이미지에 구멍을 뚫는 것\n","                A.CoarseDropout(\n","                    p=0.5,\n","                    max_holes=8,  # 최대 구멍 개수\n","                    max_height=int(0.1 * size),  # 가로 최대 길이 : 이미지의 10%\n","                    max_width=int(0.1 * size),\n","                ),\n","\n","                A.RandomBrightnessContrast(p=0.2),\n","            ])\n","\n","    def __call__(self, **kwargs):\n","        if self.transform:   # train mode인 경우\n","            augmented = self.transform(**kwargs)\n","            img = augmented['image']\n","            return img"],"metadata":{"id":"UaNW_2gvo2U7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataGenerator(keras.utils.Sequence):\n","    def __init__(self, batch_size, csv_path, image_size,\n","                 fold, mode='train', shuffle=True):\n","        self.batch_size = batch_size\n","        self.image_size = image_size\n","        self.shuffle = shuffle\n","        self.fold = fold\n","        self.mode = mode\n","        \n","        self.df = pd.read_csv(csv_path)\n","        \n","        if self.mode == 'train':\n","            self.df = self.df[self.df['fold'] != self.fold]\n","        elif self.mode == 'val':\n","            self.df = self.df[self.df['fold'] == self.fold]\n","        \n","        #### Remove invalid files\n","        #### https://github.com/tensorflow/models/issues/3134\n","        invalid_filenames = [\n","            'Egyptian_Mau_14',\n","            'Egyptian_Mau_139',\n","            'Egyptian_Mau_145',\n","            'Egyptian_Mau_156',\n","            'Egyptian_Mau_167',\n","            'Egyptian_Mau_177',\n","            'Egyptian_Mau_186',\n","            'Egyptian_Mau_191',\n","            'Abyssinian_5',\n","            'Abyssinian_34',\n","            'chihuahua_121',\n","            'beagle_116'\n","        ]\n","        self.df = self.df[~self.df['file_name']. \\\n","                          isin(invalid_filenames)]\n","\n","        self.transform = Augmentation(image_size, mode)\n","\n","        self.on_epoch_end()\n","            \n","    def __len__(self):\n","        return math.ceil(len(self.df) / self.batch_size)\n","        \n","    def __getitem__(self, idx):\n","        strt = idx * self.batch_size\n","        fin = (idx + 1) * self.batch_size\n","        data = self.df.iloc[strt:fin]\n","        \n","        batch_x, batch_y = self.get_data(data)\n","        \n","        return np.array(batch_x), np.array(batch_y)\n","        \n","    def get_data(self, data):\n","        batch_x = []\n","        batch_y = []\n","        \n","        for _, r in data.iterrows():\n","            file_name = r['file_name']\n","            \n","            image = cv2.imread(f'drive/MyDrive/data/images/{file_name}.jpg')\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            \n","            image = cv2.resize(image, (self.image_size, self.image_size))\n","\n","            if self.mode == 'train':\n","                image = image.astype('uint8')\n","                image = self.transform(image=image)\n","\n","            image = image.astype('float32')\n","            image = image / 255.\n","            \n","            label = int(r['species']) - 1\n","            \n","            batch_x.append(image)\n","            batch_y.append(label)\n","        \n","        return batch_x, batch_y\n","\n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            self.df = self.df.sample(frac=1).reset_index(drop=True)"],"metadata":{"id":"LcU4PD3Fo2Xs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["csv_path = 'kfolds.csv'\n","\n","train_generator =  DataGenerator(\n","    fold=1,\n","    mode='train',\n","    csv_path=csv_path,\n","    batch_size=128,\n","    image_size=256,\n","    shuffle=True\n",")\n","\n","valid_generator =  DataGenerator(\n","    fold=1,\n","    mode='val',\n","    csv_path=csv_path,\n","    batch_size=128,\n","    image_size=256,\n","    shuffle=True\n",")"],"metadata":{"id":"l9RtuVnruoNB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 성능이 굉장히 좋아짐"],"metadata":{"id":"K7MreRyWwB95"}},{"cell_type":"code","source":["history = model.fit(\n","    train_generator,\n","    validation_data=valid_generator,\n","    epochs=10,\n","    verbose=1\n",")"],"metadata":{"id":"bKC3kH2ho2ap"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","history = history.history\n","\n","plt.figure(figsize=(15, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(history['loss'], label='train')\n","plt.plot(history['val_loss'], label='val')\n","plt.legend()\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.title(\"Loss\")\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history['accuracy'], label='train')\n","plt.plot(history['val_accuracy'], label='val')\n","plt.legend()\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.title(\"Accuracy\")\n","plt.show()"],"metadata":{"id":"1zdHsbtEoyv5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","# TF Hub\n","\n","- 배경\n","  - keras applications는 마지막 update가 몇 년 전\n","  - efficientNet 이후에 나온 모델들에 대해서는 update가 안 됨\n","- TF Hub\n","  - https://tfhub.dev/\n","  - tensorflow에서 공식적으로 운영\n","  - 최신 모델 (weight 포함) 지속 update 됨\n","  - keras에는 image만 있는 것과 달리 text, video, audio 모델까지 포함\n","- 방법\n","  - problem domains에서 image 클릭\n","  - filter 적용 : TF2 (version) + Finetunable 켜기\n","  - efficientNet v2 검색\n","    - efficientNet 이후에 나온 것\n","    - 이걸 사용해서 학습하면 많이 update가 되었기 때문에 편리함\n","  - 원하는 것 클릭 : imagenet/efficientnet_v2_imagenet1k_b0/feature_vector\n","    - 기존 모델들보다 성능 좋음\n","    - Usage 부분에 사용방법 코드 있음\n","    - 그대로 복사해서 가져오기"],"metadata":{"id":"LWqpL5Jzoy0Z"}},{"cell_type":"code","source":["import os\n","import math\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import activations\n","from tensorflow.keras.applications import EfficientNetB0\n","\n","import albumentations as A\n","\n","os.environ['CUDA_VISIBLE_DEVICES'] = '1'"],"metadata":{"id":"PorSQvA-oy3Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 가장 최신 모델이라고 할 수 있는 efficientnet_v2를 tensorflow hub에서 가져와서 내 task 학습에 적용"],"metadata":{"id":"qQT1xs_S34DS"}},{"cell_type":"code","source":["import tensorflow_hub as hub\n","\n","# Usage 코드\n","model = tf.keras.Sequential([\n","    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\",  # 기존 구현된 모델\n","                   trainable=True),  # base 모델도 학습이 가능하게 설정\n","    tf.keras.layers.Dense(1, activation='sigmoid')  # 내 모델의 classification layer 붙이기 (binary)\n","])\n","\n","model.build([None, 256, 256, 3])  # Batch input shape\n","\n","adam = keras.optimizers.Adam(lr=0.0001)\n","model.compile(\n","    optimizer=adam,\n","    loss='binary_crossentropy',\n","    metrics='accuracy'\n",")\n","\n","model.summary()"],"metadata":{"id":"kVVOkcuHyWnx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Augmentation:\n","    def __init__(self, size, mode='train'):\n","        if mode == 'train':\n","            self.transform = A.Compose([\n","                A.HorizontalFlip(p=0.5),\n","                A.ShiftScaleRotate(\n","                    p=0.5,\n","                    shift_limit=0.05,  # 이미지의 가로 길이가 최대 몇% 넘어가도 되는 지\n","                    scale_limit=0.05,  # 이미지를 최대 몇% 확대/축소할지\n","                    rotate_limit=15,\n","                ),\n","\n","                # 이미지에 구멍을 뚫는 것\n","                A.CoarseDropout(\n","                    p=0.5,\n","                    max_holes=8,  # 최대 구멍 개수\n","                    max_height=int(0.1 * size),  # 가로 최대 길이 : 이미지의 10%\n","                    max_width=int(0.1 * size),\n","                ),\n","\n","                A.RandomBrightnessContrast(p=0.2),\n","            ])\n","\n","    def __call__(self, **kwargs):\n","        if self.transform:   # train mode인 경우\n","            augmented = self.transform(**kwargs)\n","            img = augmented['image']\n","            return img"],"metadata":{"id":"WY8Ae6HVyWqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataGenerator(keras.utils.Sequence):\n","    def __init__(self, batch_size, csv_path, image_size,\n","                 fold, mode='train', shuffle=True):\n","        self.batch_size = batch_size\n","        self.image_size = image_size\n","        self.shuffle = shuffle\n","        self.fold = fold\n","        self.mode = mode\n","        \n","        self.df = pd.read_csv(csv_path)\n","        \n","        if self.mode == 'train':\n","            self.df = self.df[self.df['fold'] != self.fold]\n","        elif self.mode == 'val':\n","            self.df = self.df[self.df['fold'] == self.fold]\n","        \n","        #### Remove invalid files\n","        #### https://github.com/tensorflow/models/issues/3134\n","        invalid_filenames = [\n","            'Egyptian_Mau_14',\n","            'Egyptian_Mau_139',\n","            'Egyptian_Mau_145',\n","            'Egyptian_Mau_156',\n","            'Egyptian_Mau_167',\n","            'Egyptian_Mau_177',\n","            'Egyptian_Mau_186',\n","            'Egyptian_Mau_191',\n","            'Abyssinian_5',\n","            'Abyssinian_34',\n","            'chihuahua_121',\n","            'beagle_116'\n","        ]\n","        self.df = self.df[~self.df['file_name']. \\\n","                          isin(invalid_filenames)]\n","\n","        self.transform = Augmentation(image_size, mode)\n","\n","        self.on_epoch_end()\n","            \n","    def __len__(self):\n","        return math.ceil(len(self.df) / self.batch_size)\n","        \n","    def __getitem__(self, idx):\n","        strt = idx * self.batch_size\n","        fin = (idx + 1) * self.batch_size\n","        data = self.df.iloc[strt:fin]\n","        \n","        batch_x, batch_y = self.get_data(data)\n","        \n","        return np.array(batch_x), np.array(batch_y)\n","        \n","    def get_data(self, data):\n","        batch_x = []\n","        batch_y = []\n","        \n","        for _, r in data.iterrows():\n","            file_name = r['file_name']\n","            \n","            image = cv2.imread(f'drive/MyDrive/data/images/{file_name}.jpg')\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            \n","            image = cv2.resize(image, (self.image_size, self.image_size))\n","\n","            if self.mode == 'train':\n","                image = image.astype('uint8')\n","                image = self.transform(image=image)\n","\n","            image = image.astype('float32')\n","            image = image / 255.\n","            \n","            label = int(r['species']) - 1\n","            \n","            batch_x.append(image)\n","            batch_y.append(label)\n","        \n","        return batch_x, batch_y\n","\n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            self.df = self.df.sample(frac=1).reset_index(drop=True)"],"metadata":{"id":"j9F1sjPdyWsq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 모델 사이즈가 커졌기 때문에 batch size를 절반 정도로 줄임"],"metadata":{"id":"c3EE0nDh4NAB"}},{"cell_type":"code","source":["csv_path = 'kfolds.csv'\n","\n","train_generator =  DataGenerator(\n","    fold=1,\n","    mode='train',\n","    csv_path=csv_path,\n","    batch_size=64,\n","    image_size=256,\n","    shuffle=True\n",")\n","\n","valid_generator =  DataGenerator(\n","    fold=1,\n","    mode='val',\n","    csv_path=csv_path,\n","    batch_size=64,\n","    image_size=256,\n","    shuffle=True\n",")"],"metadata":{"id":"rvUPjKVc4NZ3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- efficientNet v2가 차이가 없는 이유\n","  - 지금 우리가 사용하는 task가 비교적 쉬워서 성능 차이가 별로 없지만\n","  - 다른 이미지 분류에 사용하면 b0보다 v2가 성능이 좋음"],"metadata":{"id":"6qG_pw0L4cMv"}},{"cell_type":"code","source":["history = model.fit(\n","    train_generator,\n","    validation_data=valid_generator,\n","    epochs=10,\n","    verbose=1\n",")"],"metadata":{"id":"DuXNTjWz4Ncx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","history = history.history\n","\n","plt.figure(figsize=(15, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(history['loss'], label='train')\n","plt.plot(history['val_loss'], label='val')\n","plt.legend()\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.title(\"Loss\")\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history['accuracy'], label='train')\n","plt.plot(history['val_accuracy'], label='val')\n","plt.legend()\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.title(\"Accuracy\")\n","plt.show()"],"metadata":{"id":"zoWwdTBK4Nnn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","# Multiclass Classification\n","\n","- Oxford pet dataset\n","  - 총 37 종류의 개와 고양이를 구분하는 label 있음 (ID 컬럼)\n","- 해결책은 이진분류와 크게 다르지 않음\n","  - 위에서 사용한 efficientNet B0 코드를 그대로 활용하고자 함"],"metadata":{"id":"RTjpjYUm4uA8"}},{"cell_type":"code","source":["import os\n","import math\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import activations\n","from tensorflow.keras.applications import EfficientNetB0\n","\n","import albumentations as A\n","\n","os.environ['CUDA_VISIBLE_DEVICES'] = '1'"],"metadata":{"id":"XjKIcMCB4uD8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 각 class에 속하는 data는 200개 씩 균등하게 분포되어 있음"],"metadata":{"id":"IE6EcbDq9kpw"}},{"cell_type":"code","source":["csv_path = 'kfolds.csv'\n","df = pd.read_csv(csv_path)\n","np.unique(df['id'])\n","\n","value_counts = df['id'].value_counts().sort_index()\n","\n","plt.figure(figsize=(10, 5))\n","plt.bar(range(len(value_counts)), value_counts.values)\n","plt.xticks(range(len(value_counts)), value_counts.index.values)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"yM8bQHWy8qGM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- multi-class classification에 맞게 binary classification 수정"],"metadata":{"id":"kvXj5FLF8qJR"}},{"cell_type":"code","source":["def get_model(input_shape):\n","\n","    inputs = keras.Input(input_shape)\n","\n","    # Feature extract\n","    base_model = EfficientNetB0(\n","        input_shape=input_shape,\n","        weights='imagenet',\n","        include_top=False,\n","        pooling='avg'\n","    )\n","\n","    x = base_model(inputs)\n","    # softmax : 각 class에 대한 확률\n","    outputs = layers.Dense(37, activation='softmax')(x)  # multi-class에 맞게 output, activation 변경\n","    model = keras.Model(inputs, outputs)\n","\n","    return model\n","\n","input_shape = (256, 256, 3)\n","model = get_model(input_shape)\n","\n","adam = keras.optimizers.Adam(lr=0.0001)\n","\n","model.compile(\n","    optimizer=adam,\n","    # 원래 ouput이 37개니까 이에 맞게 label도 one-hot encoding을 해 줘야 하지만\n","    # sparse_categorical_crossentropy를 사용하면 one-hot encoding 필요 없음\n","    # label index만 넘겨서 모델이 학습하게 하기 때문\n","    loss='sparse_categorical_crossentropy', # multi-class에 맞게 변경\n","    metrics='accuracy'\n",")\n","\n","model.summary()"],"metadata":{"id":"lR_AT-hk4uGX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Augmentation : 수정 필요 없음"],"metadata":{"id":"_Og0P9w14uJD"}},{"cell_type":"code","source":["class Augmentation:\n","    def __init__(self, size, mode='train'):\n","        if mode == 'train':\n","            self.transform = A.Compose([\n","                A.HorizontalFlip(p=0.5),\n","                A.ShiftScaleRotate(\n","                    p=0.5,\n","                    shift_limit=0.05,  # 이미지의 가로 길이가 최대 몇% 넘어가도 되는 지\n","                    scale_limit=0.05,  # 이미지를 최대 몇% 확대/축소할지\n","                    rotate_limit=15,\n","                ),\n","\n","                # 이미지에 구멍을 뚫는 것\n","                A.CoarseDropout(\n","                    p=0.5,\n","                    max_holes=8,  # 최대 구멍 개수\n","                    max_height=int(0.1 * size),  # 가로 최대 길이 : 이미지의 10%\n","                    max_width=int(0.1 * size),\n","                ),\n","\n","                A.RandomBrightnessContrast(p=0.2),\n","            ])\n","\n","    def __call__(self, **kwargs):\n","        if self.transform:   # train mode인 경우\n","            augmented = self.transform(**kwargs)\n","            img = augmented['image']\n","            return img"],"metadata":{"id":"Hbfo5zZX-Z-d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- DataGenerator 일부 수정 필요 : label을 return 하는 부분"],"metadata":{"id":"Qd4bI3cv-aBL"}},{"cell_type":"code","source":["class DataGenerator(keras.utils.Sequence):\n","    def __init__(self, batch_size, csv_path, image_size,\n","                 fold, mode='train', shuffle=True):\n","        self.batch_size = batch_size\n","        self.image_size = image_size\n","        self.shuffle = shuffle\n","        self.fold = fold\n","        self.mode = mode\n","        \n","        self.df = pd.read_csv(csv_path)\n","        \n","        if self.mode == 'train':\n","            self.df = self.df[self.df['fold'] != self.fold]\n","        elif self.mode == 'val':\n","            self.df = self.df[self.df['fold'] == self.fold]\n","        \n","        #### Remove invalid files\n","        #### https://github.com/tensorflow/models/issues/3134\n","        invalid_filenames = [\n","            'Egyptian_Mau_14',\n","            'Egyptian_Mau_139',\n","            'Egyptian_Mau_145',\n","            'Egyptian_Mau_156',\n","            'Egyptian_Mau_167',\n","            'Egyptian_Mau_177',\n","            'Egyptian_Mau_186',\n","            'Egyptian_Mau_191',\n","            'Abyssinian_5',\n","            'Abyssinian_34',\n","            'chihuahua_121',\n","            'beagle_116'\n","        ]\n","        self.df = self.df[~self.df['file_name']. \\\n","                          isin(invalid_filenames)]\n","\n","        self.transform = Augmentation(image_size, mode)\n","\n","        self.on_epoch_end()\n","            \n","    def __len__(self):\n","        return math.ceil(len(self.df) / self.batch_size)\n","        \n","    def __getitem__(self, idx):\n","        strt = idx * self.batch_size\n","        fin = (idx + 1) * self.batch_size\n","        data = self.df.iloc[strt:fin]\n","        \n","        batch_x, batch_y = self.get_data(data)\n","        \n","        return np.array(batch_x), np.array(batch_y)\n","        \n","    def get_data(self, data):\n","        batch_x = []\n","        batch_y = []\n","        \n","        for _, r in data.iterrows():\n","            file_name = r['file_name']\n","            \n","            image = cv2.imread(f'drive/MyDrive/data/images/{file_name}.jpg')\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            \n","            image = cv2.resize(image, (self.image_size, self.image_size))\n","\n","            if self.mode == 'train':\n","                image = image.astype('uint8')\n","                image = self.transform(image=image)\n","\n","            image = image.astype('float32')\n","            image = image / 255.\n","            \n","            # sparse_categorical_crossentropy를 사용하기 때문에\n","            # 따로 one-hot encoding 변환 없이 기존처럼 id의 index만 넘기면 됨\n","            # 1~37로 되어있으니 -1을 해서 0~36으로 변환\n","            label = int(r['id']) - 1  #####\n","            \n","            batch_x.append(image)\n","            batch_y.append(label)\n","        \n","        return batch_x, batch_y\n","\n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            self.df = self.df.sample(frac=1).reset_index(drop=True)"],"metadata":{"id":"_HNcdW7q-aDo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["csv_path = 'kfolds.csv'\n","\n","train_generator =  DataGenerator(\n","    fold=1,\n","    mode='train',\n","    csv_path=csv_path,\n","    batch_size=128,\n","    image_size=256,\n","    shuffle=True\n",")\n","\n","valid_generator =  DataGenerator(\n","    fold=1,\n","    mode='val',\n","    csv_path=csv_path,\n","    batch_size=128,\n","    image_size=256,\n","    shuffle=True\n",")"],"metadata":{"id":"_xgoAakz-aGN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 10 epoch로 학습했을 때 이진분류 때보다는 성능이 약간 낮음\n","- train과 validation 사이 차이도 커짐\n","- 그래도 매 epoch마다 train, validation 모두 accuracy가 증가하고 있기 때문에 epoch 개수를 늘리면 성능이 더 좋아질 가능성이 큼\n"],"metadata":{"id":"7Zhog7thAoAf"}},{"cell_type":"code","source":["history = model.fit(\n","    train_generator,\n","    validation_data=valid_generator,\n","    epochs=10,\n","    verbose=1\n",")"],"metadata":{"id":"qCdSM8xs_SID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","history = history.history\n","\n","plt.figure(figsize=(15, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(history['loss'], label='train')\n","plt.plot(history['val_loss'], label='val')\n","plt.legend()\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.title(\"Loss\")\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history['accuracy'], label='train')\n","plt.plot(history['val_accuracy'], label='val')\n","plt.legend()\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.title(\"Accuracy\")\n","plt.show()"],"metadata":{"id":"fybh-7Y-_SKj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"HVPE6vS8_SNF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"LxH9iRuw_SPv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Tj-bEL1g_SR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"NltpYjxT_SUM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"SRM7EG3I4uL2"},"execution_count":null,"outputs":[]}]}