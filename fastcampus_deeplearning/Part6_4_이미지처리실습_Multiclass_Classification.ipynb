{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part6_4_이미지처리실습_Multiclass Classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyy7lUL36GDH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from glob import glob\n",
        "\n",
        "import math\n",
        "import random \n",
        "\n",
        "import cv2                                 # image를 읽기 위한 open cv library\n",
        "import xml.etree.ElementTree as et         # xml 파일을 parsing 하기 위한 library\n",
        "from matplotlib.patches import Rectangle   # Bounding box를 그리기 위함\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "import albumentations as A    # CoarseDropout 인지 안 된다는 문제 발생 -> pip install 아래 세 가지 코드 실행 필요\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "drive_project_root = 'drive/MyDrive/data/'\n",
        "sys.path.append(drive_project_root)\n",
        "\n",
        "image_root = 'drive/MyDrive/data/images/'\n",
        "anno_root = 'drive/MyDrive/data/annotations/'\n",
        "\n",
        "image_dir = image_root\n",
        "bbox_dir = anno_root + 'xmls/'    # bounding box\n",
        "seg_dir = anno_root + 'trimaps/'  # segmentation map\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/albumentations-team/albumentations.git  # Data Agumentation"
      ],
      "metadata": {
        "id": "I0n79GEe6Ijn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall opencv-python"
      ],
      "metadata": {
        "id": "WAsz65Xc6Iqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python"
      ],
      "metadata": {
        "id": "H7SoslMC6I3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiclass Classification\n",
        "- Oxford pet dataset\n",
        "  - 총 37 종류의 개와 고양이를 구분하는 label 있음 (ID 컬럼)\n",
        "- 해결책은 이진분류와 크게 다르지 않음\n",
        "  - 위에서 사용한 efficientNet B0 코드를 그대로 활용하고자 함"
      ],
      "metadata": {
        "id": "3rnQaptD6I_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 각 class에 속하는 data는 200개 씩 균등하게 분포되어 있음"
      ],
      "metadata": {
        "id": "MwF95ACvb7-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = drive_project_root+'kfolds.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "print(np.unique(df['id']))\n",
        "value_counts = df['id'].value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(range(len(value_counts)), value_counts.values)\n",
        "plt.xticks(range(len(value_counts)), value_counts.index.values)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uoxuhBFw6JZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- multi-class classification에 맞게 binary classification 수정"
      ],
      "metadata": {
        "id": "KbiAbVLHcG-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(input_shape):\n",
        "\n",
        "    inputs = keras.Input(input_shape)\n",
        "\n",
        "    # Feature extract\n",
        "    base_model = EfficientNetB0(\n",
        "        input_shape=input_shape,\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        pooling='avg'\n",
        "    )\n",
        "\n",
        "    x = base_model(inputs)\n",
        "    # softmax : 각 class에 대한 확률\n",
        "    outputs = layers.Dense(37, activation='softmax')(x)  # multi-class에 맞게 output, activation 변경\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape = (256, 256, 3)\n",
        "model = get_model(input_shape)\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=0.0001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=adam,\n",
        "    # ★ 원래 ouput이 37개니까 이에 맞게 label도 one-hot encoding을 해 줘야 하지만\n",
        "    # sparse_categorical_crossentropy를 사용하면 one-hot encoding 필요 없음\n",
        "    # label index만 넘겨서 모델이 학습하게 하기 때문\n",
        "    loss='sparse_categorical_crossentropy', # multi-class에 맞게 변경\n",
        "    metrics='accuracy'\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "VHAM4417cHCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Augmentation : 수정 필요 없음"
      ],
      "metadata": {
        "id": "UvaDXzjscHGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Augmentation:\n",
        "    def __init__(self, size, mode='train'):\n",
        "        if mode == 'train':\n",
        "            self.transform = A.Compose([\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.ShiftScaleRotate(\n",
        "                    p=0.5,\n",
        "                    shift_limit=0.05,  # 이미지의 가로 길이가 최대 몇% 넘어가도 되는 지\n",
        "                    scale_limit=0.05,  # 이미지를 최대 몇% 확대/축소할지\n",
        "                    rotate_limit=15,\n",
        "                ),\n",
        "\n",
        "                # 이미지에 구멍을 뚫는 것\n",
        "                A.CoarseDropout(\n",
        "                    p=0.5,\n",
        "                    max_holes=8,  # 최대 구멍 개수\n",
        "                    max_height=int(0.1 * size),  # 가로 최대 길이 : 이미지의 10%\n",
        "                    max_width=int(0.1 * size),\n",
        "                ),\n",
        "\n",
        "                A.RandomBrightnessContrast(p=0.2),\n",
        "            ])\n",
        "\n",
        "    def __call__(self, **kwargs):\n",
        "        if self.transform:   # train mode인 경우\n",
        "            augmented = self.transform(**kwargs)\n",
        "            img = augmented['image']\n",
        "            return img"
      ],
      "metadata": {
        "id": "uxPQ5GPJcHM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- DataGenerator 일부 수정 필요 : label을 return 하는 부분"
      ],
      "metadata": {
        "id": "X7UQdX1ocHQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, batch_size, csv_path, image_size,\n",
        "                 fold, mode='train', shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.shuffle = shuffle\n",
        "        self.fold = fold\n",
        "        self.mode = mode\n",
        "        \n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        \n",
        "        if self.mode == 'train':\n",
        "            self.df = self.df[self.df['fold'] != self.fold]\n",
        "        elif self.mode == 'val':\n",
        "            self.df = self.df[self.df['fold'] == self.fold]\n",
        "        \n",
        "        #### Remove invalid files\n",
        "        #### https://github.com/tensorflow/models/issues/3134\n",
        "        invalid_filenames = [\n",
        "            'Egyptian_Mau_14',\n",
        "            'Egyptian_Mau_139',\n",
        "            'Egyptian_Mau_145',\n",
        "            'Egyptian_Mau_156',\n",
        "            'Egyptian_Mau_167',\n",
        "            'Egyptian_Mau_177',\n",
        "            'Egyptian_Mau_186',\n",
        "            'Egyptian_Mau_191',\n",
        "            'Abyssinian_5',\n",
        "            'Abyssinian_34',\n",
        "            'chihuahua_121',\n",
        "            'beagle_116'\n",
        "        ]\n",
        "        self.df = self.df[~self.df['file_name']. \\\n",
        "                          isin(invalid_filenames)]\n",
        "\n",
        "        self.transform = Augmentation(image_size, mode)\n",
        "\n",
        "        self.on_epoch_end()\n",
        "            \n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.df) / self.batch_size)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        strt = idx * self.batch_size\n",
        "        fin = (idx + 1) * self.batch_size\n",
        "        data = self.df.iloc[strt:fin]\n",
        "        \n",
        "        batch_x, batch_y = self.get_data(data)\n",
        "        \n",
        "        return np.array(batch_x), np.array(batch_y)\n",
        "        \n",
        "    def get_data(self, data):\n",
        "        batch_x = []\n",
        "        batch_y = []\n",
        "        \n",
        "        for _, r in data.iterrows():\n",
        "            file_name = r['file_name']\n",
        "            \n",
        "            image = cv2.imread(f'drive/MyDrive/data/images/{file_name}.jpg')\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "\n",
        "            if self.mode == 'train':\n",
        "                image = image.astype('uint8')\n",
        "                image = self.transform(image=image)\n",
        "\n",
        "            image = image.astype('float32')\n",
        "            image = image / 255.\n",
        "            \n",
        "            # sparse_categorical_crossentropy를 사용하기 때문에\n",
        "            # 따로 one-hot encoding 변환 없이 기존처럼 id의 index만 넘기면 됨\n",
        "            # 1~37로 되어있으니 -1을 해서 0~36으로 변환\n",
        "            label = int(r['id']) - 1\n",
        "            \n",
        "            batch_x.append(image)\n",
        "            batch_y.append(label)\n",
        "        \n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "HKCH7hAlcHUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = drive_project_root+'kfolds.csv'\n",
        "\n",
        "train_generator =  DataGenerator(\n",
        "    fold=1,\n",
        "    mode='train',\n",
        "    csv_path=csv_path,\n",
        "    batch_size=128,\n",
        "    image_size=256,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "valid_generator =  DataGenerator(\n",
        "    fold=1,\n",
        "    mode='val',\n",
        "    csv_path=csv_path,\n",
        "    batch_size=128,\n",
        "    image_size=256,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "OioN0JyIcHao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 10 epoch로 학습했을 때 이진분류 때보다는 성능이 약간 낮음\n",
        "- train과 validation 사이 차이도 커짐\n",
        "- 그래도 매 epoch마다 train, validation 모두 accuracy가 증가하고 있기 때문에 epoch 개수를 늘리면 성능이 더 좋아질 가능성이 큼"
      ],
      "metadata": {
        "id": "8U7wieUy6JmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "4fTe8X0h6JsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = history.history\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['loss'], label='train')\n",
        "plt.plot(history['val_loss'], label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title(\"Loss\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['accuracy'], label='train')\n",
        "plt.plot(history['val_accuracy'], label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WRpoToN06Jzc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}