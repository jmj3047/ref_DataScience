{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c54b77",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "\n",
    "- Pytorch는 TensorFlow와 함께 Deep Learning에서 가장 널리 사용되는 framework\n",
    "- 초기에는 Torch라는 이름으로 Lua 언어 기반으로 만들어졌으나, 이후 python 기반으로 변경한 것이 Pytorch\n",
    "- New York 대학교와 Facebook이 공동으로 만들었고, Deep Learning 연구자들 사이에서는 가장 대중적으로 널리 사용되는 framework\n",
    "- Deep Learning 연구하는 사람들은 TensorFlow보다 Pytorch 더 많이 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518bf753",
   "metadata": {},
   "source": [
    "## 1. Pytorch Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86eef9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "010d99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea256b",
   "metadata": {},
   "source": [
    "MNIST Data 다운받기\n",
    "- 공개 dataset에서 train 데이터, test 데이터 내려받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0549cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb04e11",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "- TensorFlow에서 tf.Data.Dataset과 같은 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db32ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# dataset 생성\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print('Shape of x [N, C, H, W]: ', X.shape)\n",
    "    print('Shape of y: ', y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1553481",
   "metadata": {},
   "source": [
    "학습에 사용할 CPU나 GPU 장치 얻기\n",
    "- GPU가 있으면 GPU 쓰도록 코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53fa0aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "print('using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3489a897",
   "metadata": {},
   "source": [
    "### 모델 정의\n",
    "- class로 모델 만들도록 권장 함\n",
    "- to(devide) : 생성된 모델을 GPU로 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5725ac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d201d19a",
   "metadata": {},
   "source": [
    "### Loss 함수와 Optimizer 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41b50a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50528312",
   "metadata": {},
   "source": [
    "### Training을 위한 함수\n",
    "\n",
    "- TensorFlow와 차이점\n",
    "  - TensorFlow는 이중 loop 였는데, Pytorch는 dataloader를 받아와서, 안에서 for문 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24b1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 예측 오류 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24158a",
   "metadata": {},
   "source": [
    "### Test를 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61a4c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # no_grad() : gradient 전파 안 되게 함\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "984e1159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------------------------\n",
      "loss: 2.286137 [    0/60000]\n",
      "loss: 0.497393 [ 6400/60000]\n",
      "loss: 0.346694 [12800/60000]\n",
      "loss: 0.357643 [19200/60000]\n",
      "loss: 0.251323 [25600/60000]\n",
      "loss: 0.340979 [32000/60000]\n",
      "loss: 0.157604 [38400/60000]\n",
      "loss: 0.363198 [44800/60000]\n",
      "loss: 0.260771 [51200/60000]\n",
      "loss: 0.331137 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.191733\n",
      "Epoch 2\n",
      "------------------------------------\n",
      "loss: 0.124024 [    0/60000]\n",
      "loss: 0.185612 [ 6400/60000]\n",
      "loss: 0.110246 [12800/60000]\n",
      "loss: 0.177035 [19200/60000]\n",
      "loss: 0.197120 [25600/60000]\n",
      "loss: 0.244412 [32000/60000]\n",
      "loss: 0.058470 [38400/60000]\n",
      "loss: 0.235918 [44800/60000]\n",
      "loss: 0.157711 [51200/60000]\n",
      "loss: 0.198995 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.138271\n",
      "Epoch 3\n",
      "------------------------------------\n",
      "loss: 0.079269 [    0/60000]\n",
      "loss: 0.118605 [ 6400/60000]\n",
      "loss: 0.078662 [12800/60000]\n",
      "loss: 0.085851 [19200/60000]\n",
      "loss: 0.122364 [25600/60000]\n",
      "loss: 0.170875 [32000/60000]\n",
      "loss: 0.038596 [38400/60000]\n",
      "loss: 0.181661 [44800/60000]\n",
      "loss: 0.128167 [51200/60000]\n",
      "loss: 0.138779 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.118339\n",
      "Epoch 4\n",
      "------------------------------------\n",
      "loss: 0.064629 [    0/60000]\n",
      "loss: 0.083897 [ 6400/60000]\n",
      "loss: 0.070817 [12800/60000]\n",
      "loss: 0.037616 [19200/60000]\n",
      "loss: 0.086503 [25600/60000]\n",
      "loss: 0.125954 [32000/60000]\n",
      "loss: 0.027274 [38400/60000]\n",
      "loss: 0.133010 [44800/60000]\n",
      "loss: 0.111313 [51200/60000]\n",
      "loss: 0.092274 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.109303\n",
      "Epoch 5\n",
      "------------------------------------\n",
      "loss: 0.045491 [    0/60000]\n",
      "loss: 0.061247 [ 6400/60000]\n",
      "loss: 0.060975 [12800/60000]\n",
      "loss: 0.023439 [19200/60000]\n",
      "loss: 0.064365 [25600/60000]\n",
      "loss: 0.098574 [32000/60000]\n",
      "loss: 0.018982 [38400/60000]\n",
      "loss: 0.102584 [44800/60000]\n",
      "loss: 0.099363 [51200/60000]\n",
      "loss: 0.061969 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.099356\n",
      "Epoch 6\n",
      "------------------------------------\n",
      "loss: 0.031268 [    0/60000]\n",
      "loss: 0.053701 [ 6400/60000]\n",
      "loss: 0.052510 [12800/60000]\n",
      "loss: 0.017514 [19200/60000]\n",
      "loss: 0.046522 [25600/60000]\n",
      "loss: 0.084010 [32000/60000]\n",
      "loss: 0.014291 [38400/60000]\n",
      "loss: 0.073479 [44800/60000]\n",
      "loss: 0.098396 [51200/60000]\n",
      "loss: 0.046417 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.090682\n",
      "Epoch 7\n",
      "------------------------------------\n",
      "loss: 0.024199 [    0/60000]\n",
      "loss: 0.036199 [ 6400/60000]\n",
      "loss: 0.036962 [12800/60000]\n",
      "loss: 0.018234 [19200/60000]\n",
      "loss: 0.036200 [25600/60000]\n",
      "loss: 0.073687 [32000/60000]\n",
      "loss: 0.013411 [38400/60000]\n",
      "loss: 0.051074 [44800/60000]\n",
      "loss: 0.105382 [51200/60000]\n",
      "loss: 0.037083 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.088781\n",
      "Epoch 8\n",
      "------------------------------------\n",
      "loss: 0.025858 [    0/60000]\n",
      "loss: 0.027423 [ 6400/60000]\n",
      "loss: 0.027006 [12800/60000]\n",
      "loss: 0.020892 [19200/60000]\n",
      "loss: 0.027538 [25600/60000]\n",
      "loss: 0.054031 [32000/60000]\n",
      "loss: 0.010144 [38400/60000]\n",
      "loss: 0.035256 [44800/60000]\n",
      "loss: 0.108583 [51200/60000]\n",
      "loss: 0.028478 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.084938\n",
      "Epoch 9\n",
      "------------------------------------\n",
      "loss: 0.021013 [    0/60000]\n",
      "loss: 0.021924 [ 6400/60000]\n",
      "loss: 0.024074 [12800/60000]\n",
      "loss: 0.015836 [19200/60000]\n",
      "loss: 0.021731 [25600/60000]\n",
      "loss: 0.034075 [32000/60000]\n",
      "loss: 0.008854 [38400/60000]\n",
      "loss: 0.018914 [44800/60000]\n",
      "loss: 0.109606 [51200/60000]\n",
      "loss: 0.020079 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.081895\n",
      "Epoch 10\n",
      "------------------------------------\n",
      "loss: 0.021878 [    0/60000]\n",
      "loss: 0.015954 [ 6400/60000]\n",
      "loss: 0.024735 [12800/60000]\n",
      "loss: 0.012152 [19200/60000]\n",
      "loss: 0.019405 [25600/60000]\n",
      "loss: 0.024908 [32000/60000]\n",
      "loss: 0.007545 [38400/60000]\n",
      "loss: 0.013897 [44800/60000]\n",
      "loss: 0.091478 [51200/60000]\n",
      "loss: 0.016673 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.080128\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n------------------------------------')\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c33afa",
   "metadata": {},
   "source": [
    "### 내가 쓴 손글씨로 Test 해보기\n",
    "\n",
    "Colab을 쓰는 경우 아래 cell 실행하면 파일 업로드 가능\n",
    "- 그림판과 같은 도구를 이용하여 손으로 숫자 쓰고 파일로 저장하고 업로드 하기\n",
    "- 파일명 : image.png\n",
    "\n",
    "```python\n",
    "imoprt os\n",
    "from PIL import Image\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "        name=fn, length=len(uploaded[fn])))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image file 경로 설정\n",
    "cur_dir = os.getcwd()\n",
    "img_path = os.path.join(cur_dir, 'image.png')\n",
    "\n",
    "# image file 읽기\n",
    "cur_img = Image.open(img_path)\n",
    "\n",
    "# 28×28로 resize\n",
    "cur_img = cur_img.resize((28,28))\n",
    "image = np.asarray(cur_img)\n",
    "\n",
    "# color image일 경우 RGB 평균값으로 gray scale로 변경\n",
    "try:\n",
    "    image = np.mean(image, axis=2)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# upload한 image는 흰 배경에 검은 글씨로 되어 있으므로, MNIST data와 같이 검은 배경에 흰 글씨로 변경\n",
    "image = np.abs(255-image)\n",
    "\n",
    "# MNIST와 동일하게 data preprocessing(255로 나눠줌)\n",
    "image = image.astype(np.float32)/255.\n",
    "\n",
    "# 화면에 출력하여 확인\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df9029",
   "metadata": {},
   "source": [
    "- 'image'가 현재 numpy array 형태인데, torch에서 사용하는 tensor로 변경\n",
    "- reshape\n",
    "- model에 넣고 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.as_tensor(image).to(device).reshape(1,1,28,28)\n",
    "model.eval()\n",
    "predict = model(image)\n",
    "print(\"Model이 예측한 값은 {} 입니다.\".format(predict.argmax(1).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03c6c22",
   "metadata": {},
   "source": [
    "## 2. Tensor\n",
    "\n",
    "- Tensor는 배열(array)이나 행렬(matrix)과 매우 유사한 특수한 자료구조\n",
    "  - 특히 numpy ndarray와 거의 똑같음 (TensorFlow가 numpy ndarray와 비슷한 것보다 훨씬 똑같음)\n",
    "- Pytorch에서는 tensor를 사용하여 모델의 입력(input)과 출력(output), 모델의 매개변수들을 부호화(encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe86fb3",
   "metadata": {},
   "source": [
    "### 2.1 list로부터 직접 tensor 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdddab24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98988289",
   "metadata": {},
   "source": [
    "### 2.2 numpy array로부터 tensor 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93de5c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0e1c768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 방법1\n",
    "x_np_1 = torch.tensor(np_array)\n",
    "print(x_np_1)\n",
    "\n",
    "# 방법2\n",
    "x_np_2 = torch.as_tensor(np_array)\n",
    "print(x_np_2)\n",
    "\n",
    "# 방법3\n",
    "x_np_3 = torch.from_numpy(np_array)\n",
    "print(x_np_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2a423",
   "metadata": {},
   "source": [
    "<b>차이점</b>\n",
    "- 방법1 : copy 해서 새로운 tensor 만듦\n",
    "  - 새로 만든 x_np_1 값 바꿔도 원래 np_array 값은 안 바뀜\n",
    "  - 메모리 낭비될 수 있음\n",
    "- 방법2, 방법3 : view를 만듦\n",
    "  - 새로 만든 x_np_2, x_np_3 값 바꾸면 원래 np_array 값도 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61883e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x_np_1[0,0] = 5\n",
    "print(x_np_1)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e409b36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "[[6 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x_np_2[0,0] = 6\n",
    "print(x_np_2)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "276e87a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "[[7 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x_np_3[0,0] = 7\n",
    "print(x_np_3)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e910ea",
   "metadata": {},
   "source": [
    "<b>다시 numpy로 바꾸기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c223680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 2]\n",
      " [3 4]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_again = x_np_1.numpy()\n",
    "print(np_again, type(np_again))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2647c761",
   "metadata": {},
   "source": [
    "### 2.3 numpy와 동일하게 아래 기능들 모두 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ab737d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[2, 2, 2],\n",
      "        [2, 2, 2]])\n",
      "tensor([[0.0000e+00, 0.0000e+00, 1.8754e+28],\n",
      "        [1.6634e-04, 6.6280e-10, 1.3040e-11]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,3)\n",
    "b = torch.zeros(2,3)\n",
    "c = torch.full((2,3),2)\n",
    "d = torch.empty(2,3)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36764799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[3, 3, 3],\n",
      "        [3, 3, 3]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "e = torch.zeros_like(c)\n",
    "f = torch.ones_like(c)\n",
    "g = torch.full_like(c, 3)\n",
    "h = torch.empty_like(c)\n",
    "print(e)\n",
    "print(f)\n",
    "print(g)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1c8b0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.eye(3)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e575ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "j = torch.arange(10)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56fb6f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8637, 0.1836],\n",
      "        [0.0368, 0.6927]])\n",
      "tensor([[ 2.2270, -0.0899],\n",
      "        [-0.3708,  1.4289]])\n"
     ]
    }
   ],
   "source": [
    "k = torch.rand(2,2)\n",
    "l = torch.randn(2,2)\n",
    "print(k)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3867558b",
   "metadata": {},
   "source": [
    "### 2.4 Tensor의 속성\n",
    "\n",
    "- tensor.device : 지금 이 tensor가 올라가 있는 메모리 확인 (CPU/GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23657fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f'Shape of tensor: {tensor.shape}')\n",
    "print(f'Datatype of tensor: {tensor.dtype}')\n",
    "print(f'Device tensor is stored on: {tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bbeff",
   "metadata": {},
   "source": [
    "<b>속성 변경</b>\n",
    "- reshape이 numpy, TensorFlow에서도 모두 사용되는 문법이니 보통 view보다는 reshape 씀\n",
    "- reshape과 view의 차이점\n",
    "  - reshape : original과 분리되는 copy를 만들기도 하고 original 값까지 바꾸는 view를 만들기도 함 (랜덤)\n",
    "  - view : 현재 생성한 것의 특정 값 바꾸면 original 값까지 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "580db2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([4, 3])\n",
      "Datatype of tensor: torch.int32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = tensor.reshape(4,3)\n",
    "#tensor = tensor.view(4,3)\n",
    "\n",
    "# type 변경\n",
    "tensor = tensor.int()\n",
    "\n",
    "# device 변경\n",
    "# cuda : GPU로 변경\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "\n",
    "print(f'Shape of tensor: {tensor.shape}')\n",
    "print(f'Datatype of tensor: {tensor.dtype}')\n",
    "print(f'Device tensor is stored on: {tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca941ae",
   "metadata": {},
   "source": [
    "### 2.5 Indexing과 Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee49eb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(1,13).reshape(3,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eccbe64",
   "metadata": {},
   "source": [
    "indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "105ed4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 7, 8])\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "print(a[1])\n",
    "print(a[0,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb061f",
   "metadata": {},
   "source": [
    "slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "839a983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 6, 7, 8]])\n",
      "tensor([[3, 4],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "print(a[1:-1])\n",
    "print(a[:2,2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2e6fbf",
   "metadata": {},
   "source": [
    "### 2.6 Transpose\n",
    "\n",
    "numpy, TensorFlow, Pytorch 세 개가 모두 다른 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "719f179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7]],\n",
      "\n",
      "        [[ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]]]) torch.Size([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(16).reshape(2,2,4)\n",
    "print(a, a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea589b22",
   "metadata": {},
   "source": [
    "transpose : numpy의 swap과 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c810979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  4],\n",
      "         [ 1,  5],\n",
      "         [ 2,  6],\n",
      "         [ 3,  7]],\n",
      "\n",
      "        [[ 8, 12],\n",
      "         [ 9, 13],\n",
      "         [10, 14],\n",
      "         [11, 15]]]) torch.Size([2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "b = a.transpose(1,2)\n",
    "print(b, b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db8ef0",
   "metadata": {},
   "source": [
    "permute : tensorflow의 transpose와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e83048e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  4],\n",
      "         [ 8, 12]],\n",
      "\n",
      "        [[ 1,  5],\n",
      "         [ 9, 13]],\n",
      "\n",
      "        [[ 2,  6],\n",
      "         [10, 14]],\n",
      "\n",
      "        [[ 3,  7],\n",
      "         [11, 15]]]) torch.Size([4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "c = a.permute((2,0,1))\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb8e36",
   "metadata": {},
   "source": [
    "### 2.7 Tensor 연산\n",
    "\n",
    "numpy, TensorFlow, Pytorch 간 차이 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c419e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[5., 6.],\n",
      "        [7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
    "y = torch.tensor([[5,6],[7,8]], dtype=torch.float32)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a768a7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[-4., -4.],\n",
      "        [-4., -4.]])\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]])\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n",
      "==============================\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[-4., -4.],\n",
      "        [-4., -4.]])\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]])\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)\n",
    "print(x - y)\n",
    "print(x * y)\n",
    "print(x / y)\n",
    "print(x @ y)\n",
    "print(\"=\"*30)\n",
    "print(torch.add(x,y))\n",
    "print(torch.subtract(x,y))\n",
    "print(torch.multiply(x,y))\n",
    "print(torch.divide(x,y))\n",
    "print(torch.matmul(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4110fa74",
   "metadata": {},
   "source": [
    "<b>pytorch에는 in-place 연산이라는 것 있음</b>\n",
    "- torch.add(x,y)가 아닌 x.add(y)라고 쓸 수 있음\n",
    "- 이때, x 값은 변하지 않음\n",
    "- 그런데 x.add_(y)라고 하면 inplace 되어서 x 값도 덧셈 결과로 변경됨\n",
    "- x. 입력하고 tab 해보면 여러 가지 연산 볼 수 있는데, 그 중 add_ 처럼 'underbar(\\_)' 붙은 건 inplace 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21d407d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.add(y))\n",
    "print(x)\n",
    "print(x.add_(y))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56f5e5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.arange(1,11).reshape(2,5)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9dae5",
   "metadata": {},
   "source": [
    "axis = ?\n",
    "- 해당하는 축이 사라지는 방향으로 연산 (sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfb71e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7,  9, 11, 13, 15]) torch.Size([5])\n",
      "tensor([15, 40]) torch.Size([2])\n",
      "tensor([15, 40]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "sum1 = torch.sum(z, axis=0)\n",
    "sum2 = torch.sum(z, axis=1)\n",
    "sum3 = torch.sum(z, axis=-1)\n",
    "print(sum1, sum1.shape)\n",
    "print(sum2, sum2.shape)\n",
    "print(sum3, sum3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3b4fd6",
   "metadata": {},
   "source": [
    "<b>concat & stack</b>\n",
    "- stack : 새로운 축을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc2e9402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]]) torch.Size([4, 6])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]]) torch.Size([4, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(24).reshape(4,6)\n",
    "b = a.clone().detach()\n",
    "print(a, a.shape)\n",
    "print(b, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c22ff214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23],\n",
      "        [ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]]) torch.Size([8, 6])\n"
     ]
    }
   ],
   "source": [
    "c = torch.cat([a,b], axis=0)\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "addca136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11,  6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17, 12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23, 18, 19, 20, 21, 22, 23]]) torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "c = torch.cat([a,b], axis=-1)\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7edce",
   "metadata": {},
   "source": [
    "stack : axis=0 → 0번 자리에 축 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e33dd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9, 10, 11],\n",
      "         [12, 13, 14, 15, 16, 17],\n",
      "         [18, 19, 20, 21, 22, 23]],\n",
      "\n",
      "        [[ 0,  1,  2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9, 10, 11],\n",
      "         [12, 13, 14, 15, 16, 17],\n",
      "         [18, 19, 20, 21, 22, 23]]]) torch.Size([2, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "d = torch.stack([a,b], axis=0)\n",
    "print(d, d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b858c6",
   "metadata": {},
   "source": [
    "stack : axis=-1 → -1번 자리에 축 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6715c448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  0],\n",
      "         [ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5]],\n",
      "\n",
      "        [[ 6,  6],\n",
      "         [ 7,  7],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9],\n",
      "         [10, 10],\n",
      "         [11, 11]],\n",
      "\n",
      "        [[12, 12],\n",
      "         [13, 13],\n",
      "         [14, 14],\n",
      "         [15, 15],\n",
      "         [16, 16],\n",
      "         [17, 17]],\n",
      "\n",
      "        [[18, 18],\n",
      "         [19, 19],\n",
      "         [20, 20],\n",
      "         [21, 21],\n",
      "         [22, 22],\n",
      "         [23, 23]]]) torch.Size([4, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "d = torch.stack([a,b], axis=-1)\n",
    "print(d, d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a9fe7",
   "metadata": {},
   "source": [
    "---\n",
    "# Dataset / Dataloader\n",
    "\n",
    "- Data를 처리하여 model에 공급하는 방법으로 Pytorch에서는 Dataset과 DataLoader 제공\n",
    "- Dataset : data & label 저장\n",
    "- DataLoader : Dataset을 model에 공급할 수 있도록 iterable 객체로 감싸줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93938a72",
   "metadata": {},
   "source": [
    "## 1. FashionMNIST data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "325eb127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d6e17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()  # tensor로 바꿈 & FashionMNIST를 255로 나눠서 0~1 사이 값으로 scaling\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd0dc4",
   "metadata": {},
   "source": [
    "## 2. 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efe99358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: 'T-Shirt',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle Boot'\n",
    "}\n",
    "figure = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3,3\n",
    "\n",
    "# 랜덤하게 9개를 골라서 해당 index에 해당하는 training_data 출력\n",
    "for i in range(1, cols*rows+1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de96220",
   "metadata": {},
   "source": [
    "## 3. DataLoader 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "565a09bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973bc986",
   "metadata": {},
   "source": [
    "DataLoader를 통해 반복하기 (iterate)</br>\n",
    "이미지와 정답(label) 표시\n",
    "- .size()와 .shape은 동일한 의미 (어떤 걸 써도 상관 없음)\n",
    "- squeeze()\n",
    "  - 지금 data shape이 앞에 channel이 들어가 있음\n",
    "  - TensorFlow에서는 (28,28)으로 되어 있었는데, 여기서는 (1,28,28)\n",
    "  - 그런데 grayscale 이미지 볼 때는 channel이 없어야 됨\n",
    "  - 이걸 없애 주는 역할이 squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1485ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 8\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f'Feature batch shape: {train_features.size()}')\n",
    "print(f'Labels batch shape: {train_labels.size()}')\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "print(f'Label: {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0108ae",
   "metadata": {},
   "source": [
    "## 4. Custom Dataset, Data Loader 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23dd10a",
   "metadata": {},
   "source": [
    "### 간단한 Custom Dataset/Transform/DataLoader 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ad11a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    # np_data : numpy data라고 가정\n",
    "    # transform : 전처리할 때 필요한 transform\n",
    "    def __init__(self, np_data, transform=None):\n",
    "        self.data = np_data\n",
    "        self.transform = transform\n",
    "        self.len = np_data.shape[0]  # data 개수\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # index에 해당하는 data를 return\n",
    "    # 만약 transform이 있으면, transform 적용해서 return\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea025822",
   "metadata": {},
   "source": [
    "<b>전처리로 사용할 함수</b>\n",
    "- TensorFlow에서 tf.square와 같은 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7940e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(sample):\n",
    "    return sample**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d97c8f",
   "metadata": {},
   "source": [
    "transform 자리에 입력할 때\n",
    "- 그냥 넣으면 안 되고 tr.Comopose()로 변환해 줘야 함\n",
    "- 여러 개를 넣을 수도 있음\n",
    "  - tr.Compose([square, xxx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa8d20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = tr.Compose([square])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b92283",
   "metadata": {},
   "source": [
    "data에는 0~9 숫자를 입력해라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daf7873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = np.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a925f",
   "metadata": {},
   "source": [
    "각각을 모두 제곱해라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aecf21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset(np_data, transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f6e60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataloader = DataLoader(custom_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88a911ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([49, 64], dtype=torch.int32)\n",
      "tensor([36,  0], dtype=torch.int32)\n",
      "tensor([9, 1], dtype=torch.int32)\n",
      "tensor([16,  4], dtype=torch.int32)\n",
      "tensor([81, 25], dtype=torch.int32)\n",
      "==============================\n",
      "tensor([25,  1], dtype=torch.int32)\n",
      "tensor([0, 9], dtype=torch.int32)\n",
      "tensor([36, 16], dtype=torch.int32)\n",
      "tensor([81, 49], dtype=torch.int32)\n",
      "tensor([ 4, 64], dtype=torch.int32)\n",
      "==============================\n",
      "tensor([25, 16], dtype=torch.int32)\n",
      "tensor([36,  4], dtype=torch.int32)\n",
      "tensor([49, 81], dtype=torch.int32)\n",
      "tensor([64,  0], dtype=torch.int32)\n",
      "tensor([1, 9], dtype=torch.int32)\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    for data in custom_dataloader:\n",
    "        print(data)\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0465de",
   "metadata": {},
   "source": [
    "---\n",
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90825b8",
   "metadata": {},
   "source": [
    "### device 설정\n",
    "\n",
    "- CPU/GPU 중 결정\n",
    "- 'cuda' 사용이 가능하면 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8022d57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d726f1",
   "metadata": {},
   "source": [
    "## 1. Model Class 만들기\n",
    "\n",
    "- TensorFlow는 Model 만들기에 세 가지 방법을 사용하지만, Pytorch는 공식적으로 이렇게 class를 활용한 모델 만들기를 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7714d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()  # 28×28을 vector로 펴기\n",
    "        # 하나씩 지정해도 되지만\n",
    "        # nn.Sequential을 사용하면, 한 번에 묶어서 쓰면 되서 편함\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # Pytorch - nn.Linear : TensorFlow의 Dense Layer와 같은 역할\n",
    "            # Dense Layer와 달리 nn.Linear에서는 28*28 input을 명시함\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128,10)\n",
    "            # TensorFlow에서는 마지막에 softmax 쓰지만, 여기서는 안 씀\n",
    "            # 나중에 Loss 계산할 때, softmax 쓸 거기 때문에 여기서는 빠져있음\n",
    "        )\n",
    "    \n",
    "    # TensorFlow의 call method와 같은 기능\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c9adb3",
   "metadata": {},
   "source": [
    "Model instance 생성, device 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f12635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55c81f9",
   "metadata": {},
   "source": [
    "가상의 data 만들어서 예측해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e08611a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([7])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1,28,28,device=device)\n",
    "logits = model(X)\n",
    "pred_prob = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_prob.argmax(1)\n",
    "print(f'Predicted class: {y_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b63b7e",
   "metadata": {},
   "source": [
    "## 2. Training / Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3eeb21",
   "metadata": {},
   "source": [
    "### 2.1 Loss Function\n",
    "- 손실 함수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5cf4ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9fa09a",
   "metadata": {},
   "source": [
    "### 2.2 Optimizer\n",
    "\n",
    "- optimizer : weight, bias update\n",
    "- model.parameters() : 모델의 parameter들을 미분하고 update 해라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f60e96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c79faa",
   "metadata": {},
   "source": [
    "### 2.3 Training / Validation(Test) Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c5173",
   "metadata": {},
   "source": [
    "Training을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a50c8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)  # 전체 data 개수 (6만개)\n",
    "    # 6만 개 데이터를 batch 단위(64)로 나눠 학습\n",
    "    # 이게 한 번 돌면 한 epoch이 끝난 것\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # X : 이미지, y : label\n",
    "        # device에서 GPU로 보냄\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 예측(prediction)과 손실(loss) 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        \n",
    "        # 역전파\n",
    "        # zero_grad() : gradient가 남아있는 것 clean 해줌\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()   # gradient 생성 (backpropagation)\n",
    "        optimizer.step()  # optimizer에서 weight, bias update\n",
    "        \n",
    "        # batch가 100번 돌 때마다 화면에 출력\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc1c46",
   "metadata": {},
   "source": [
    "Test를 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd4afbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # 한 epoch에서 batch가 몇 번 들어가야 끝나는지 계산\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # with torch.no_grad():\n",
    "    # Gradient를 계산하지 않을 거라는 걸 알려주는 것\n",
    "    # 안 써도 되지만 memory 절약을 위해 쓰는 걸 권장\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # item() : torch tensor 중 0차원인 것(scalar 값인 것)은\n",
    "            # item()을 쓰면 바로 해당 숫자를 뽑아 줌\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb11dbaf",
   "metadata": {},
   "source": [
    "학습 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a3b1018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ------------------------------\n",
      "loss: 0.493957 [    0/60000]\n",
      "loss: 0.332706 [ 6400/60000]\n",
      "loss: 0.607512 [12800/60000]\n",
      "loss: 0.326489 [19200/60000]\n",
      "loss: 0.414436 [25600/60000]\n",
      "loss: 0.381990 [32000/60000]\n",
      "loss: 0.428773 [38400/60000]\n",
      "loss: 0.425388 [44800/60000]\n",
      "loss: 0.415842 [51200/60000]\n",
      "loss: 0.308633 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.426593 \n",
      "\n",
      "Epoch 2\n",
      " ------------------------------\n",
      "loss: 0.649881 [    0/60000]\n",
      "loss: 0.359434 [ 6400/60000]\n",
      "loss: 0.287935 [12800/60000]\n",
      "loss: 0.513347 [19200/60000]\n",
      "loss: 0.359240 [25600/60000]\n",
      "loss: 0.364250 [32000/60000]\n",
      "loss: 0.562118 [38400/60000]\n",
      "loss: 0.369292 [44800/60000]\n",
      "loss: 0.298844 [51200/60000]\n",
      "loss: 0.578522 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.404454 \n",
      "\n",
      "Epoch 3\n",
      " ------------------------------\n",
      "loss: 0.327099 [    0/60000]\n",
      "loss: 0.365280 [ 6400/60000]\n",
      "loss: 0.278361 [12800/60000]\n",
      "loss: 0.454039 [19200/60000]\n",
      "loss: 0.446914 [25600/60000]\n",
      "loss: 0.303327 [32000/60000]\n",
      "loss: 0.299344 [38400/60000]\n",
      "loss: 0.177979 [44800/60000]\n",
      "loss: 0.439611 [51200/60000]\n",
      "loss: 0.450267 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.409863 \n",
      "\n",
      "Epoch 4\n",
      " ------------------------------\n",
      "loss: 0.329279 [    0/60000]\n",
      "loss: 0.339565 [ 6400/60000]\n",
      "loss: 0.437470 [12800/60000]\n",
      "loss: 0.427719 [19200/60000]\n",
      "loss: 0.339435 [25600/60000]\n",
      "loss: 0.406687 [32000/60000]\n",
      "loss: 0.228726 [38400/60000]\n",
      "loss: 0.280688 [44800/60000]\n",
      "loss: 0.392133 [51200/60000]\n",
      "loss: 0.304154 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.381690 \n",
      "\n",
      "Epoch 5\n",
      " ------------------------------\n",
      "loss: 0.223087 [    0/60000]\n",
      "loss: 0.357219 [ 6400/60000]\n",
      "loss: 0.421990 [12800/60000]\n",
      "loss: 0.374323 [19200/60000]\n",
      "loss: 0.182788 [25600/60000]\n",
      "loss: 0.443491 [32000/60000]\n",
      "loss: 0.293352 [38400/60000]\n",
      "loss: 0.427156 [44800/60000]\n",
      "loss: 0.296212 [51200/60000]\n",
      "loss: 0.220322 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.369067 \n",
      "\n",
      "Epoch 6\n",
      " ------------------------------\n",
      "loss: 0.274693 [    0/60000]\n",
      "loss: 0.206467 [ 6400/60000]\n",
      "loss: 0.252469 [12800/60000]\n",
      "loss: 0.413437 [19200/60000]\n",
      "loss: 0.314722 [25600/60000]\n",
      "loss: 0.308483 [32000/60000]\n",
      "loss: 0.238547 [38400/60000]\n",
      "loss: 0.245863 [44800/60000]\n",
      "loss: 0.334234 [51200/60000]\n",
      "loss: 0.176185 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.361281 \n",
      "\n",
      "Epoch 7\n",
      " ------------------------------\n",
      "loss: 0.300811 [    0/60000]\n",
      "loss: 0.266032 [ 6400/60000]\n",
      "loss: 0.297224 [12800/60000]\n",
      "loss: 0.380715 [19200/60000]\n",
      "loss: 0.369565 [25600/60000]\n",
      "loss: 0.272043 [32000/60000]\n",
      "loss: 0.239389 [38400/60000]\n",
      "loss: 0.283961 [44800/60000]\n",
      "loss: 0.533191 [51200/60000]\n",
      "loss: 0.300996 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.364672 \n",
      "\n",
      "Epoch 8\n",
      " ------------------------------\n",
      "loss: 0.376076 [    0/60000]\n",
      "loss: 0.382517 [ 6400/60000]\n",
      "loss: 0.352880 [12800/60000]\n",
      "loss: 0.226997 [19200/60000]\n",
      "loss: 0.216452 [25600/60000]\n",
      "loss: 0.206467 [32000/60000]\n",
      "loss: 0.262382 [38400/60000]\n",
      "loss: 0.542589 [44800/60000]\n",
      "loss: 0.183665 [51200/60000]\n",
      "loss: 0.535684 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.370418 \n",
      "\n",
      "Epoch 9\n",
      " ------------------------------\n",
      "loss: 0.277025 [    0/60000]\n",
      "loss: 0.308605 [ 6400/60000]\n",
      "loss: 0.284255 [12800/60000]\n",
      "loss: 0.322607 [19200/60000]\n",
      "loss: 0.152486 [25600/60000]\n",
      "loss: 0.132668 [32000/60000]\n",
      "loss: 0.172752 [38400/60000]\n",
      "loss: 0.235548 [44800/60000]\n",
      "loss: 0.356393 [51200/60000]\n",
      "loss: 0.353004 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.355451 \n",
      "\n",
      "Epoch 10\n",
      " ------------------------------\n",
      "loss: 0.289446 [    0/60000]\n",
      "loss: 0.369513 [ 6400/60000]\n",
      "loss: 0.174273 [12800/60000]\n",
      "loss: 0.202112 [19200/60000]\n",
      "loss: 0.303298 [25600/60000]\n",
      "loss: 0.326399 [32000/60000]\n",
      "loss: 0.286739 [38400/60000]\n",
      "loss: 0.169342 [44800/60000]\n",
      "loss: 0.237515 [51200/60000]\n",
      "loss: 0.185817 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.356376 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n ------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f347e",
   "metadata": {},
   "source": [
    "## 3. Model save & restore\n",
    "\n",
    "- pytorch에서는 '.pth' 확장자 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e70421",
   "metadata": {},
   "source": [
    "### 3.1 parameter만 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4411e790",
   "metadata": {},
   "source": [
    "학습된 model parameter 저장\n",
    "- state_dict() 라는 format으로 모델의 weight, bias 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d567314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31096ee8",
   "metadata": {},
   "source": [
    "새 Model instance 생성, device 설정 (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73e99f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model2 = NeuralNetwork().to(device)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f91356",
   "metadata": {},
   "source": [
    "<b>test</b>\n",
    "- eval() : training을 하는 게 아니라는 것을 모델에게 알려주는 것\n",
    "  - inference 할 때는 eval() 해주는 게 좋음\n",
    "- 학습이 하나도 안 된 상태니 정확도가 8.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c950f115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.333184 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2.eval()\n",
    "test_loop(test_dataloader, model2, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82da74",
   "metadata": {},
   "source": [
    "저장한 parameter 불러오기 (weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1175fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f62dd",
   "metadata": {},
   "source": [
    "<b>test</b>\n",
    "- 저장했던 weight, bias 적용\n",
    "- 정확도가 88.2%로 다시 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7dabfa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.333184 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2.eval()\n",
    "test_loop(test_dataloader, model2, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb792b",
   "metadata": {},
   "source": [
    "### 3.2 Model 전체를 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b367ff",
   "metadata": {},
   "source": [
    "저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ed2dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd744c",
   "metadata": {},
   "source": [
    "불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "24cdaea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4748a",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b0c290e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.333184 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3.eval()\n",
    "test_loop(test_dataloader, model2, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e1cb59",
   "metadata": {},
   "source": [
    "---\n",
    "# Tensorboard 사용하여 시각화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041b4d82",
   "metadata": {},
   "source": [
    "### 1. Load the TensorBoard notebook extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6710e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9910e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('./logs/pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40194475",
   "metadata": {},
   "source": [
    "### 2. 새 Model instance 생성, device 설정\n",
    "- 하나도 학습되지 않은 상태 → 정확도 : 11.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e8899f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Test Error: \n",
      " Accuracy: 11.7%, Avg loss: 2.305897 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model4 = NeuralNetwork().to(device)\n",
    "print(model4)\n",
    "\n",
    "model4.eval()\n",
    "test_loop(test_dataloader, model4, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40367225",
   "metadata": {},
   "source": [
    "### 3. Model의 구조를 tensorboard에 저장\n",
    "\n",
    "- 모델의 구조 저장하려면 입력이 한 개 필요\n",
    "- 랜덤하게 입력 X 만들기\n",
    "- writer에 add_graph()로 model과 입력 X 넣기\n",
    "- 모델이 tensorboard에 write 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "257d3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1,28,28,device=device)\n",
    "writer.add_graph(model4,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa6127",
   "metadata": {},
   "source": [
    "### 4. 기타 필요한 것들 tensorboard에 저장\n",
    "\n",
    "- loss, accuracy 저장\n",
    "- weight, bias 의 histogram 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fc07be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)  # 전체 data 개수 (6만개)\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "   \n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 예측(prediction)과 손실(loss) 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        \n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()   # gradient 생성 (backpropagation)\n",
    "        optimizer.step()  # optimizer에서 weight, bias update\n",
    "        \n",
    "        # batch 단위 loss 계산\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "        # 전체 데이터의 loss 계산\n",
    "        # len(dataloader) : batch 가 몇 개 들어갔는지\n",
    "        total_loss += loss / len(dataloader)\n",
    "\n",
    "    return total_loss            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5c465b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0,0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: (test_loss:>8f) \\n')\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043826b9",
   "metadata": {},
   "source": [
    "### 5. 학습이 되는 동안 writer가 TensorBoard에 write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bfa29627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ------------------------------\n",
      "loss: 0.207744 [    0/60000]\n",
      "loss: 0.386491 [ 6400/60000]\n",
      "loss: 0.426200 [12800/60000]\n",
      "loss: 0.217056 [19200/60000]\n",
      "loss: 0.132200 [25600/60000]\n",
      "loss: 0.329132 [32000/60000]\n",
      "loss: 0.328750 [38400/60000]\n",
      "loss: 0.416143 [44800/60000]\n",
      "loss: 0.360943 [51200/60000]\n",
      "loss: 0.158486 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: (test_loss:>8f) \n",
      "\n",
      "Epoch 2\n",
      " ------------------------------\n",
      "loss: 0.277458 [    0/60000]\n",
      "loss: 0.282787 [ 6400/60000]\n",
      "loss: 0.117578 [12800/60000]\n",
      "loss: 0.239410 [19200/60000]\n",
      "loss: 0.142754 [25600/60000]\n",
      "loss: 0.341028 [32000/60000]\n",
      "loss: 0.180452 [38400/60000]\n",
      "loss: 0.331701 [44800/60000]\n",
      "loss: 0.205145 [51200/60000]\n",
      "loss: 0.407487 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: (test_loss:>8f) \n",
      "\n",
      "Epoch 3\n",
      " ------------------------------\n",
      "loss: 0.265841 [    0/60000]\n",
      "loss: 0.236849 [ 6400/60000]\n",
      "loss: 0.200243 [12800/60000]\n",
      "loss: 0.436144 [19200/60000]\n",
      "loss: 0.127317 [25600/60000]\n",
      "loss: 0.228373 [32000/60000]\n",
      "loss: 0.170170 [38400/60000]\n",
      "loss: 0.279606 [44800/60000]\n",
      "loss: 0.365748 [51200/60000]\n",
      "loss: 0.251725 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: (test_loss:>8f) \n",
      "\n",
      "Epoch 4\n",
      " ------------------------------\n",
      "loss: 0.192547 [    0/60000]\n",
      "loss: 0.237489 [ 6400/60000]\n",
      "loss: 0.191870 [12800/60000]\n",
      "loss: 0.376084 [19200/60000]\n",
      "loss: 0.129568 [25600/60000]\n",
      "loss: 0.248147 [32000/60000]\n",
      "loss: 0.172933 [38400/60000]\n",
      "loss: 0.251769 [44800/60000]\n",
      "loss: 0.105085 [51200/60000]\n",
      "loss: 0.255350 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: (test_loss:>8f) \n",
      "\n",
      "Epoch 5\n",
      " ------------------------------\n",
      "loss: 0.263162 [    0/60000]\n",
      "loss: 0.209879 [ 6400/60000]\n",
      "loss: 0.256593 [12800/60000]\n",
      "loss: 0.108979 [19200/60000]\n",
      "loss: 0.191679 [25600/60000]\n",
      "loss: 0.156039 [32000/60000]\n",
      "loss: 0.204615 [38400/60000]\n",
      "loss: 0.225017 [44800/60000]\n",
      "loss: 0.239689 [51200/60000]\n",
      "loss: 0.265508 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: (test_loss:>8f) \n",
      "\n",
      "Epoch 6\n",
      " ------------------------------\n",
      "loss: 0.129881 [    0/60000]\n",
      "loss: 0.221227 [ 6400/60000]\n",
      "loss: 0.355242 [12800/60000]\n",
      "loss: 0.242591 [19200/60000]\n",
      "loss: 0.153585 [25600/60000]\n",
      "loss: 0.230464 [32000/60000]\n",
      "loss: 0.159441 [38400/60000]\n",
      "loss: 0.382558 [44800/60000]\n",
      "loss: 0.341915 [51200/60000]\n",
      "loss: 0.209504 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: (test_loss:>8f) \n",
      "\n",
      "Epoch 7\n",
      " ------------------------------\n",
      "loss: 0.160470 [    0/60000]\n",
      "loss: 0.273691 [ 6400/60000]\n",
      "loss: 0.267206 [12800/60000]\n",
      "loss: 0.228693 [19200/60000]\n",
      "loss: 0.227853 [25600/60000]\n",
      "loss: 0.082378 [32000/60000]\n",
      "loss: 0.234645 [38400/60000]\n",
      "loss: 0.321682 [44800/60000]\n",
      "loss: 0.138453 [51200/60000]\n",
      "loss: 0.212276 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: (test_loss:>8f) \n",
      "\n",
      "Epoch 8\n",
      " ------------------------------\n",
      "loss: 0.107921 [    0/60000]\n",
      "loss: 0.198024 [ 6400/60000]\n",
      "loss: 0.156596 [12800/60000]\n",
      "loss: 0.259557 [19200/60000]\n",
      "loss: 0.178106 [25600/60000]\n",
      "loss: 0.219241 [32000/60000]\n",
      "loss: 0.199324 [38400/60000]\n",
      "loss: 0.272180 [44800/60000]\n",
      "loss: 0.307022 [51200/60000]\n",
      "loss: 0.181465 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: (test_loss:>8f) \n",
      "\n",
      "Epoch 9\n",
      " ------------------------------\n",
      "loss: 0.147938 [    0/60000]\n",
      "loss: 0.241441 [ 6400/60000]\n",
      "loss: 0.165498 [12800/60000]\n",
      "loss: 0.223946 [19200/60000]\n",
      "loss: 0.237675 [25600/60000]\n",
      "loss: 0.264985 [32000/60000]\n",
      "loss: 0.180945 [38400/60000]\n",
      "loss: 0.212535 [44800/60000]\n",
      "loss: 0.154210 [51200/60000]\n",
      "loss: 0.217332 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: (test_loss:>8f) \n",
      "\n",
      "Epoch 10\n",
      " ------------------------------\n",
      "loss: 0.210950 [    0/60000]\n",
      "loss: 0.171002 [ 6400/60000]\n",
      "loss: 0.300559 [12800/60000]\n",
      "loss: 0.197901 [19200/60000]\n",
      "loss: 0.178739 [25600/60000]\n",
      "loss: 0.315833 [32000/60000]\n",
      "loss: 0.129762 [38400/60000]\n",
      "loss: 0.196321 [44800/60000]\n",
      "loss: 0.242698 [51200/60000]\n",
      "loss: 0.209488 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: (test_loss:>8f) \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "parameters = ['Weight1', 'Bias1', 'Weight2', 'Bias2']\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n ------------------------------\")\n",
    "    # train_loss 저장\n",
    "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    writer.add_scalar('training loss', train_loss, t)\n",
    "    # model.parameters() : parameter들이 하나씩 꺼내져 나옴\n",
    "    # add_histogram(name, param, t) : 이 이름(name)으로 parameter를 저장해라 (t : 몇 번째 epoch인지)\n",
    "    for param, name in zip(model.parameters(), parameters):\n",
    "        writer.add_histogram(name, param, t)\n",
    "    # test_loss 저장\n",
    "    test_loss = test(test_dataloader, model, loss_fn)\n",
    "    writer.add_scalar('test loss', test_loss, t)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d2922",
   "metadata": {},
   "source": [
    "### 6. write 기록 후에는 반드시 write를 close 해줘야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "89c9bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4ca98",
   "metadata": {},
   "source": [
    "### 7. 저장된 directory 지정해서 TensorBoard 열어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a3ec898d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c48253386a85cbe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c48253386a85cbe\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir './logs/pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ce162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
