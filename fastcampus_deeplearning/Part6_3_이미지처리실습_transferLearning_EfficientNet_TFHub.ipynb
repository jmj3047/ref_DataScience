{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part6_1_이미지처리실습_transferLearning_EfficientNet_TFHub.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyy7lUL36GDH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from glob import glob\n",
        "\n",
        "import math\n",
        "import random \n",
        "\n",
        "import cv2                                 # image를 읽기 위한 open cv library\n",
        "import xml.etree.ElementTree as et         # xml 파일을 parsing 하기 위한 library\n",
        "from matplotlib.patches import Rectangle   # Bounding box를 그리기 위함\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "import albumentations as A    # CoarseDropout 인지 안 된다는 문제 발생 -> pip install 아래 세 가지 코드 실행 필요\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "drive_project_root = 'drive/MyDrive/data/'\n",
        "sys.path.append(drive_project_root)\n",
        "\n",
        "image_root = 'drive/MyDrive/data/images/'\n",
        "anno_root = 'drive/MyDrive/data/annotations/'\n",
        "\n",
        "image_dir = image_root\n",
        "bbox_dir = anno_root + 'xmls/'    # bounding box\n",
        "seg_dir = anno_root + 'trimaps/'  # segmentation map\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/albumentations-team/albumentations.git  # Data Agumentation"
      ],
      "metadata": {
        "id": "I0n79GEe6Ijn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall opencv-python"
      ],
      "metadata": {
        "id": "WAsz65Xc6Iqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python"
      ],
      "metadata": {
        "id": "H7SoslMC6I3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Transfer Learning\n",
        "- 배경\n",
        "  - dataset의 고양이와 개 비율 = 2:5\n",
        "    - 모든 data를 강아지로 찍어도 성능이 70% 정도\n",
        "  - 앞에서 만든 모델의 성능 : validation data 70% accuracy\n",
        "  - 즉, 모델 학습을 했음에도 불구하고 찍었을 때와 큰 차이가 없음\n",
        "  - 그냥 학습을 했을 때와 data augmentation 적용했을 때도 최종 모델 성능 차이가 거의 없었음\n",
        "  - 모델 바꿀 필요 있음 -> Transfer Learning\n",
        "- Transfer Learning\n",
        "  - 특정 분야에서 학습된 모델을 유사하거나 전혀 새로운 분야에 사용하는 것\n",
        "    - 수십만 장의 image 학습하고 유의미한 feature 추출\n",
        "    - 이를 oxford pet data 분류에 사용\n",
        "  - 학습데이터가 적을 때 유용 + 학습 속도, 최종 결과도 모두 좋음 -> 항상 모델을 pre train 하는 것 추천\n",
        "- pre trained된 모델을 가져올 수 있는 곳\n",
        "  - https://github.com/keras-team/keras-applications\n",
        "  - https://keras.io/api/applications/\n",
        "  - VGG, ResNet, EfficientNet, etc.\n",
        "  - 이 중 image net 분류에 대해 성능(Top-1 accuracy 부분)이 좋게 적혀 있는 모델일수록 내가 하려는 task에 쓸 때도 성능이 좋음\n",
        "  - 주의 : 모델의 Size가 클수록 학습속도 느림\n",
        "    - 느려도 상관 없는지 vs real-time이 중요한지\n",
        "    - accuracy와 size의 trade off 잘 고려해서 선택할 것"
      ],
      "metadata": {
        "id": "3rnQaptD6I_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 1. EfficientNet\n",
        "- 모델을 불러서 내가 사용하려는 것에 맞게 변환하기\n",
        "- `model.summary()` 결과\n",
        "  - efficientnetb0가 하나의 layer처럼 사용됨\n",
        "  - 앞에서 쓴 모델은 parameter 수가 27만 개 정도 됐는데 parameter 수도 훨씬 많아짐 (400만)\n",
        "  - 마지막 dense : 실제 분류하는 layer"
      ],
      "metadata": {
        "id": "loEhTMSC6JIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(input_shape):\n",
        "\n",
        "    inputs = keras.Input(input_shape)\n",
        "\n",
        "    # Feature extract\n",
        "    base_model = EfficientNetB0(\n",
        "        input_shape=input_shape,\n",
        "\n",
        "        # 만약 아무 것도 안 쓰면 transfer을 사용하는 게 아니라 모델 구현체만 가져다 학습에 사용하겠다는 의미\n",
        "        weights='imagenet',   # imagenet의 pre trained 된 weight값 사용\n",
        "        \n",
        "        # github 링크에서 모델 코드 보면 if include_top: 부분이 있음\n",
        "        # whether to include the fully-connected layer at the top of the network\n",
        "        # 해당 모델이 image를 분류하기 위해 사용한 layer들\n",
        "        # = image에서 feature를 추출하는 layer 외에 그 feature를 가지고 분류하는 layer 부분임\n",
        "        # = 내가 사용하려는 task랑 크게 관련은 없음 + 무거움\n",
        "        # -> 이걸 가져다 쓰지 않고 (False) 내 task에 맞게 따로 구현하고자 함\n",
        "        include_top=False,\n",
        "\n",
        "        pooling='avg'  # Gloabl average pooling\n",
        "    )\n",
        "\n",
        "    x = base_model(inputs)  # image의 feature 추출\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)  # 이진분류\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape = (256, 256, 3)\n",
        "model = get_model(input_shape)\n",
        "\n",
        "# Transfer learning 할 때는 보통 사용하는 learning rate(0.001)보다 작은 값 사용\n",
        "adam = keras.optimizers.Adam(lr=0.0001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=adam,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics='accuracy'\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "uoxuhBFw6JZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Augmentation:\n",
        "    def __init__(self, size, mode='train'):\n",
        "        if mode == 'train':\n",
        "            self.transform = A.Compose([\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.ShiftScaleRotate(\n",
        "                    p=0.5,\n",
        "                    shift_limit=0.05,  # 이미지의 가로 길이가 최대 몇% 넘어가도 되는 지\n",
        "                    scale_limit=0.05,  # 이미지를 최대 몇% 확대/축소할지\n",
        "                    rotate_limit=15,\n",
        "                ),\n",
        "\n",
        "                # 이미지에 구멍을 뚫는 것\n",
        "                A.CoarseDropout(\n",
        "                    p=0.5,\n",
        "                    max_holes=8,                 # 최대 구멍 개수\n",
        "                    max_height=int(0.1 * size),  # 가로 최대 길이 : 이미지의 10%\n",
        "                    max_width=int(0.1 * size),\n",
        "                ),\n",
        "\n",
        "                A.RandomBrightnessContrast(p=0.2),\n",
        "            ])\n",
        "\n",
        "    def __call__(self, **kwargs):\n",
        "        if self.transform:   # train mode인 경우\n",
        "            augmented = self.transform(**kwargs)\n",
        "            img = augmented['image']\n",
        "            return img"
      ],
      "metadata": {
        "id": "8U7wieUy6JmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, batch_size, csv_path, image_size,\n",
        "                 fold, mode='train', shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.shuffle = shuffle\n",
        "        self.fold = fold\n",
        "        self.mode = mode\n",
        "        \n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        \n",
        "        if self.mode == 'train':\n",
        "            self.df = self.df[self.df['fold'] != self.fold]\n",
        "        elif self.mode == 'val':\n",
        "            self.df = self.df[self.df['fold'] == self.fold]\n",
        "        \n",
        "        #### Remove invalid files\n",
        "        #### https://github.com/tensorflow/models/issues/3134\n",
        "        invalid_filenames = [\n",
        "            'Egyptian_Mau_14',\n",
        "            'Egyptian_Mau_139',\n",
        "            'Egyptian_Mau_145',\n",
        "            'Egyptian_Mau_156',\n",
        "            'Egyptian_Mau_167',\n",
        "            'Egyptian_Mau_177',\n",
        "            'Egyptian_Mau_186',\n",
        "            'Egyptian_Mau_191',\n",
        "            'Abyssinian_5',\n",
        "            'Abyssinian_34',\n",
        "            'chihuahua_121',\n",
        "            'beagle_116'\n",
        "        ]\n",
        "        self.df = self.df[~self.df['file_name']. \\\n",
        "                          isin(invalid_filenames)]\n",
        "\n",
        "        self.transform = Augmentation(image_size, mode)\n",
        "\n",
        "        self.on_epoch_end()\n",
        "            \n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.df) / self.batch_size)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        strt = idx * self.batch_size\n",
        "        fin = (idx + 1) * self.batch_size\n",
        "        data = self.df.iloc[strt:fin]\n",
        "        \n",
        "        batch_x, batch_y = self.get_data(data)\n",
        "        \n",
        "        return np.array(batch_x), np.array(batch_y)\n",
        "        \n",
        "    def get_data(self, data):\n",
        "        batch_x = []\n",
        "        batch_y = []\n",
        "        \n",
        "        for _, r in data.iterrows():\n",
        "            file_name = r['file_name']\n",
        "            \n",
        "            image = cv2.imread(f'drive/MyDrive/data/images/{file_name}.jpg')\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "\n",
        "            if self.mode == 'train':\n",
        "                image = image.astype('uint8')\n",
        "                image = self.transform(image=image)\n",
        "\n",
        "            image = image.astype('float32')\n",
        "            image = image / 255.\n",
        "            \n",
        "            label = int(r['species']) - 1\n",
        "            \n",
        "            batch_x.append(image)\n",
        "            batch_y.append(label)\n",
        "        \n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "4fTe8X0h6JsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = drive_project_root+'kfolds.csv'\n",
        "\n",
        "train_generator =  DataGenerator(\n",
        "    fold=1,\n",
        "    mode='train',\n",
        "    csv_path=csv_path,\n",
        "    batch_size=128,\n",
        "    image_size=256,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "valid_generator =  DataGenerator(\n",
        "    fold=1,\n",
        "    mode='val',\n",
        "    csv_path=csv_path,\n",
        "    batch_size=128,\n",
        "    image_size=256,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "WRpoToN06Jzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 성능 굉장히 좋아짐"
      ],
      "metadata": {
        "id": "Hv1ZDt_tXwCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "RvT-fclQ7i6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = history.history\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['loss'], label='train')\n",
        "plt.plot(history['val_loss'], label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title(\"Loss\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['accuracy'], label='train')\n",
        "plt.plot(history['val_accuracy'], label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3R4bw9g7jBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 2. TF Hub\n",
        "\n",
        "- 배경\n",
        "  - keras applications는 마지막 update가 몇 년 전\n",
        "  - efficientNet 이후에 나온 모델들에 대해서는 update가 안 됨\n",
        "- TF Hub\n",
        "  - https://tfhub.dev/\n",
        "  - tensorflow에서 공식적으로 운영\n",
        "  - 최신 모델 (weight 포함) 지속 update 됨\n",
        "  - keras에는 image만 있는 것과 달리 text, video, audio 모델까지 포함\n",
        "- 방법\n",
        "  - problem domains에서 image 클릭\n",
        "  - filter 적용 : TF2 (version) + Finetunable 켜기\n",
        "  - efficientNet v2 검색\n",
        "    - efficientNet 이후에 나온 것\n",
        "    - 이걸 사용해서 학습하면 많이 update가 되었기 때문에 편리함\n",
        "  - 원하는 것 클릭 : imagenet/efficientnet_v2_imagenet1k_b0/feature_vector\n",
        "    - 기존 모델들보다 성능 좋음\n",
        "    - Usage 부분에 사용방법 코드 있음\n",
        "    - 그대로 복사해서 가져오기"
      ],
      "metadata": {
        "id": "eyb2xMhxYJJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 가장 최신 모델이라고 할 수 있는 efficientnet_v2를 tensorflow hub에서 가져와서 내 task 학습에 적용"
      ],
      "metadata": {
        "id": "xDOROTrTYJPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage 코드\n",
        "model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\n",
        "        \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\",  # 기존 구현된 모델\n",
        "        trainable=True    # base 모델도 학습이 가능하게 설정\n",
        "    ), \n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # 내 모델의 (binary) classification layer 붙이기\n",
        "])\n",
        "\n",
        "model.build([None, 256, 256, 3])  # Batch input shape\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=0.0001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=adam,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics='accuracy'\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ySSgvCoIYJUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 사이즈가 커졌기 때문에 batch size를 절반 정도로 줄임"
      ],
      "metadata": {
        "id": "99_ZlQvXYJX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = drive_project_root+'kfolds.csv'\n",
        "\n",
        "train_generator =  DataGenerator(\n",
        "    fold=1,\n",
        "    mode='train',\n",
        "    csv_path=csv_path,\n",
        "    batch_size=64,\n",
        "    image_size=256,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "valid_generator =  DataGenerator(\n",
        "    fold=1,\n",
        "    mode='val',\n",
        "    csv_path=csv_path,\n",
        "    batch_size=64,\n",
        "    image_size=256,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "IkfyrBoBYJdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- efficientNet v2(TF Hub)가 b0과 큰 차이가 없는 이유\n",
        "  - 지금 우리가 사용하는 task가 비교적 쉽기 때문\n",
        "  - 다른 이미지 분류에 사용하면 b0보다 v2가 성능이 좋음"
      ],
      "metadata": {
        "id": "xrhvz2EAYJms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "5LWeQxu7YJsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = history.history\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['loss'], label='train')\n",
        "plt.plot(history['val_loss'], label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title(\"Loss\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['accuracy'], label='train')\n",
        "plt.plot(history['val_accuracy'], label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z3U_39iJaZXx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}