{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4737967",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "- Convolutional Layer 안에는 kernel이 있음\n",
    "  - kernel (Computer Vision 용어) : weight와 bias라고 생각하면 됨\n",
    "- Neural Network 만들면 그것에 대한 테이블(그림)로 반드시 표현해 줄 것 ★★\n",
    "  - 나중에 검증하고, 설계할 때 아주 유용하게 사용할 수 있음\n",
    "- Tensorflow는 매우 유연함\n",
    "  - 같은 것을 다양한 방법으로 구현 가능\n",
    "  - 아래와 같이 각각의 구현하는 방법의 장단점을 분명하게 알고, 원할 때, 적절하게 사용하기 ★"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed903c46",
   "metadata": {},
   "source": [
    "# 1. Shapes in CNNs\n",
    "\n",
    "아래 코드가 Convolutional Neural Network의 Forward Proagation의 전부\n",
    "- 가장 간단한 모델을 만들기 위한 최소한의 지식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e81ac9c",
   "metadata": {},
   "source": [
    "## 1.1 Shapes in the Feature Extractors\n",
    "\n",
    "- convolutional layer, pooling layer의 반복을 통해 만들어짐\n",
    "- 마지막에는 Feature vector 생성 : (32, 245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4acb7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (32, 28, 28, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# channel : 3 - color image\n",
    "N, n_H, n_W, n_c = 32, 28, 28, 3\n",
    "n_conv_filter = 5\n",
    "k_size = 3\n",
    "pool_size, pool_strides = 2, 2\n",
    "batch_size = 32\n",
    "\n",
    "# normal distribution에서 임의의 noise가 담긴 이미지 N(32)개 생성\n",
    "x = tf.random.normal(shape=(N, n_H, n_W, n_c))\n",
    "\n",
    "conv1 = Conv2D(filters=n_conv_filter, kernel_size=k_size,\n",
    "              padding='same', activation='relu')\n",
    "\n",
    "conv1_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "\n",
    "conv2 = Conv2D(filters=n_conv_filter, kernel_size=k_size,\n",
    "              padding='same', activation='relu')\n",
    "\n",
    "conv2_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "\n",
    "flatten = Flatten()\n",
    "\n",
    "print(\"Input: {}\\n\".format(x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63391010",
   "metadata": {},
   "source": [
    "max pooling layer는 trainable parameter(weight와 bias)가 들어있지 않음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b353b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W/B: (3, 3, 3, 5)/(5,)\n",
      "After conv1: (32, 28, 28, 5)\n",
      "After conv1_pool: (32, 14, 14, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = conv1(x)\n",
    "W, B = conv1.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After conv1: {}\".format(x.shape))  # same padding → 28 * 28 고정, neuron 개수 : 5개\n",
    "x = conv1_pool(x)\n",
    "print(\"After conv1_pool: {}\\n\".format(x.shape)) # 2칸씩 건너 뛰었으니 (strides) 사이즈가 절반이 됨 → 14 * 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c561e8e",
   "metadata": {},
   "source": [
    "weight 값 의미 (3, 3, 5, 5)\n",
    "- 3 * 3\n",
    "- 세 번째 5 : 위에서 conv1 pooling 지나며, channel이 5개가 되었었음 : input = 5\n",
    "- 네 번째 5 : filter = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506ab223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W/B: (3, 3, 5, 5)/(5,)\n",
      "After conv2: (32, 14, 14, 5)\n",
      "After conv2_pool: (32, 7, 7, 5)\n",
      "After flatten: (32, 245)\n"
     ]
    }
   ],
   "source": [
    "x = conv2(x)\n",
    "W, B = conv2.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After conv2: {}\".format(x.shape))\n",
    "x = conv2_pool(x)\n",
    "print(\"After conv2_pool: {}\".format(x.shape)) # 2칸씩 건너 뛰었으니 (strides) 사이즈가 절반이 됨 → 7 * 7\n",
    "\n",
    "x = flatten(x)\n",
    "print(\"After flatten: {}\".format(x.shape))   # 7 * 7 * 5 = 245"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d838246b",
   "metadata": {},
   "source": [
    "## 1.2 Shapes in the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6688be7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature: (32, 245)\n",
      "\n",
      "W/B: (245, 50)/(50,)\n",
      "After dense1: (32, 50)\n",
      "\n",
      "W/B: (50, 25)/(25,)\n",
      "After dense2: (32, 25)\n",
      "\n",
      "W/B: (25, 10)/(10,)\n",
      "After dense3: (32, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "n_neurons = [50, 25, 10]\n",
    "\n",
    "dense1 = Dense(units=n_neurons[0], activation='relu')\n",
    "dense2 = Dense(units=n_neurons[1], activation='relu')\n",
    "dense3 = Dense(units=n_neurons[2], activation='softmax')  # 마지막 layer는 softmax\n",
    "\n",
    "print(\"Input feature: {}\\n\".format(x.shape))\n",
    "\n",
    "x = dense1(x)\n",
    "W, B = dense1.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))  # 50개의 neuron 생성\n",
    "print(\"After dense1: {}\\n\".format(x.shape))   # input의 32를 가져오고, 첫 번째 neuron 개수만큼 만들어짐 (50)\n",
    "\n",
    "x = dense2(x)\n",
    "W, B = dense2.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After dense2: {}\\n\".format(x.shape)) \n",
    "\n",
    "x = dense3(x)\n",
    "W, B = dense3.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After dense3: {}\\n\".format(x.shape))    # 마지막 10개 class에 대해 각각의 probability vector 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7fcd86",
   "metadata": {},
   "source": [
    "## 1.3 Shapes in the Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f35ad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]], shape=(32, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "y = tf.random.uniform(minval=0, maxval=10,  # 0~9 class\n",
    "                      shape=(32, ),         # vector\n",
    "                      dtype=tf.int32)\n",
    "\n",
    "y = tf.one_hot(y, depth=10)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5139cbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "tf.Tensor(2.4431143, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss_object = CategoricalCrossentropy()\n",
    "loss = loss_object(y, x)   # x : predictions\n",
    "print(loss.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe0661a",
   "metadata": {},
   "source": [
    "# 2. Implementation of CNNS\n",
    "\n",
    "전체 Convolutional Neural Network를 Tensorflow에서 제공하는 모델을 만드는 방법으로 만들어보려고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b6608",
   "metadata": {},
   "source": [
    "## 2.1 Implementation with Sequential Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2de6fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d7523d",
   "metadata": {},
   "source": [
    "sequential model\n",
    "- 가장 큰 장점 : .add를 이용해서 layer를 추가만 하면 되니 만들기 간편\n",
    "- 단점\n",
    "  - 중간에 sequential한 connection이 아니라 다른 식의 tensor 연산이 필요하면 사용 불가능\n",
    "  - layer를 새로 하나 만들 때마다 코드가 길어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6798d50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  (4, 28, 28, 3)\n",
      "Output :  (4, 10)\n"
     ]
    }
   ],
   "source": [
    "N, n_H, n_W, n_C = 4, 28, 28, 3\n",
    "n_conv_neurons = [10, 20, 30]\n",
    "n_dense_neurons = [50, 30, 10]\n",
    "k_size = 3   # kernel size\n",
    "padding = 'same'\n",
    "pool_size, pool_strides = 2, 2\n",
    "activation = 'relu'\n",
    "\n",
    "x = tf.random.normal(shape=(N, n_H, n_W, n_C))\n",
    "\n",
    "print(\"Input : \", x.shape)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=n_conv_neurons[0],\n",
    "                 kernel_size=k_size, padding=padding, activation=activation))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "\n",
    "model.add(Conv2D(filters=n_conv_neurons[1],\n",
    "                 kernel_size=k_size, padding=padding, activation=activation))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "\n",
    "model.add(Conv2D(filters=n_conv_neurons[2],\n",
    "                 kernel_size=k_size, padding=padding, activation=activation))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=n_dense_neurons[0], activation=activation))\n",
    "model.add(Dense(units=n_dense_neurons[1], activation=activation))\n",
    "model.add(Dense(units=n_dense_neurons[2], activation='softmax'))\n",
    "\n",
    "predictions = model(x)\n",
    "\n",
    "print(\"Output : \", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29afc68e",
   "metadata": {},
   "source": [
    "for loop을 사용해서 조금 더 간단하게 작성하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba89fef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output :  (4, 10)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "for n_conv_neuron in n_conv_neurons:\n",
    "    model.add(Conv2D(filters=n_conv_neuron,\n",
    "                     kernel_size=k_size, padding=padding, activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "for n_dense_neuron in n_dense_neurons:\n",
    "    model.add(Dense(units=n_dense_neuron, activation=activation))\n",
    "\n",
    "# 마지막 dense layer는 softmax로 변경\n",
    "model.add(Dense(units=n_dense_neurons[-1], activation='softmax'))\n",
    "\n",
    "predictions = model(x)\n",
    "\n",
    "print(\"Output : \", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d003de",
   "metadata": {},
   "source": [
    "## 2.2 Implementation with Model Sub-classing\n",
    "\n",
    "연구, 개발 시 매우 많이 사용되는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ceb250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29d627b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCNN(Model):\n",
    "    def __init__(self):\n",
    "        super(TestCNN, self).__init__()\n",
    "        \n",
    "        # Feature Extractor 구현\n",
    "        self.conv1 = Conv2D(filters=n_conv_neurons[0],\n",
    "                            kernel_size=k_size, padding=padding, activation=activation)\n",
    "        self.conv1_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "        \n",
    "        self.conv2 = Conv2D(filters=n_conv_neurons[1],\n",
    "                            kernel_size=k_size, padding=padding, activation=activation)\n",
    "        self.conv2_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "\n",
    "        self.conv3 = Conv2D(filters=n_conv_neurons[2],\n",
    "                            kernel_size=k_size, padding=padding, activation=activation)\n",
    "        self.conv3_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        self.dense1 = Dense(units=n_dense_neurons[0], activation=activation)\n",
    "        self.dense2 = Dense(units=n_dense_neurons[1], activation=activation)\n",
    "        self.dense3 = Dense(units=n_dense_neurons[2], activation='softmax')\n",
    "    \n",
    "    # prototype 생성 시에는 print문으로 중간 결과 모두 확인해 볼 것\n",
    "    def call(self, x):\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.conv1(x)      # convolutional\n",
    "        print(x.shape)\n",
    "        x = self.conv1_pool(x) # pooling\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv2_pool(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv3_pool(x)\n",
    "        print(x.shape)\n",
    "         \n",
    "        x = self.flatten(x)  # flatten\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.dense1(x)   # dense\n",
    "        print(x.shape)\n",
    "        x = self.dense2(x)   # dense\n",
    "        print(x.shape)\n",
    "        x = self.dense3(x)   # dense : softmax\n",
    "        print(x.shape)\n",
    "        \n",
    "        return x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63eac0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 28, 28, 3)\n",
      "(4, 28, 28, 10)\n",
      "(4, 14, 14, 10)\n",
      "(4, 14, 14, 20)\n",
      "(4, 7, 7, 20)\n",
      "(4, 7, 7, 30)\n",
      "(4, 3, 3, 30)\n",
      "(4, 270)\n",
      "(4, 50)\n",
      "(4, 30)\n",
      "(4, 10)\n"
     ]
    }
   ],
   "source": [
    "N, n_H, n_W, n_C = 4, 28, 28, 3\n",
    "n_conv_neurons = [10, 20, 30]\n",
    "n_dense_neurons = [50, 30, 10]\n",
    "k_size = 3   # kernel size\n",
    "padding = 'same'\n",
    "pool_size, pool_strides = 2, 2\n",
    "activation = 'relu'\n",
    "\n",
    "x = tf.random.normal(shape=(N, n_H, n_W, n_C))\n",
    "\n",
    "model = TestCNN()\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd92f11",
   "metadata": {},
   "source": [
    "## 2.3 Implementation with Sequential + Layer Sub-classing\n",
    "\n",
    "위에서와 같이 코딩을 하면, 코드가 너무 길어져서 중간에 실수할 수도 있음\n",
    "- Layer Sub-classing 사용하는 게 좋음\n",
    "  - Model sub-classing을 하는 것처럼 Layer Sub-classing을 하는 것\n",
    "    - 앞에서 배운 것과 형태는 동일\n",
    "    - 모델 fit 등에서 차이가 조금 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c341ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90999bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv(Layer):\n",
    "    def __init__(self, n_neuron):\n",
    "        super(MyConv, self).__init__()\n",
    "        \n",
    "        self.conv = Conv2D(filters=n_neuron,\n",
    "                           kernel_size=k_size, padding=padding, activation=activation)\n",
    "        self.conv_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492b5590",
   "metadata": {},
   "source": [
    "custom layer 사용해서 sequential 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1996181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, n_H, n_W, n_C = 4, 28, 28, 3\n",
    "n_conv_neurons = [10, 20, 30]\n",
    "n_dense_neurons = [50, 30, 10]\n",
    "k_size = 3   # kernel size\n",
    "padding = 'same'\n",
    "pool_size, pool_strides = 2, 2\n",
    "activation = 'relu'\n",
    "\n",
    "x = tf.random.normal(shape=(N, n_H, n_W, n_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "948d4b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output :  (4, 10)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(MyConv(n_conv_neurons[0]))\n",
    "model.add(MyConv(n_conv_neurons[1]))\n",
    "model.add(MyConv(n_conv_neurons[2]))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=n_dense_neurons[0], activation=activation))\n",
    "model.add(Dense(units=n_dense_neurons[1], activation=activation))\n",
    "model.add(Dense(units=n_dense_neurons[2], activation='softmax'))\n",
    "\n",
    "predictions = model(x)\n",
    "print(\"Output : \", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb301f0c",
   "metadata": {},
   "source": [
    "## 2.4 Implementation with Model and Layer Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6bb2ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1cb32f",
   "metadata": {},
   "source": [
    "### 2.4.1 Custom Layer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "940c9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv(Layer):\n",
    "    def __init__(self, n_neuron):\n",
    "        super(MyConv, self).__init__()\n",
    "        \n",
    "        self.conv = Conv2D(filters=n_neuron,\n",
    "                           kernel_size=k_size, padding=padding, activation=activation)\n",
    "        self.conv_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f40bc",
   "metadata": {},
   "source": [
    "### 2.4.2 Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c99b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCNN(Model):\n",
    "    def __init__(self):\n",
    "        super(TestCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = MyConv(n_conv_neurons[0])\n",
    "        self.conv2 = MyConv(n_conv_neurons[1])\n",
    "        self.conv3 = MyConv(n_conv_neurons[2])\n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        self.dense1 = Dense(units=n_dense_neurons[0], activation=activation)\n",
    "        self.dense2 = Dense(units=n_dense_neurons[1], activation=activation)\n",
    "        self.dense3 = Dense(units=n_dense_neurons[2], activation='softmax')\n",
    "    \n",
    "    def call(self, x):\n",
    "\n",
    "        x = self.conv1(x)      # convolutional\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        x = self.flatten(x)  # flatten\n",
    "        \n",
    "        x = self.dense1(x)   # dense\n",
    "        x = self.dense2(x)   # dense\n",
    "        x = self.dense3(x)   # dense : softmax\n",
    "        \n",
    "        return x       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d337ade",
   "metadata": {},
   "source": [
    "## 2.5 Sequential Model : 가장 효율적인 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152a530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb755a93",
   "metadata": {},
   "source": [
    "### 2.5.1 Custom Layer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a682a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv(Layer):\n",
    "    def __init__(self, n_neuron):\n",
    "        super(MyConv, self).__init__()\n",
    "        \n",
    "        self.conv = Conv2D(filters=n_neuron,\n",
    "                           kernel_size=k_size, padding=padding, activation=activation)\n",
    "        self.conv_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b6ade2",
   "metadata": {},
   "source": [
    "### 2.5.2 Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd5b904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCNN(Model):\n",
    "    def __init__(self):\n",
    "        super(TestCNN, self).__init__()\n",
    "        \n",
    "        # feature extractor를 sequential model로 생성\n",
    "        self.fe = Seuqntial()\n",
    "        \n",
    "        # for n_neuron in n_conv_neurons:\n",
    "            # self.fe.add(MyConv(n_neuron))\n",
    "            \n",
    "        self.fe.add(MyConv(n_conv_neurons[0]))\n",
    "        self.fe.add(MyConv(n_conv_neurons[1]))\n",
    "        self.fe.add(MyConv(n_conv_neurons[2]))\n",
    "        self.fe.add(Flatten())\n",
    "        \n",
    "        self.classifier = Sequential()\n",
    "        self.classifier.add(Dense(units=n_dense_neurons[0], activation=activation))\n",
    "        self.classifier.add(Dense(units=n_dense_neurons[1], activation=activation))\n",
    "        self.classifier.add(Dense(units=n_dense_neurons[2], activation='softmax'))\n",
    "    \n",
    "    def call(self, x):\n",
    "\n",
    "        x = self.fe(x)\n",
    "        #x = self.conv1(x)\n",
    "        #x = self.conv2(x)\n",
    "        #x = self.conv3(x)\n",
    "        #x = self.flatten(x)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        #x = self.dense1(x)\n",
    "        #x = self.dense2(x)\n",
    "        #x = self.dense3(x)\n",
    "        \n",
    "        return x       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef4055a",
   "metadata": {},
   "source": [
    "# 3. Implementation of LeNet\n",
    "\n",
    "LeNet (르넷)\n",
    "- CNN의 가장 classic한 model\n",
    "- 사람의 손글씨를 구분하는 Neural Network (숫자 0~9 : 총 10개 구분)\n",
    "- 처음에 Deep Learning을 유명하게 만들었던 model 중 하나"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eb4ce8",
   "metadata": {},
   "source": [
    "## 3.1 LeNet with Model Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05fb7d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a29ff952",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Model):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2D(filters=6, kernel_size=5, padding='same', activation='tanh')\n",
    "        self.conv1_pool = AveragePooling2D(pool_size=2, strides=2)\n",
    "        \n",
    "        self.conv2 = Conv2D(filters=16, kernel_size=5, padding='valid', activation='tanh')\n",
    "        self.conv2_pool = AveragePooling2D(pool_size=2, strides=2)\n",
    "\n",
    "        self.conv3 = Conv2D(filters=120, kernel_size=5, padding='valid', activation='tanh')\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        self.dense1 = Dense(units=84, activation='tanh')\n",
    "        self.dense2 = Dense(units=10, activation='softmax')\n",
    "    \n",
    "    def call(self, x):\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.conv1_pool(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.conv2_pool(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.dense2(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        \n",
    "        return x        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c488523c",
   "metadata": {},
   "source": [
    "### MNIST dataset은 흑백이미지 : channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a5e6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (32, 28, 28, 1)\n",
      "x: (32, 28, 28, 6)\n",
      "x: (32, 14, 14, 6)\n",
      "x: (32, 10, 10, 16)\n",
      "x: (32, 5, 5, 16)\n",
      "x: (32, 1, 1, 120)\n",
      "x: (32, 120)\n",
      "x: (32, 84)\n",
      "x: (32, 10)\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "\n",
    "x = tf.random.normal(shape=(32, 28, 28, 1))\n",
    "predictions = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093e10c",
   "metadata": {},
   "source": [
    "## 3.2 LeNet with Hybrid Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd5c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, AveragePooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "555a999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(Layer):\n",
    "    def __init__(self, filters, padding, pool=True):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.pool = pool        \n",
    "        self.conv = Conv2D(filters=filters, kernel_size=5, padding=padding, activation='tanh')\n",
    "\n",
    "        if self.pool == True:\n",
    "            self.conv_pool = AveragePooling2D(pool_size=2, strides=2)\n",
    "    \n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.pool == True:\n",
    "            x = self.conv_pool(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class LeNet(Model):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = ConvLayer(filters=6, padding='same')\n",
    "        self.conv2 = ConvLayer(filters=16, padding='valid')\n",
    "        self.conv3 = ConvLayer(filters=120, padding='valid', pool=False)\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        self.dense1 = Dense(units=84, activation='tanh')\n",
    "        self.dense2 = Dense(units=10, activation='softmax')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cb6bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "\n",
    "x = tf.random.normal(shape=(32, 28, 28, 1))\n",
    "predictions = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281d4bd0",
   "metadata": {},
   "source": [
    "## 3.3 Forward Propagation of LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75526a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist  # 28×28×1 dataset\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d970487d",
   "metadata": {},
   "source": [
    "### 3.3.1 LeNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4135c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(Layer):\n",
    "    def __init__(self, filters, padding, pool=True):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.pool = pool        \n",
    "        self.conv = Conv2D(filters=filters, kernel_size=5, padding=padding, activation='tanh')\n",
    "\n",
    "        if self.pool == True:\n",
    "            self.conv_pool = AveragePooling2D(pool_size=2, strides=2)\n",
    "    \n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.pool == True:\n",
    "            x = self.conv_pool(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class LeNet(Model):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = ConvLayer(filters=6, padding='same')\n",
    "        self.conv2 = ConvLayer(filters=16, padding='valid')\n",
    "        self.conv3 = ConvLayer(filters=120, padding='valid', pool=False)\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        self.dense1 = Dense(units=84, activation='tanh')\n",
    "        self.dense2 = Dense(units=10, activation='softmax')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442bb27",
   "metadata": {},
   "source": [
    "### 3.3.2 Dataset Preparation\n",
    "\n",
    "tensorflow에서 데이터 가져오기\n",
    "- 원래 tensorflow data는 (train_images, train_labels), (test_images, test_labels)로 구성되어 있음\n",
    "- 지금은 train 데이터만 받아서 사용하고자 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcc32df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e527c4b",
   "metadata": {},
   "source": [
    "6만 장의 데이터가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75a446de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) uint8\n",
      "(60000,) uint8\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape, train_images.dtype)\n",
    "print(train_labels.shape, train_labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f30a843",
   "metadata": {},
   "source": [
    "train_images\n",
    "- 지금은 28×28 데이터인데 마지막 color 채널 추가하기\n",
    "- dtype 변환 (uint8 → float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "834cc58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) float32\n",
      "(60000,) int32\n"
     ]
    }
   ],
   "source": [
    "train_images = np.expand_dims(train_images, axis=3).astype(np.float32)\n",
    "print(train_images.shape, train_images.dtype)\n",
    "\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "print(train_labels.shape, train_labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214f5bc9",
   "metadata": {},
   "source": [
    "지금 train_images와 train_labels는 numpy array\n",
    "- tensor로 하나씩 꺼내 쓸 수 있도록 변환 : from_tensor_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47af37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds = train_ds.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef5183d",
   "metadata": {},
   "source": [
    "### 3.3.3 Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74eadd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 1) (32,)\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "loss_object = SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711ec49",
   "metadata": {},
   "source": [
    "한 바퀴만 돌려서 형태 확인\n",
    "- 32장이 뽑히고 28×28×1 data임\n",
    "- label : 최종 카테고리는 32개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3df9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds:\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13be6b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.3559756, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds:\n",
    "    predictions = model(images)\n",
    "    loss = loss_object(labels, predictions)\n",
    "    print(loss)\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
