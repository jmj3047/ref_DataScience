{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03. MLP + basic regularizations (dropout, early stopping)_TF.ipynb","private_outputs":true,"provenance":[{"file_id":"1Yq_LYjN0_deqoBFaD_ZJFfoes_VYtBVN","timestamp":1633790134053}],"collapsed_sections":[],"authorship_tag":"ABX9TyMj4VVVHbOZWTShnaw1uetW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7CUNw8dNBwA4"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","import os\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/#fastcampus\")\n","drive_project_root = \"/content/drive/MyDrive/#fastcampus\"\n","!pip install -r \"/content/drive/MyDrive/#fastcampus/requirements.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kBxZXWDEHbkh"},"source":["from datetime import datetime\n","\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OdeNqGVRIJzv"},"source":["tf.config.list_physical_devices()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mR6QoAFuIMY0"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zawdEF0vIO-9"},"source":["# define gpus strategy\n","mirrored_strategy = tf.distribute.MirroredStrategy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZ_NevzbKGBk"},"source":["## 데이터 및 데이터로더 정의"]},{"cell_type":"code","metadata":{"id":"X89D1QCGJXTN"},"source":["with mirrored_strategy.scope():\n","    # 데이터 셋 정의 \n","    fashion_mnist = tf.keras.datasets.fashion_mnist\n","    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n","    \n","    # normalization\n","    x_train = x_train / 255.0\n","    x_test = x_test / 255.0\n","\n","    # train/val splits\n","    train_size = int(len(x_train) * 0.9)\n","    val_size = len(x_train) - train_size\n","\n","    dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=1024)\n","    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(buffer_size=1024)\n","\n","    train_dataset = dataset.take(train_size)\n","    val_dataset = dataset.skip(train_size)\n","    print(len(train_dataset), len(val_dataset), len(dataset), len(test_dataset))\n","    \n","    # dataloader 정의\n","    train_batch_size = 100\n","    val_batch_size = 10\n","    test_batch_size = 100\n","\n","    train_dataloader = train_dataset.batch(train_batch_size, drop_remainder=True)\n","    val_dataloader = val_dataset.batch(val_batch_size, drop_remainder=True)\n","    test_dataloader = test_dataset.batch(test_batch_size, drop_remainder=True)\n","\n","sample_example = next(iter(train_dataloader))\n","print(sample_example)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGRtSVzNJmck"},"source":["# plot figure\n","plt.figure(figsize=(10, 10))\n","for c in range(16):\n","    plt.subplot(4, 4, c+1)\n","    plt.imshow(x_train[c].reshape(28, 28), cmap=\"gray\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8LwF7hrxLzfP"},"source":["## 모델 정의"]},{"cell_type":"code","metadata":{"id":"54FXO6o1J654"},"source":["class MLP(tf.keras.Model):\n","    def __init__(self, input_dim: int, h1_dim: int, h2_dim: int, out_dim: int):\n","        super().__init__()\n","        self.flatten = tf.keras.layers.Flatten()\n","        self.linear1 = tf.keras.layers.Dense(input_dim=input_dim, units=h1_dim)\n","        self.linear2 = tf.keras.layers.Dense(units=h2_dim)\n","        self.linear3 = tf.keras.layers.Dense(units=out_dim)\n","        self.relu = tf.nn.relu\n","    \n","    def call(self, input, training=False):\n","        x = self.flatten(input)\n","        x = self.relu(self.linear1(x))\n","        x = self.relu(self.linear2(x))\n","        out = self.linear3(x)\n","        out = tf.nn.softmax(out)\n","        return out\n","    \n","    def train_step(self, data):\n","        images, labels = data\n","        \n","        with tf.GradientTape() as tape:\n","            outputs = self(images, training=True)\n","            preds = tf.argmax(outputs, 1)\n","\n","            loss = self.compiled_loss(\n","                labels, outputs\n","            )\n","        \n","        # compute gradients\n","        trainable_vars = self.trainable_variables\n","        gradients = tape.gradient(loss, trainable_vars)\n","\n","        # update weights\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","\n","        # update the metrics\n","        self.compiled_metrics.update_state(labels, preds)\n","\n","        # return a dict mapping metrics names to current values\n","        logs = {m.name: m.result() for m in self.metrics}\n","        logs.update({\"loss\": loss})\n","        return logs\n","\n","    \n","    def test_step(self, data):\n","        images, labels = data\n","        outputs = self(images, training=False)\n","        preds = tf.argmax(outputs, 1)\n","        loss = self.compiled_loss(\n","            labels, outputs\n","        )\n","\n","        # update the metrics\n","        self.compiled_metrics.update_state(labels, preds)\n","\n","        # return a dict mapping metrics names to current values\n","        logs = {m.name: m.result() for m in self.metrics}       \n","        logs.update({\"test_loss\": loss})\n","        return logs      \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJI8kHykffHy"},"source":["class MLPWithDropout(tf.keras.Model):\n","    def __init__(self, input_dim: int, h1_dim: int, h2_dim: int, out_dim: int, dropout_prob: float):\n","        super().__init__()\n","        self.flatten = tf.keras.layers.Flatten()\n","        self.linear1 = tf.keras.layers.Dense(input_dim=input_dim, units=h1_dim)\n","        self.linear2 = tf.keras.layers.Dense(units=h2_dim)\n","        self.linear3 = tf.keras.layers.Dense(units=out_dim)\n","        self.dropout = tf.keras.layers.Dropout(dropout_prob)\n","        self.relu = tf.nn.relu\n","    \n","    def call(self, input, training=False):\n","        x = self.flatten(input)\n","        x = self.relu(self.linear1(x))\n","        x = self.dropout(x, training=training)\n","        x = self.relu(self.linear2(x))\n","        x = self.dropout(x, training=training)\n","        out = self.linear3(x)\n","        out = tf.nn.softmax(out)\n","        return out\n","    \n","    def train_step(self, data):\n","        images, labels = data\n","        \n","        with tf.GradientTape() as tape:\n","            outputs = self(images, training=True)\n","            preds = tf.argmax(outputs, 1)\n","\n","            loss = self.compiled_loss(\n","                labels, outputs\n","            )\n","        \n","        # compute gradients\n","        trainable_vars = self.trainable_variables\n","        gradients = tape.gradient(loss, trainable_vars)\n","\n","        # update weights\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","\n","        # update the metrics\n","        self.compiled_metrics.update_state(labels, preds)\n","\n","        # return a dict mapping metrics names to current values\n","        logs = {m.name: m.result() for m in self.metrics}\n","        return logs\n","\n","    \n","    def test_step(self, data):\n","        images, labels = data\n","        outputs = self(images, training=False)\n","        preds = tf.argmax(outputs, 1)\n","        loss = self.compiled_loss(\n","            labels, outputs\n","        )\n","\n","        # update the metrics\n","        self.compiled_metrics.update_state(labels, preds)\n","\n","        # return a dict mapping metrics names to current values\n","        logs = {m.name: m.result() for m in self.metrics}\n","        return logs    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9KyfbS4RzQ7"},"source":["# 모델 정의 \n","n_class = 10\n","max_epoch = 50\n","\n","with mirrored_strategy.scope():\n","    # model = MLP(28*28*1, 128, 64, n_class)\n","    model = MLPWithDropout(28*28*1, 128, 64, n_class, dropout_prob=0.3)\n","    model_name = type(model).__name__\n","\n","    # define loss\n","    loss_function = tf.losses.SparseCategoricalCrossentropy()\n","\n","    # define optimizer\n","    lr = 1e-3\n","    optimizer = tf.optimizers.Adam(learning_rate=lr)\n","\n","    model.compile(\n","        loss=loss_function,\n","        optimizer=optimizer,\n","        metrics=[tf.keras.metrics.Accuracy()],\n","    )\n","\n","    model.build((1, 28*28*1))\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eo3jhwhHVOqu"},"source":["# define logging & callbacks\n","log_interval = 100\n","run_name = f\"{datetime.now()}-{model_name}\"\n","run_dirname = \"dnn-tutorial-fashion-mnist-runs-tf\"\n","log_dir = os.path.join(drive_project_root, \"runs\", run_dirname, run_name)\n","\n","tb_callback = tf.keras.callbacks.TensorBoard(\n","    log_dir, update_freq=log_interval\n",")\n","early_stop_callback = tf.keras.callbacks.EarlyStopping(patience=5, verbose=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIXfPYDeWqTH"},"source":["%load_ext tensorboard\n","%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/\n","\n","model.fit(\n","    train_dataloader,\n","    validation_data=val_dataloader,\n","    epochs=max_epoch,\n","    callbacks=[tb_callback, early_stop_callback]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T5SnIKTKVOab"},"source":["## Model testing"]},{"cell_type":"code","metadata":{"id":"bt7d0YMxXd5w"},"source":["model.evaluate(test_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3NIlcw5YBJc"},"source":["test_labels_list = []\n","test_preds_list = []\n","test_outputs_list = []\n","\n","for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc=\"testing\")):\n","    with mirrored_strategy.scope():\n","        test_outputs = model(test_images)\n","    test_preds = tf.argmax(test_outputs, 1)\n","\n","    final_outs = test_outputs.numpy()\n","    test_outputs_list.extend(final_outs)\n","    test_preds_list.extend(test_preds.numpy())\n","    test_labels_list.extend(test_labels.numpy())\n","\n","test_preds_list = np.array(test_preds_list)\n","test_labels_list = np.array(test_labels_list)\n","\n","test_accuracy = np.mean(test_preds_list == test_labels_list)\n","print(f\"\\nacc: {test_accuracy*100}%\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C7TXScWnZAPR"},"source":["# ROC Curve\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","\n","fpr = {}\n","tpr = {}\n","thresh = {}\n","n_class = 10\n","\n","for i in range(n_class):\n","    fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:, i], pos_label=i)\n","\n","# plot\n","for i in range(n_class):\n","    plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n","plt.title(\"Multi-class ROC Curve\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","auc_score = roc_auc_score(test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\")\n","print(f\"auc_score: {auc_score}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2b-2TiKdZdWd"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qau4Vi0zZgm3"},"source":[""],"execution_count":null,"outputs":[]}]}