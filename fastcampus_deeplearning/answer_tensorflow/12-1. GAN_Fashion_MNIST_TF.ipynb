{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"12-1. GAN_Fashion_MNIST_TF.ipynb","private_outputs":true,"provenance":[{"file_id":"1W6VBHVBWmTWx1NEe78VNAbXnPQ2DsYh3","timestamp":1636286035536},{"file_id":"1-Kuw2KqbixGHAmKXAQv1_FygXgZlXxE0","timestamp":1636280073726},{"file_id":"14UhxSABuj-M683k4TilUDhQIo39HFK-t","timestamp":1634019312693},{"file_id":"1CBRS5ajK2WVXMEN97owUmh6yhmljiILI","timestamp":1634015371559},{"file_id":"1bRDRTJmGm80o_sWIacmyt-pUnHfqOKqE","timestamp":1634012243448},{"file_id":"1apCHsYMGF0a1zGJeJe5WhAGyUTbehmi7","timestamp":1633794411943},{"file_id":"1Yq_LYjN0_deqoBFaD_ZJFfoes_VYtBVN","timestamp":1633790134053}],"collapsed_sections":[],"authorship_tag":"ABX9TyPufqyJCsJ75lxN2rAIqlXw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7CUNw8dNBwA4"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","import os\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/#fastcampus\")\n","drive_project_root = \"/content/drive/MyDrive/#fastcampus\"\n","!pip install -r \"/content/drive/MyDrive/#fastcampus/requirements.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kBxZXWDEHbkh"},"source":["from datetime import datetime\n","\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from omegaconf import OmegaConf\n","from omegaconf import DictConfig\n","import hydra\n","from hydra.core.config_store import ConfigStore\n","\n","import tensorflow as tf\n","import tensorflow_probability as tfp\n","import tensorflow_addons as tfa\n","\n","import wandb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QlfSWYBuJvXi"},"source":["from config_utils_tf import flatten_dict\n","from config_utils_tf import register_config\n","from config_utils_tf import get_optimizer_element\n","from config_utils_tf import get_callbacks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OdeNqGVRIJzv"},"source":["tf.config.list_physical_devices()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mR6QoAFuIMY0"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8LwF7hrxLzfP"},"source":["## 모델 정의"]},{"cell_type":"code","metadata":{"id":"54FXO6o1J654"},"source":["class GAN(tf.keras.Model):\n","    \"\"\"Convolutional variational autoencoder\"\"\"\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.latent_dim = cfg.model.latent_dim\n","        self.discriminator = tf.keras.Sequential(\n","            [\n","                tf.keras.layers.Conv2D(**cfg.model.dis.conv1),\n","                tf.keras.layers.Conv2D(**cfg.model.dis.conv2),\n","                tf.keras.layers.Flatten(),\n","                tf.keras.layers.Dense(1),\n","            ],\n","            name=\"discriminator\",\n","        )\n","        self.generator = tf.keras.Sequential(\n","            [\n","                tf.keras.layers.Dense(\n","                    units=cfg.model.gen.in_fc.units,\n","                    activation=tf.nn.relu\n","                ),\n","                tf.keras.layers.Reshape(\n","                    target_shape=tuple(cfg.model.gen.reshape_shape)\n","                ),\n","                tf.keras.layers.Conv2DTranspose(**cfg.model.gen.tr_conv1),\n","                tf.keras.layers.Conv2DTranspose(**cfg.model.gen.tr_conv2),\n","                tf.keras.layers.Conv2DTranspose(**cfg.model.gen.tr_conv3),\n","            ],\n","            name=\"generator\",\n","        )\n","        self.generator_loss_tracker = tf.keras.metrics.Mean(name=\"generator_loss\")\n","        self.discriminator_loss_tracker = tf.keras.metrics.Mean(name=\"discriminator_loss\")\n","        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(\n","            from_logits=True, reduction=tf.keras.losses.Reduction.SUM\n","        )\n","    \n","    @property\n","    def metrics(self):\n","        return [\n","            self.generator_loss_tracker,\n","            self.discriminator_loss_tracker,\n","        ]\n","    \n","    def compile(self, d_optimizer, g_optimizer, **kwargs):\n","        super().compile(**kwargs)\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","    \n","    @tf.function\n","    def get_generator_loss(self, fake_outputs):\n","        return self.cross_entropy(\n","            tf.ones_like(fake_outputs), fake_outputs,\n","        ) / fake_outputs.shape[0]\n","    \n","    @tf.function\n","    def get_discriminator_loss(self, real_outputs, fake_outputs):\n","        real_loss = self.cross_entropy(\n","            tf.ones_like(real_outputs), real_outputs\n","        )\n","        fake_loss = self.cross_entropy(\n","            tf.zeros_like(fake_outputs), fake_outputs,\n","        )\n","        total_d_loss = (real_loss + fake_loss) / (real_outputs.shape[0] + fake_outputs.shape[0])\n","        return total_d_loss\n","    \n","    @tf.function\n","    def sample(self, sample_size=100):\n","        return tf.random.normal(shape=(sample_size, 1, 1, self.latent_dim))\n","    \n","    def call(self, _, training=False):\n","        noise = self.sample(sample_size=self.cfg.train.train_batch_size)\n","        generated_images = self.generator(noise, training=training)\n","        discriminator_results = self.discriminator(generated_images, training=training)\n","        return generated_images, discriminator_results\n","    \n","    def train_step(self, data):\n","        images, _ = data\n","        # images = [B X 28 X 28] -> [B X 28 X 28 X 1]\n","        images = tf.cast(tf.expand_dims(images, -1), tf.float32)\n","            \n","        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n","            outputs, fake_output = self(images, training=True)\n","            real_output = self.discriminator(images, training=True)\n","\n","            # Calculate the loss for each item in the batch\n","            g_loss = self.get_generator_loss(fake_output)\n","            d_loss = self.get_discriminator_loss(real_output, fake_output)\n","\n","        # compute gradients\n","        g_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)\n","        d_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n","\n","        # update weights\n","        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n","        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n","\n","        # update the metrics\n","        self.generator_loss_tracker.update_state(g_loss)\n","        self.discriminator_loss_tracker.update_state(d_loss)\n","\n","        # tensorboard image update\n","        tf.summary.image(\"train_real_img\", images, max_outputs=5)\n","        tf.summary.image(\"train_generated_img\", outputs, max_outputs=5)\n","\n","        # return a dict mapping metrics names to current values\n","        logs = {m.name: m.result() for m in self.metrics}\n","        return logs\n","\n","    def test_step(self, data):\n","        images, _ = data\n","        # images = [B X 28 X 28] -> [B X 28 X 28 X 1]\n","        images = tf.cast(tf.expand_dims(images, -1), tf.float32)\n","            \n","        outputs, fake_output = self(images, training=True)\n","        real_output = self.discriminator(images, training=True)\n","\n","        # Calculate the loss for each item in the batch\n","        g_loss = self.get_generator_loss(fake_output)\n","        d_loss = self.get_discriminator_loss(real_output, fake_output)\n","\n","        # update the metrics\n","        self.generator_loss_tracker.update_state(g_loss)\n","        self.discriminator_loss_tracker.update_state(d_loss)\n","\n","        # tensorboard image update\n","        tf.summary.image(\"val_real_img\", images, max_outputs=5)\n","        tf.summary.image(\"val_generated_img\", outputs, max_outputs=5)\n","\n","        # return a dict mapping metrics names to current values\n","        logs = {m.name: m.result() for m in self.metrics}\n","        return logs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SnWpAd6MQK_v"},"source":["class VAE(tf.keras.Model):\n","    \"\"\"Convolutional variational autoencoder\"\"\"\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.latent_dim = cfg.model.latent_dim\n","        self.encoder = tf.keras.Sequential(\n","            [\n","                tf.keras.layers.Conv2D(**cfg.model.enc.conv1),\n","                tf.keras.layers.Conv2D(**cfg.model.enc.conv2),\n","                tf.keras.layers.Flatten(),\n","                tf.keras.layers.Dense(cfg.model.enc.out_fc.units),\n","            ],\n","            name=\"encoder\",\n","        )\n","        self.decoder = tf.keras.Sequential(\n","            [\n","                tf.keras.layers.Dense(\n","                    units=cfg.model.dec.in_fc.units,\n","                    activation=tf.nn.relu\n","                ),\n","                tf.keras.layers.Reshape(\n","                    target_shape=tuple(cfg.model.dec.reshape_shape)\n","                ),\n","                tf.keras.layers.Conv2DTranspose(**cfg.model.dec.tr_conv1),\n","                tf.keras.layers.Conv2DTranspose(**cfg.model.dec.tr_conv2),\n","                tf.keras.layers.Conv2DTranspose(**cfg.model.dec.tr_conv3),\n","            ],\n","            name=\"decoder\",\n","        )\n","        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n","        self.recon_loss_tracker = tf.keras.metrics.Mean(name=\"recon_loss\")\n","        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n","    \n","    @property\n","    def metrics(self):\n","        return [\n","            self.total_loss_tracker,\n","            self.recon_loss_tracker,\n","            self.kl_loss_tracker,\n","        ]\n","    \n","    @tf.function\n","    def sample(self, epsilon=None, sample_size=100):\n","        if epsilon is None:\n","            epsilon = tf.random.normal(shape=(sample_size, self.latent_dim))\n","        return self.decode(epsilon)\n","    \n","    def encode(self, x, training=False):\n","        mu, logvar = tf.split(\n","            self.encoder(x, training=training),\n","            num_or_size_splits=2, \n","            axis=1\n","        )\n","        return mu, logvar\n","    \n","    def reparameterize(self, mu, logvar):\n","        \"\"\"get z\"\"\"\n","        epsilon = tf.random.normal(shape=mu.shape)\n","        return mu + epsilon * tf.exp(logvar * .5)\n","    \n","    def decode(self, z, training=False):\n","        return tf.sigmoid(self.decoder(z, training=training))\n","\n","    def call(self, input, training=False):\n","        mu, logvar = self.encode(input, training=training)\n","        z = self.reparameterize(mu, logvar)\n","        output = self.decode(z, training=training)\n","        return output, z, mu, logvar\n","    \n","    def train_step(self, data):\n","        images, _ = data\n","        # images = [B X 28 X 28] -> [B X 28 X 28 X 1]\n","        images = tf.cast(tf.expand_dims(images, -1), tf.float32)\n","            \n","        with tf.GradientTape() as tape:\n","            outputs, z, z_mu, z_logvar = self(images, training=True)\n","            \n","            # reconstuction loss\n","            recon_loss = tf.reduce_mean(\n","                tf.reduce_sum(\n","                    tf.keras.losses.mae(images, outputs),\n","                    axis=(1, 2)\n","                )\n","            )\n","\n","            # kld_loss\n","            kl_loss = -0.5 * (1 + z_logvar - tf.square(z_mu) - tf.exp(z_logvar))\n","            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n","\n","            # total_loss\n","            total_loss = recon_loss + kl_loss\n","        \n","        # compute gradients\n","        trainable_vars = self.trainable_variables\n","        gradients = tape.gradient(total_loss, trainable_vars)\n","\n","        # update weights\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","\n","        # update the metrics\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.recon_loss_tracker.update_state(recon_loss)\n","        self.kl_loss_tracker.update_state(kl_loss)\n","\n","        # tensorboard image update\n","        tf.summary.image(\"train_source_img\", images, max_outputs=5)\n","        tf.summary.image(\"train_recon_img\", outputs, max_outputs=5)\n","\n","        # return a dict mapping metrics names to current values\n","        logs = {m.name: m.result() for m in self.metrics}\n","        return logs\n","\n","    def test_step(self, data):\n","        images, _ = data\n","        # images = [B X 28 X 28] -> [B X 28 X 28 X 1]\n","        images = tf.cast(tf.expand_dims(images, -1), tf.float32)\n","            \n","        outputs, z, z_mu, z_logvar = self(images, training=False)\n","            \n","        # reconstuction loss\n","        recon_loss = tf.reduce_mean(\n","            tf.reduce_sum(\n","                tf.keras.losses.mae(images, outputs),\n","                axis=(1, 2)\n","            )\n","        )\n","\n","        # kld_loss\n","        kl_loss = -0.5 * (1 + z_logvar - tf.square(z_mu) - tf.exp(z_logvar))\n","        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n","\n","        # total_loss\n","        total_loss = recon_loss + kl_loss\n","\n","        # update the metrics\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.recon_loss_tracker.update_state(recon_loss)\n","        self.kl_loss_tracker.update_state(kl_loss)\n","\n","        # tensorboard image update\n","        tf.summary.image(\"val_source_img\", images, max_outputs=5)\n","        tf.summary.image(\"val_recon_img\", outputs, max_outputs=5)\n","\n","        # return a dict mapping metrics names to current values\n","        logs = {m.name: m.result() for m in self.metrics}\n","        return logs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SopEf-gWLq_d"},"source":["\n","## Configuration 정의"]},{"cell_type":"code","metadata":{"id":"1tmuu8gaLpwf"},"source":["# data configuration\n","data_fashion_mnist_cfg: dict = {\n","    \"n_class\": 10,\n","    \"train_val_split\": [0.9, 0.1],\n","    \"train_val_shuffle\": True,\n","    \"train_val_shuffle_buffer_size\": 1024,\n","    \"test_shuffle\": False,\n","    \"test_shuffle_buffer_size\": 1024,\n","}\n","\n","# model configuration\n","model_mnist_vae_cfg: dict = {\n","    \"name\": \"VAE\",\n","    \"data_normalize\": True,\n","    \"latent_dim\": 2,\n","    \"enc\": {\n","        \"conv1\": {\n","            \"filters\": 32,\n","            \"kernel_size\": 3,\n","            \"strides\": [2, 2],\n","            \"activation\": \"relu\",\n","        },\n","        \"conv2\": {\n","            \"filters\": 64,\n","            \"kernel_size\": 3,\n","            \"strides\": [2, 2],\n","            \"activation\": \"relu\",\n","        },\n","        \"out_fc\": {\n","            \"units\": 4, # latent_dim * 2 (mu, log_var)\n","        },\n","    },\n","    \"dec\": {\n","        \"in_fc\": {\n","            \"units\": 7*7*32,\n","        },\n","        \"reshape_shape\": [7, 7, 32],\n","        \"tr_conv1\": {\n","            \"filters\": 64,\n","            \"kernel_size\": 3,\n","            \"strides\": [2, 2],\n","            \"padding\": \"same\",\n","            \"activation\": \"relu\",\n","        },\n","        \"tr_conv2\": {\n","            \"filters\": 32,\n","            \"kernel_size\": 3,\n","            \"strides\": [2, 2],\n","            \"padding\": \"same\",\n","            \"activation\": \"relu\",\n","        },\n","        \"tr_conv3\": {\n","            \"filters\": 1,\n","            \"kernel_size\": 3,\n","            \"strides\": [1, 1],\n","            \"padding\": \"same\",\n","        },\n","    }\n","}\n","model_mnist_gan_cfg: dict = {\n","    \"name\": \"GAN\",\n","    \"data_normalize\": True,\n","    \"latent_dim\": 64,\n","    \"dis\": {\n","        \"conv1\": {\n","            \"filters\": 32,\n","            \"kernel_size\": 3,\n","            \"strides\": [2, 2],\n","            \"activation\": \"relu\",\n","            \"padding\": \"same\",\n","        },\n","        \"conv2\": {\n","            \"filters\": 64,\n","            \"kernel_size\": 3,\n","            \"strides\": [2, 2],\n","            \"activation\": \"relu\",\n","            \"padding\": \"same\",\n","        },\n","    },\n","    \"gen\": {\n","        \"in_fc\": {\n","            \"units\": 7*7*32,\n","        },\n","        \"reshape_shape\": [7, 7, 32],\n","        \"tr_conv1\": {\n","            \"filters\": 64,\n","            \"kernel_size\": 3,\n","            \"strides\": [2, 2],\n","            \"padding\": \"same\",\n","            \"use_bias\": False,\n","            \"activation\": \"relu\",\n","        },\n","        \"tr_conv2\": {\n","            \"filters\": 32,\n","            \"kernel_size\": 3,\n","            \"strides\": [2, 2],\n","            \"padding\": \"same\",\n","            \"use_bias\": False,\n","            \"activation\": \"relu\",\n","        },\n","        \"tr_conv3\": {\n","            \"filters\": 1,\n","            \"kernel_size\": 3,\n","            \"strides\": [1, 1],\n","            \"use_bias\": False,\n","            \"padding\": \"same\",\n","            \"activation\": \"sigmoid\",\n","        },\n","    }\n","}\n","\n","\n","# optimizer_configs\n","adam_warmup_lr_sch_opt_cfg = {\n","    \"optimizer\": {\n","        \"name\": \"Adam\",\n","        \"other_kwargs\": {},\n","    },\n","    \"lr_scheduler\": {\n","        \"name\": \"LinearWarmupLRSchedule\",\n","        \"kwargs\": {\n","            \"lr_peak\": 1e-3,\n","            \"warmup_end_steps\": 1500,\n","        }\n","    }\n","}\n","radam_no_lr_sch_opt_cfg = {\n","    \"optimizer\": {\n","        \"name\": \"RectifiedAdam\",\n","        \"learning_rate\": 1e-3,\n","        \"other_kwargs\": {},\n","    },\n","    \"lr_scheduler\": None\n","}\n","\n","gan_opt_cfg = {\n","    \"discriminator\": {\n","        \"optimizer\": {\n","            \"name\": \"RMSprop\",\n","            \"learning_rate\": 0.005,\n","            \"other_kwargs\": {},\n","        },\n","        \"lr_scheduler\": None,\n","    },\n","    \"generator\": {\n","        \"optimizer\": {\n","            \"name\": \"Adam\",\n","            \"learning_rate\": 0.001,\n","            \"other_kwargs\": {\n","                \"beta_1\": 0.5\n","            },\n","        },\n","        \"lr_scheduler\": None,\n","    }\n","}\n","\n","# train_cfg\n","train_cfg: dict = {\n","    \"train_batch_size\": 256,\n","    \"val_batch_size\": 32,\n","    \"test_batch_size\": 32,\n","    \"max_epochs\": 50,\n","    \"distribute_strategy\": \"MirroredStrategy\",\n","}\n","\n","_merged_cfg_presets = {\n","    \"vae_fashion_mnist_radam\": {\n","        \"data\": data_fashion_mnist_cfg,\n","        \"model\": model_mnist_vae_cfg,\n","        \"opt\": radam_no_lr_sch_opt_cfg,\n","        \"train\": train_cfg\n","    },\n","    \"gan_fashion_mnist\": {\n","        \"data\": data_fashion_mnist_cfg,\n","        \"model\": model_mnist_gan_cfg,\n","        \"opt\": gan_opt_cfg,\n","        \"train\": train_cfg\n","    }\n","}\n","\n","### hydra composition ###\n","# clear hydra instance \n","hydra.core.global_hydra.GlobalHydra.instance().clear()\n","\n","# register preset configs\n","register_config(_merged_cfg_presets)\n","\n","# initialization\n","hydra.initialize(config_path=None)\n","\n","using_config_key = \"gan_fashion_mnist\"\n","cfg = hydra.compose(using_config_key)\n","\n","# define & override log_cfg\n","model_name = cfg.model.name\n","run_dirname = \"fastcampus_generative_model_tutorials_tf\"\n","run_name = f\"{datetime.now().isoformat(timespec='seconds')}-{using_config_key}-{model_name}\"\n","log_dir = os.path.join(drive_project_root, \"runs\", run_dirname, run_name)\n","\n","log_cfg = {\n","    \"run_name\": run_name,\n","    \"callbacks\": {\n","        \"TensorBoard\": {\n","            \"log_dir\": log_dir,\n","            \"update_freq\": 10,\n","        },\n","    },\n","    \"wandb\": {\n","        \"project\": \"fastcampus_generative_model_tutorials_tf\",\n","        \"name\": run_name,\n","        \"tags\": [\"fastcampus_generative_model_tutorials_tf\"],\n","        \"reinit\": True,\n","        \"sync_tensorboard\": True\n","    }\n","}\n","\n","# unlock struct of config & set log config\n","OmegaConf.set_struct(cfg, False)\n","cfg.log = log_cfg\n","\n","# relock config\n","OmegaConf.set_struct(cfg, True)\n","print(OmegaConf.to_yaml(cfg))\n","\n","# save yaml\n","# with open(os.path.join(log_dir, \"config.yaml\")) as f:\n","# with open(\"config.yaml\", \"w\") as f:\n","#     OmegaConf.save(cfg, f)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yARForQbUcbx"},"source":["def get_distribute_strategy(strategy_name: str, **kwargs):\n","    return getattr(tf.distribute, strategy_name)(**kwargs)\n","\n","distribute_strategy = get_distribute_strategy(cfg.train.distribute_strategy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X89D1QCGJXTN"},"source":["with distribute_strategy.scope():\n","    # 데이터 셋 정의 \n","    fashion_mnist = tf.keras.datasets.fashion_mnist\n","    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n","    \n","    # normalization\n","    if cfg.model.data_normalize:\n","        x_train = x_train / 255.0\n","        x_test = x_test / 255.0\n","\n","    # train/val splits\n","    assert sum(cfg.data.train_val_split) == 1.0\n","    train_size = int(len(x_train) * cfg.data.train_val_split[0])\n","    val_size = len(x_train) - train_size\n","\n","    dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n","    if cfg.data.train_val_shuffle:\n","        dataset = dataset.shuffle(\n","            buffer_size=cfg.data.train_val_shuffle_buffer_size,\n","        )\n","    if cfg.data.test_shuffle:\n","        test_dataset = test_dataset.shuffle(\n","            buffer_size=cfg.data.test_shuffle_buffer_size,\n","        )\n","\n","    train_dataset = dataset.take(train_size)\n","    val_dataset = dataset.skip(train_size)\n","    print(len(train_dataset), len(val_dataset), len(dataset), len(test_dataset))\n","    \n","    # dataloader 정의\n","    train_batch_size = cfg.train.train_batch_size\n","    val_batch_size = cfg.train.val_batch_size\n","    test_batch_size = cfg.train.test_batch_size\n","\n","    train_dataloader = train_dataset.batch(train_batch_size, drop_remainder=True)\n","    val_dataloader = val_dataset.batch(val_batch_size, drop_remainder=True)\n","    test_dataloader = test_dataset.batch(test_batch_size, drop_remainder=True)\n","\n","sample_example = next(iter(train_dataloader))\n","print(sample_example)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9KyfbS4RzQ7"},"source":["# 모델 정의 \n","def get_model(cfg: DictConfig):\n","    if cfg.model.name == \"VAE\":\n","        model = VAE(cfg)\n","    elif cfg.model.name == \"GAN\":\n","        model = GAN(cfg)\n","    else:\n","        raise NotImplementedError()\n","    return model\n","\n","\n","with distribute_strategy.scope():\n","    model = get_model(cfg)\n","\n","    # define optimizer & scheduler\n","    if cfg.model.name == \"GAN\":\n","        d_optimizer, d_scheduler = get_optimizer_element(\n","            cfg.opt.discriminator.optimizer, cfg.opt.discriminator.lr_scheduler\n","        )\n","        g_optimizer, g_scheduler = get_optimizer_element(\n","            cfg.opt.generator.optimizer, cfg.opt.generator.lr_scheduler\n","        )\n","        model.compile(\n","            d_optimizer=d_optimizer,\n","            g_optimizer=g_optimizer,\n","        )\n","    else:\n","        optimizer, scheduler = get_optimizer_element(\n","            cfg.opt.optimizer, cfg.opt.lr_scheduler\n","        )\n","        model.compile(optimizer=optimizer)\n","        model.build((train_batch_size, 28, 28, 1))\n","        model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eo3jhwhHVOqu"},"source":["# get callbacks\n","callbacks = get_callbacks(cfg.log)\n","\n","# wandb setup\n","wandb.init(\n","    config=flatten_dict(cfg),\n","    **cfg.log.wandb\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIXfPYDeWqTH"},"source":["%reload_ext tensorboard\n","%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/fastcampus_generative_model_tutorials_tf\n","\n","model.fit(\n","    train_dataloader,\n","    validation_data=val_dataloader,\n","    epochs=cfg.train.max_epochs,\n","    callbacks=callbacks,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T5SnIKTKVOab"},"source":["## VAE Model testing"]},{"cell_type":"code","metadata":{"id":"2b-2TiKdZdWd"},"source":["def get_latent_img(model, n, single_img_size=28):\n","    \"\"\"plot n x n images decoded from the latent_space\"\"\"\n","\n","    norm = tfp.distributions.Normal(0, 1)\n","    grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n","    grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n","    width = single_img_size * n\n","    height = width\n","    image = np.zeros((height, width))\n","    \n","    for i, yi in enumerate(grid_y):\n","        for j, xi in enumerate(grid_x):\n","            z = np.array([[xi, yi]])\n","            x_decoded = model.sample(z)\n","            # x_decoded = model.decode(z)\n","            digit = tf.reshape(x_decoded[0], (single_img_size, single_img_size))        \n","            image[i*single_img_size:(i + 1)*single_img_size,\n","                  j*single_img_size:(j + 1)*single_img_size] = digit.numpy()\n","    return image\n","\n","latent_img = get_latent_img(model, n=20)\n","plt.figure(figsize=(10, 10))\n","plt.imshow(latent_img, cmap=\"Greys_r\")\n","plt.axis(\"Off\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qau4Vi0zZgm3"},"source":[""],"execution_count":null,"outputs":[]}]}