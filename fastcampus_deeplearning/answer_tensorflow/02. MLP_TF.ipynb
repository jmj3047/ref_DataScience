{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CUNw8dNBwA4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/content/drive/MyDrive/#fastcampus\")\n",
    "drive_project_root = \"/content/drive/MyDrive/#fastcampus\"\n",
    "!pip install -r \"/content/drive/MyDrive/#fastcampus/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBxZXWDEHbkh"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdeNqGVRIJzv"
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mR6QoAFuIMY0"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zawdEF0vIO-9"
   },
   "outputs": [],
   "source": [
    "# define gpus strategy\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ_NevzbKGBk"
   },
   "source": [
    "## 데이터 및 데이터로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X89D1QCGJXTN"
   },
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    # 데이터 셋 정의 \n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    \n",
    "    # normalization\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "\n",
    "    # train/val splits\n",
    "    train_size = int(len(x_train) * 0.9)\n",
    "    val_size = len(x_train) - train_size\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=1024)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(buffer_size=1024)\n",
    "\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    val_dataset = dataset.skip(train_size)\n",
    "    print(len(train_dataset), len(val_dataset), len(dataset), len(test_dataset))\n",
    "    \n",
    "    # dataloader 정의\n",
    "    train_batch_size = 100\n",
    "    val_batch_size = 10\n",
    "    test_batch_size = 100\n",
    "\n",
    "    train_dataloader = train_dataset.batch(train_batch_size, drop_remainder=True)\n",
    "    val_dataloader = val_dataset.batch(val_batch_size, drop_remainder=True)\n",
    "    test_dataloader = test_dataset.batch(test_batch_size, drop_remainder=True)\n",
    "\n",
    "sample_example = next(iter(train_dataloader))\n",
    "print(sample_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGRtSVzNJmck"
   },
   "outputs": [],
   "source": [
    "# plot figure\n",
    "plt.figure(figsize=(10, 10))\n",
    "for c in range(16):\n",
    "    plt.subplot(4, 4, c+1)\n",
    "    plt.imshow(x_train[c].reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LwF7hrxLzfP"
   },
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54FXO6o1J654"
   },
   "outputs": [],
   "source": [
    "\n",
    "# model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#   tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self, input_dim: int, h1_dim: int, h2_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.linear1 = tf.keras.layers.Dense(input_dim=input_dim, units=h1_dim)\n",
    "        self.linear2 = tf.keras.layers.Dense(units=h2_dim)\n",
    "        self.linear3 = tf.keras.layers.Dense(units=out_dim)\n",
    "        self.relu = tf.nn.relu\n",
    "    \n",
    "    def call(self, input, training=False):\n",
    "        x = self.flatten(input)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        out = self.linear3(x)\n",
    "        out = tf.nn.softmax(out)\n",
    "        return out\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        images, labels = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self(images, training=True)\n",
    "            preds = tf.argmax(outputs, 1)\n",
    "\n",
    "            loss = self.compiled_loss(\n",
    "                labels, outputs\n",
    "            )\n",
    "        \n",
    "        # compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # update the metrics\n",
    "        self.compiled_metrics.update_state(labels, preds)\n",
    "\n",
    "        # return a dict mapping metrics names to current values\n",
    "        logs = {m.name: m.result() for m in self.metrics}\n",
    "        logs.update({\"loss\": loss})\n",
    "        return logs\n",
    "\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        images, labels = data\n",
    "        outputs = self(images, training=False)\n",
    "        preds = tf.argmax(outputs, 1)\n",
    "        loss = self.compiled_loss(\n",
    "            labels, outputs\n",
    "        )\n",
    "\n",
    "        # update the metrics\n",
    "        self.compiled_metrics.update_state(labels, preds)\n",
    "\n",
    "        # return a dict mapping metrics names to current values\n",
    "        logs = {m.name: m.result() for m in self.metrics}       \n",
    "        logs.update({\"test_loss\": loss})\n",
    "        return logs      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9KyfbS4RzQ7"
   },
   "outputs": [],
   "source": [
    "# 모델 정의 \n",
    "n_class = 10\n",
    "max_epoch = 50\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    model = MLP(28*28*1, 128, 64, n_class)\n",
    "    model_name = type(model).__name__\n",
    "\n",
    "    # define loss\n",
    "    loss_function = tf.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    # define optimizer\n",
    "    lr = 1e-3\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    model.compile(\n",
    "        loss=loss_function,\n",
    "        optimizer=optimizer,\n",
    "        metrics=[tf.keras.metrics.Accuracy()],\n",
    "    )\n",
    "\n",
    "    model.build((1, 28*28*1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eo3jhwhHVOqu"
   },
   "outputs": [],
   "source": [
    "# define logging & callbacks\n",
    "log_interval = 100\n",
    "run_name = f\"{datetime.now()}-{model_name}\"\n",
    "run_dirname = \"dnn-tutorial-fashion-mnist-runs-tf\"\n",
    "log_dir = os.path.join(drive_project_root, \"runs\", run_dirname, run_name)\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir, update_freq=log_interval\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIXfPYDeWqTH"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/\n",
    "\n",
    "model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=max_epoch,\n",
    "    callbacks=[tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5SnIKTKVOab"
   },
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bt7d0YMxXd5w"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3NIlcw5YBJc"
   },
   "outputs": [],
   "source": [
    "test_labels_list = []\n",
    "test_preds_list = []\n",
    "test_outputs_list = []\n",
    "\n",
    "for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc=\"testing\")):\n",
    "    with mirrored_strategy.scope():\n",
    "        test_outputs = model(test_images)\n",
    "    test_preds = tf.argmax(test_outputs, 1)\n",
    "\n",
    "    final_outs = test_outputs.numpy()\n",
    "    test_outputs_list.extend(final_outs)\n",
    "    test_preds_list.extend(test_preds.numpy())\n",
    "    test_labels_list.extend(test_labels.numpy())\n",
    "\n",
    "test_preds_list = np.array(test_preds_list)\n",
    "test_labels_list = np.array(test_labels_list)\n",
    "\n",
    "test_accuracy = np.mean(test_preds_list == test_labels_list)\n",
    "print(f\"\\nacc: {test_accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7TXScWnZAPR"
   },
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh = {}\n",
    "n_class = 10\n",
    "\n",
    "for i in range(n_class):\n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:, i], pos_label=i)\n",
    "\n",
    "# plot\n",
    "for i in range(n_class):\n",
    "    plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n",
    "plt.title(\"Multi-class ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "auc_score = roc_auc_score(test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\")\n",
    "print(f\"auc_score: {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b-2TiKdZdWd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qau4Vi0zZgm3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO7/CM6jCNMTZwkfOgm6W6t",
   "collapsed_sections": [],
   "name": "02. MLP_TF.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
