{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08-1. Transformer Seq2seq TF.ipynb","private_outputs":true,"provenance":[{"file_id":"1pbpR0WGGXY2Odh4QDkd5YxA1Ab2Umoo7","timestamp":1636646633558},{"file_id":"1p3dDvm1_3oOGjxKSMVLAUgss95EMZ8sf","timestamp":1636642636450},{"file_id":"1-Kuw2KqbixGHAmKXAQv1_FygXgZlXxE0","timestamp":1636634164801},{"file_id":"14UhxSABuj-M683k4TilUDhQIo39HFK-t","timestamp":1634019312693},{"file_id":"1CBRS5ajK2WVXMEN97owUmh6yhmljiILI","timestamp":1634015371559},{"file_id":"1bRDRTJmGm80o_sWIacmyt-pUnHfqOKqE","timestamp":1634012243448},{"file_id":"1apCHsYMGF0a1zGJeJe5WhAGyUTbehmi7","timestamp":1633794411943},{"file_id":"1Yq_LYjN0_deqoBFaD_ZJFfoes_VYtBVN","timestamp":1633790134053}],"collapsed_sections":[],"authorship_tag":"ABX9TyNjSCT0MQ0SE9KIXHERJz2O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7CUNw8dNBwA4"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","import os\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/#fastcampus\")\n","drive_project_root = \"/content/drive/MyDrive/#fastcampus\"\n","!pip install -r \"/content/drive/MyDrive/#fastcampus/requirements.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kBxZXWDEHbkh"},"source":["from typing import Optional\n","from typing import List\n","from typing import Dict\n","from typing import Tuple\n","\n","import io\n","import re\n","import unicodedata\n","import time\n","from datetime import datetime\n","import random\n","\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import matplotlib.pyplot as ticker\n","from omegaconf import OmegaConf\n","from omegaconf import DictConfig\n","import hydra\n","from hydra.core.config_store import ConfigStore\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","import wandb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QlfSWYBuJvXi"},"source":["from config_utils_tf import flatten_dict\n","from config_utils_tf import register_config\n","from config_utils_tf import get_optimizer_element\n","from config_utils_tf import get_callbacks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OdeNqGVRIJzv"},"source":["tf.config.list_physical_devices()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mR6QoAFuIMY0"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aknbjV1NLAGD"},"source":["## Data 다운로드 및 전처리."]},{"cell_type":"code","metadata":{"id":"VYTBI0gDCA75"},"source":["# Download the file\n","data_root = os.path.join(drive_project_root, \"data\", \"anki_spa_eng\")\n","if not os.path.exists(data_root):\n","    os.mkdir(data_root)\n","\n","data_path = os.path.join(data_root, \"spa-eng.zip\")\n","path_to_zip = tf.keras.utils.get_file(\n","    data_path,\n","    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n","    extract=True,\n","    cache_dir=data_root\n",")\n","\n","path_to_file = os.path.join(\n","    os.path.dirname(path_to_zip),\n","    \"datasets\",\n","    \"spa-eng\",\n","    \"spa.txt\",\n",")\n","print(path_to_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LeYe7E2KDGBR"},"source":["# 전처리\n","def unicode_to_ascii(s):\n","    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")\n","\n","def preprocess_sentence(w):\n","    # ascii 로 변환 및 소문자로 변환\n","    w = unicode_to_ascii(w.lower().strip())\n","\n","    # 단어와 단어 뒤에 오는 구두점(.) 사이에 공백을 생성\n","    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","    w = re.sub(r'[\" \"]+', \" \", w)\n","\n","    # (a-z, A-Z, [?.!,¿] 을 제외한 모든 것을 공백으로 대체)\n","    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n","    w = w.strip()\n","\n","    # 모델의 앞뒤에 start, end 토큰 추가.\n","    w = \"<start> \" + w + \" <end>\"\n","    return w\n","\n","\n","def create_dataset(path: str, num_examples: Optional[int]=None):\n","    lines = io.open(path, encoding=\"UTF-8\").read().strip().split(\"\\n\")\n","\n","    word_pairs = [[preprocess_sentence(w) for w in l.split(\"\\t\")] for l in lines[:num_examples]]\n","\n","    return zip(*word_pairs)\n","\n","\n","en, sp = create_dataset(path_to_file)\n","print(en[-1])\n","print(sp[-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7hP5kWUFte-"},"source":["# Tokenizer 정의, 최종적으로 쓸 데이터 정리.\n","\n","def tokenize(lang):\n","    lang_tokenizer = Tokenizer(filters=\"\")\n","    lang_tokenizer.fit_on_texts(lang)\n","\n","    tensor = lang_tokenizer.texts_to_sequences(lang)\n","    tensor = pad_sequences(tensor, padding=\"post\")\n","\n","    return tensor, lang_tokenizer\n","\n","def load_dataset(path, num_examples=None):\n","    tar_lang, src_lang = create_dataset(path, num_examples) # en, sp\n","\n","    src_tensor, src_tokenizer = tokenize(src_lang)\n","    tar_tensor, tar_tokenizer = tokenize(tar_lang)\n","\n","    return src_tensor, tar_tensor, src_tokenizer, tar_tokenizer\n","\n","\n","# 언어 데이터셋을 불러오기.\n","# num_examples = 30000\n","num_examples = 100000\n","src_tensor, tar_tensor, src_tokenizer, tar_tokenizer = load_dataset(\n","    path_to_file, num_examples\n",")\n","\n","max_tar_len, max_src_len = tar_tensor.shape[1], src_tensor.shape[1]\n","\n","src_vocab_size = len(src_tokenizer.word_index) + 1\n","tar_vocab_size = len(tar_tokenizer.word_index) + 1\n","\n","print(src_vocab_size, tar_vocab_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3JNJuccAHjmY"},"source":["print(tar_tensor[-1])\n","print(tar_tokenizer.word_index)\n","for i in tar_tensor[-1]:\n","    if i == 0:\n","        break\n","    print(i, tar_tokenizer.index_word[i])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8LwF7hrxLzfP"},"source":["## 모델 정의"]},{"cell_type":"code","metadata":{"id":"fiV5XAEDImlt"},"source":["class GRUEncoder(tf.keras.Model):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.enc_emb = tf.keras.layers.Embedding(\n","            cfg.data.src.vocab_size,\n","            cfg.model.enc.embed_size\n","        )\n","        self.enc_gru = tf.keras.layers.GRU(\n","            cfg.model.enc.rnn.units,\n","            return_state=True,\n","            return_sequences=True,\n","            recurrent_initializer=\"glorot_uniform\"\n","        )\n","    \n","    def call(self, src_tokens, state=None, training=False):\n","        embed_enc = self.enc_emb(src_tokens)\n","        enc_outputs, enc_states = self.enc_gru(\n","            embed_enc, initial_state=state\n","        )\n","        return enc_outputs, enc_states\n","\n","\n","class GRUDecoder(tf.keras.Model):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.dec_emb = tf.keras.layers.Embedding(\n","            cfg.data.tar.vocab_size,\n","            cfg.model.dec.embed_size\n","        )\n","        self.dec_gru = tf.keras.layers.GRU(\n","            cfg.model.dec.rnn.units,\n","            return_state=True,\n","            return_sequences=True,\n","            recurrent_initializer=\"glorot_uniform\"\n","        )\n","        self.fc = tf.keras.layers.Dense(cfg.data.tar.vocab_size)\n","    \n","    def call(self, tar_tokens, state=None, training=False):\n","        embed_dec = self.dec_emb(tar_tokens)\n","        dec_outputs, dec_states = self.dec_gru(\n","            embed_dec, initial_state=state\n","        )\n","        final_outputs = self.fc(dec_outputs)\n","        return final_outputs, dec_states, None # None는 추후 attention 등 추가시 인터페이스 통일 위함"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EVFGsb4UgXo1"},"source":["# Attention 모델 정의\n","class BahdanauAttention(tf.keras.layers.Layer):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.fc1 = tf.keras.layers.Dense(cfg.model.attention.latent_dim)\n","        self.fc2 = tf.keras.layers.Dense(cfg.model.attention.latent_dim)\n","        self.fc_score = tf.keras.layers.Dense(1)\n","    \n","    def call(self, query, value):\n","        # query = hidden, value = enc_outputs\n","        query_with_time_axis = tf.expand_dims(query, 1) # [B, L, hidden_dim] # 보통 L=1이다.\n","\n","        score = self.fc_score(\n","            tf.nn.tanh(\n","                self.fc1(query_with_time_axis) + self.fc2(value)\n","            )\n","        ) # [B, L, hidden_dim] -> [B, L, 1]\n","\n","        attention_weights = tf.nn.softmax(score, axis=1) # [B, L, 1]\n","\n","        context_vector = attention_weights * value # [B, hidden]\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\n","        return context_vector, attention_weights\n","\n","\n","class AttentionalGRUDecoder(tf.keras.Model):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.dec_emb = tf.keras.layers.Embedding(\n","            cfg.data.tar.vocab_size,\n","            cfg.model.dec.embed_size\n","        )\n","        self.dec_gru = tf.keras.layers.GRU(\n","            cfg.model.dec.rnn.units,\n","            return_state=True,\n","            return_sequences=True,\n","            recurrent_initializer=\"glorot_uniform\"\n","        )\n","        self.attention = BahdanauAttention(cfg)\n","        self.fc = tf.keras.layers.Dense(cfg.data.tar.vocab_size)\n","\n","\n","    def call(self, tar_tokens, hidden, enc_output):\n","        # enc_output: [B, L, hidden_dim]\n","        context_vector, attention_weights = self.attention(hidden, enc_output)\n","\n","        x = self.dec_emb(tar_tokens)\n","\n","        # embedding된 tar_token과 context_vector를 concat으로 합친다.\n","        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","        dec_outputs, dec_states = self.dec_gru(x)\n","        dec_outputs = tf.reshape(dec_outputs, (-1, dec_outputs.shape[2])) # [B * 1, embedding_dim + hidden_dim]\n","        \n","        final_outputs = self.fc(dec_outputs) # [B, Vocab Size]\n","        return final_outputs, dec_states, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pU3-2XJivz_J"},"source":["# Transformer layer 들 정의.\n","\n","# 1. PositionalEmbedding \n","class PositionalEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, sequence_size, vocab_size, embed_dim):\n","        super().__init__()\n","        self.sequence_size = sequence_size\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","\n","        self.token_embedding = tf.keras.layers.Embedding(\n","            input_dim=self.vocab_size, output_dim=self.embed_dim\n","        )\n","        self.position_embedding = tf.keras.layers.Embedding(\n","            input_dim=self.sequence_size, output_dim=self.embed_dim\n","        )\n","    \n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update({\n","            \"sequence_size\": self.sequence_size,\n","            \"vocab_size\": self.vocab_size,\n","            \"embed_dim\": self.embed_dim,\n","            \"token_embedding\": self.token_embedding,\n","            \"position_embedding\": self.position_embedding,\n","        })\n","        return config\n","    \n","    \n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embedding(inputs)\n","        embedded_positions = self.position_embedding(positions)\n","        return embedded_tokens + embedded_positions\n","    \n","    def compute_mask(self, inputs, mask=None):\n","        # pad masking.\n","        return tf.math.not_equal(inputs, 0)\n","\n","\n","# 2. TransformerEncoder\n","class TransformerEncoder(tf.keras.layers.Layer):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.embed_dim = cfg.model.enc.embed_dim\n","        self.dense_dim = cfg.model.enc.tr.dense_dim\n","        self.num_heads = cfg.model.enc.tr.num_heads\n","        self.supports_masking = cfg.model.enc.tr.supports_masking\n","\n","        self.attention = tf.keras.layers.MultiHeadAttention(\n","            num_heads=self.num_heads, key_dim=self.embed_dim\n","        )\n","        self.dense_proj = tf.keras.Sequential([\n","            tf.keras.layers.Dense(self.dense_dim, activation=\"relu\"),\n","            tf.keras.layers.Dense(self.embed_dim)\n","        ])\n","        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n","        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n","\n","        self.positional_embedding = PositionalEmbedding(\n","            cfg.data.src.max_len,\n","            cfg.data.src.vocab_size,\n","            cfg.model.enc.embed_dim\n","        )\n","    \n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update({\n","            \"cfg\": self.cfg,\n","            \"embed_dim\": self.embed_dim,\n","            \"dense_dim\": self.dense_dim,\n","            \"num_heads\": self.num_heads,\n","            \"supports_masking\": self.supports_masking,\n","            \"attention\": self.attention,\n","            \"dense_proj\": self.dense_proj,\n","            \"layernorm_1\": self.layernorm_1,\n","            \"layernorm_2\": self.layernorm_2,\n","            \"positional_embedding\": self.positional_embedding,\n","        })\n","        return config\n","    \n","    def call(self, inputs, padding_mask=None, training=False):\n","        inputs = self.positional_embedding(inputs)\n","        if padding_mask is not None:\n","            padding_mask = tf.cast(\n","                padding_mask[:, tf.newaxis, tf.newaxis, :],\n","                dtype=\"int32\"\n","            )\n","        attention_output = self.attention(\n","            query=inputs,\n","            value=inputs,\n","            key=inputs,\n","            attention_mask=padding_mask,\n","            training=training\n","        )\n","        proj_input = self.layernorm_1(inputs + attention_output) # skip_connect + norm\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output) # skip_connect + norm\n","\n","\n","# 3. TransformerDecoder (encoder와 decoder를 잇는 attention도 존재!)\n","class TransformerDecoder(tf.keras.layers.Layer):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.embed_dim = cfg.model.dec.embed_dim\n","        self.latent_dim = cfg.model.dec.tr.latent_dim\n","        self.num_heads = cfg.model.dec.tr.num_heads\n","        self.supports_masking = cfg.model.dec.tr.supports_masking\n","\n","        self.attention_1 = tf.keras.layers.MultiHeadAttention(\n","            num_heads=self.num_heads, key_dim=self.embed_dim\n","        )\n","        self.attention_2 = tf.keras.layers.MultiHeadAttention(\n","            num_heads=self.num_heads, key_dim=self.embed_dim\n","        )\n","        self.dense_proj = tf.keras.Sequential([\n","            tf.keras.layers.Dense(self.latent_dim, activation=\"relu\"),\n","            tf.keras.layers.Dense(self.embed_dim)\n","        ])\n","        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n","        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n","        self.layernorm_3 = tf.keras.layers.LayerNormalization()\n","\n","        self.positional_embedding = PositionalEmbedding(\n","            cfg.data.src.max_len,\n","            cfg.data.src.vocab_size,\n","            cfg.model.dec.embed_dim\n","        )\n","        self.dropout = tf.keras.layers.Dropout(cfg.model.dropout_prob)\n","        self.out_dense = tf.keras.layers.Dense(cfg.data.tar.vocab_size)\n","    \n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update({\n","            \"cfg\": self.cfg,\n","            \"embed_dim\": self.embed_dim,\n","            \"latent_dim\": self.latent_dim,\n","            \"num_heads\": self.num_heads,\n","            \"supports_masking\": self.supports_masking,\n","            \"attention_1\": self.attention_1,\n","            \"attention_2\": self.attention_2,\n","            \"dense_proj\": self.dense_proj,\n","            \"layernorm_1\": self.layernorm_1,\n","            \"layernorm_2\": self.layernorm_2,\n","            \"layernorm_3\": self.layernorm_3,\n","            \"positional_embedding\": self.positional_embedding,\n","            \"dropout\": self.dropout,\n","            \"out_dense\": self.out_dense,\n","        })\n","        return config\n","    \n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = tf.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = tf.range(sequence_length)[:, tf.newaxis]\n","        j = tf.range(sequence_length)\n","        mask = tf.cast(i >= j, dtype=\"int32\")\n","        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        mult = tf.concat(\n","            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n","            axis=0,\n","        )\n","        return tf.tile(mask, mult)\n","\n","    def call(self, inputs, encoder_outputs, padding_mask=None, training=False):\n","        inputs = self.positional_embedding(inputs)\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","        if padding_mask is not None:\n","            padding_mask = tf.cast(\n","                padding_mask[:, tf.newaxis, tf.newaxis, :],\n","                dtype=\"int32\"\n","            )\n","            padding_mask = tf.minimum(padding_mask, causal_mask)\n","        \n","        # masked dec self-attention\n","        attention_output_1 = self.attention_1(\n","            query=inputs,\n","            value=inputs,\n","            key=inputs,\n","            attention_mask=causal_mask,\n","            training=training\n","        )\n","        out_1 = self.layernorm_1(inputs + attention_output_1) # skip_connect + norm\n","\n","        # migrate with encoder\n","        attention_output_2 = self.attention_2(\n","            query=out_1,\n","            value=encoder_outputs,\n","            key=encoder_outputs,\n","            attention_mask=padding_mask,\n","            training=training\n","        )\n","        out_2 = self.layernorm_2(out_1 + attention_output_2) # skip_connect + norm\n","\n","        proj_output = self.dense_proj(out_2)\n","        out_3 = self.layernorm_3(out_2 + proj_output) # skip_connect + norm\n","        out_3 = self.dropout(out_3, training=training)\n","        return self.out_dense(out_3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SopEf-gWLq_d"},"source":["## Configuration 정의"]},{"cell_type":"code","metadata":{"id":"1tmuu8gaLpwf"},"source":["# data configuration\n","data_anki_spa_eng_cfg = {\n","    \"name\": \"anki_spa_eng_cfg\",\n","    \"src\": {\n","        \"vocab_size\": src_vocab_size,\n","        \"max_len\": max_src_len,\n","    },\n","    \"tar\": {\n","        \"vocab_size\": tar_vocab_size,\n","        \"max_len\": max_tar_len,\n","    },\n","    \"train_val_test_split_ratio\": [0.8, 0.1, 0.1],\n","    \"train_val_shuffle\": True,\n","}\n","\n","# model configuration\n","model_translate_rnn_seq2seq_cfg = {\n","    \"name\": \"RNNSeq2Seq\",\n","    \"enc\": {\n","        \"embed_size\": 256,\n","        \"rnn\": {\n","            \"units\": 1024,\n","        },\n","    },\n","    \"dec\": {\n","        \"embed_size\": 256,\n","        \"rnn\": {\n","            \"units\": 1024,\n","        },\n","    }\n","}\n","\n","model_translate_attention_based_seq2seq_cfg = {\n","    \"name\": \"AttentionBasedSeq2Seq\",\n","    \"enc\": {\n","        \"embed_size\": 256,\n","        \"rnn\": {\n","            \"units\": 1024,\n","        },\n","    },\n","    \"dec\": {\n","        \"embed_size\": 256,\n","        \"rnn\": {\n","            \"units\": 1024,\n","        },\n","    },\n","    \"attention\": {\n","        \"latent_dim\": 1024,\n","    }\n","}\n","\n","model_translate_transformer_based_seq2seq_cfg = {\n","    \"name\": \"TransformerBasedSeq2Seq\",\n","    \"dropout_prob\": 0.5,\n","    \"enc\": {\n","        \"embed_dim\": 256,\n","        \"tr\": {\n","            \"dense_dim\": 2048,\n","            \"num_heads\": 8,\n","            \"supports_masking\": True,\n","        },\n","    },\n","    \"dec\": {\n","        \"embed_dim\": 256,\n","        \"tr\": {\n","            \"latent_dim\": 2048,\n","            \"num_heads\": 8,\n","            \"supports_masking\": True,\n","        },\n","    },\n","}\n","\n","# optimizer_configs\n","adam_warmup_lr_sch_opt_cfg = {\n","    \"optimizer\": {\n","        \"name\": \"Adam\",\n","        \"other_kwargs\": {},\n","    },\n","    \"lr_scheduler\": {\n","        \"name\": \"LinearWarmupLRSchedule\",\n","        \"kwargs\": {\n","            \"lr_peak\": 1e-3,\n","            \"warmup_end_steps\": 1500,\n","        }\n","    }\n","}\n","radam_no_lr_sch_opt_cfg = {\n","    \"optimizer\": {\n","        \"name\": \"RectifiedAdam\",\n","        \"learning_rate\": 1e-3,\n","        \"other_kwargs\": {},\n","    },\n","    \"lr_scheduler\": None\n","}\n","\n","# train_cfg\n","train_cfg: dict = {\n","    \"train_batch_size\": 128,\n","    \"val_batch_size\": 32,\n","    \"test_batch_size\": 32,\n","    \"max_epochs\": 50,\n","    \"distribute_strategy\": \"MirroredStrategy\",\n","    \"teacher_forcing_ratio\": 0.5,\n","}\n","\n","_merged_cfg_presets = {\n","    \"rnn_translate_spa_eng_radam\": {\n","        \"data\": data_anki_spa_eng_cfg,\n","        \"model\": model_translate_rnn_seq2seq_cfg,\n","        \"opt\": radam_no_lr_sch_opt_cfg ,\n","        \"train\": train_cfg\n","    },\n","    \"attention_based_translate_spa_eng_radam\": {\n","        \"data\": data_anki_spa_eng_cfg,\n","        \"model\": model_translate_attention_based_seq2seq_cfg,\n","        \"opt\": radam_no_lr_sch_opt_cfg ,\n","        \"train\": train_cfg\n","    },\n","    \"transformer_based_translate_spa_eng_radam\": {\n","        \"data\": data_anki_spa_eng_cfg,\n","        \"model\": model_translate_transformer_based_seq2seq_cfg,\n","        \"opt\": radam_no_lr_sch_opt_cfg ,\n","        \"train\": train_cfg\n","    },\n","}\n","\n","### hydra composition ###\n","# clear hydra instance \n","hydra.core.global_hydra.GlobalHydra.instance().clear()\n","\n","# register preset configs\n","register_config(_merged_cfg_presets)\n","\n","# initialization\n","hydra.initialize(config_path=None)\n","\n","# using_config_key = \"rnn_translate_spa_eng_radam\"\n","# using_config_key = \"attention_based_translate_spa_eng_radam\"\n","using_config_key = \"transformer_based_translate_spa_eng_radam\"\n","cfg = hydra.compose(using_config_key)\n","\n","# define & override log_cfg\n","model_name = cfg.model.name\n","run_dirname = \"dnn-tutorial-spa-eng-translate-runs-tf\"\n","run_name = f\"{datetime.now().isoformat(timespec='seconds')}-{using_config_key}-{model_name}\"\n","log_dir = os.path.join(drive_project_root, \"runs\", run_dirname, run_name)\n","\n","log_cfg = {\n","    \"run_name\": run_name,\n","    \"checkpoint_filepath\": os.path.join(log_dir, \"model\"),\n","    \"tensorboard_log_dir\": log_dir,\n","    \"callbacks\": {\n","        \"TensorBoard\": {\n","            \"log_dir\": log_dir,\n","            \"update_freq\": 50,\n","        },\n","        \"EarlyStopping\": {\n","            \"patience\": 30,\n","            \"verbose\": True,\n","        }\n","    },\n","    \"wandb\": {\n","        \"project\": \"dnn-tutorial-spa-eng-translate-runs-tf\",\n","        \"name\": run_name,\n","        \"tags\": [\"dnn-tutorial-spa-eng-translate-runs-tf\"],\n","        \"reinit\": True,\n","        \"sync_tensorboard\": True\n","    },\n","}\n","\n","# unlock struct of config & set log config\n","OmegaConf.set_struct(cfg, False)\n","cfg.log = log_cfg\n","\n","# relock config\n","OmegaConf.set_struct(cfg, True)\n","print(OmegaConf.to_yaml(cfg))\n","\n","# save yaml\n","# with open(os.path.join(log_dir, \"config.yaml\")) as f:\n","# with open(\"config.yaml\", \"w\") as f:\n","#     OmegaConf.save(cfg, f)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yARForQbUcbx"},"source":["def get_distribute_strategy(strategy_name: str, **kwargs):\n","    return getattr(tf.distribute, strategy_name)(**kwargs)\n","\n","distribute_strategy = get_distribute_strategy(cfg.train.distribute_strategy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X89D1QCGJXTN"},"source":["# dataset batchify 및 train/val/test splits\n","dataset = tf.data.Dataset.from_tensor_slices((src_tensor, tar_tensor))\n","total_n = len(src_tensor)\n","\n","print(cfg.data.train_val_test_split_ratio)\n","train_size = int(total_n * cfg.data.train_val_test_split_ratio[0])\n","val_size = int(total_n * cfg.data.train_val_test_split_ratio[1])\n","test_size = total_n - (train_size + val_size)\n","\n","# split (train, val) (test) dataset\n","test_dataset = dataset.skip(train_size + val_size)\n","train_val_dataset = dataset.take(train_size + val_size)\n","\n","if cfg.data.train_val_shuffle:\n","    train_val_dataset = train_val_dataset.shuffle(buffer_size=1024)\n","\n","train_dataset = train_val_dataset.take(train_size)\n","val_dataset = train_val_dataset.skip(train_size)\n","\n","train_n, val_n, test_n = len(train_dataset), len(val_dataset), len(test_dataset)\n","print(train_n, val_n, test_n)\n","assert train_n + val_n + test_n == total_n\n","\n","# batchfy (dataloader)\n","train_batch_size = cfg.train.train_batch_size\n","val_batch_size = cfg.train.val_batch_size\n","test_batch_size = cfg.train.test_batch_size\n","\n","train_dataloader = train_dataset.batch(train_batch_size, drop_remainder=True)\n","val_dataloader = val_dataset.batch(val_batch_size, drop_remainder=True)\n","test_dataloader = test_dataset.batch(test_batch_size, drop_remainder=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9KyfbS4RzQ7"},"source":["# 모델 정의 \n","def get_seq2seq_model(cfg: DictConfig):\n","    if cfg.model.name == \"RNNSeq2Seq\":\n","        encoder = GRUEncoder(cfg)\n","        decoder = GRUDecoder(cfg)\n","    elif cfg.model.name == \"AttentionBasedSeq2Seq\":\n","        encoder = GRUEncoder(cfg)\n","        decoder = AttentionalGRUDecoder(cfg)\n","    elif cfg.model.name == \"TransformerBasedSeq2Seq\":\n","        encoder = TransformerEncoder(cfg)\n","        decoder = TransformerDecoder(cfg)\n","    else:\n","        raise NotImplementedError()\n","    return encoder, decoder"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXowW1xyR8yI"},"source":["# loss 정의\n","def loss_function(\n","    real,\n","    pred,\n","    loss_object=tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction=\"none\"\n","    ),\n","    masking_loss=True\n","):\n","    # delete [pad] loss part with masks. \n","    \n","    _loss = loss_object(real, pred)\n","\n","    if masking_loss:\n","        mask = tf.math.logical_not(\n","            tf.math.equal(real, 0)\n","        )\n","        mask = tf.cast(mask, dtype=_loss.dtype)\n","        _loss *= mask\n","\n","    return tf.reduce_mean(_loss)\n","\n","from functools import partial\n","no_masking_loss_function = partial(loss_function, masking_loss=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ijO-VITS80n"},"source":["# get model\n","encoder, decoder = get_seq2seq_model(cfg)\n","encoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","encoder_outputs = encoder(encoder_inputs)\n","\n","decoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","decoder_outputs = decoder(decoder_inputs, encoder_outputs)\n","\n","transformer = tf.keras.Model(\n","    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",")\n","transformer.summary()\n","\n","# get optimizer \n","optimizer, scheduler = get_optimizer_element(\n","    cfg.opt.optimizer, cfg.opt.lr_scheduler\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dYFWi7D35gN8"},"source":["transformer.compile(\n","    optimizer,\n","    # loss=loss_function,\n","    loss=no_masking_loss_function,\n","    metrics=[]   \n",")\n","\n","# get_callbacks\n","callbacks = get_callbacks(cfg.log)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wfI_V53I5tDU"},"source":["def decode_tr_sequence(transformer, sentence: str):\n","    sentence = preprocess_sentence(sentence)\n","\n","    inputs = [src_tokenizer.word_index[i] for i in sentence.split(\" \")]\n","    inputs = pad_sequences([inputs], maxlen=max_src_len, padding=\"post\")\n","\n","    inputs = tf.convert_to_tensor(inputs)\n","    result = \"\"\n","\n","    # autoregressive inference of decoder\n","    dec_inputs = tf.cast(\n","        tf.expand_dims([tar_tokenizer.word_index[\"<start>\"]], 0),\n","        tf.int64\n","    ) # start token\n","\n","    for t in range(max_tar_len):\n","        dec_outputs = transformer([inputs, dec_inputs]) # [B, L, Vocab SZ]\n","\n","        predicted_id = tf.expand_dims(\n","            tf.argmax(\n","                tf.math.softmax(dec_outputs[:, t, :]), # [B, Vocab SZ]\n","                axis=1,\n","            ), # [B]\n","            0,\n","        ) # [1, B]\n","\n","        # prep next steps\n","        dec_inputs = tf.concat([dec_inputs, predicted_id], 1)\n","\n","        sampled_token = tar_tokenizer.index_word[predicted_id.numpy()[0, 0]]\n","\n","        if sampled_token == \"<end>\":\n","            break\n","        result += sampled_token + \" \"\n","    \n","    return result\n","\n","print(decode_tr_sequence(transformer, u\"Esta es mi vida.\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eo3jhwhHVOqu"},"source":["# wandb setup\n","wandb.init(\n","    config=flatten_dict(cfg),\n","    **cfg.log.wandb\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NZ6GD-st5XXO"},"source":["%load_ext tensorboard\n","%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/dnn-tutorial-spa-eng-translate-runs-tf\n","\n","def format_dataset(_src, _tar):\n","    return ({\n","        \"encoder_inputs\": _src,\n","        \"decoder_inputs\": _tar[:, :-1],\n","    }, _tar[:, 1:])\n","\n","transformer.fit(\n","    train_dataloader.map(format_dataset),\n","    validation_data=val_dataloader.map(format_dataset),\n","    epochs=cfg.train.max_epochs,\n","    callbacks=callbacks\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5DO6ohcS9ae7"},"source":["print(decode_tr_sequence(transformer, u\"Esta es mi vida.\")) # this is my life .\n","print(decode_tr_sequence(transformer, u'hace mucho frio aqui.')) # it s very cold ."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jBtJIDQ-TWHP"},"source":["## Define Custom Train/Eval Steps"]},{"cell_type":"code","metadata":{"id":"BsmpRVD2sBW6"},"source":[""],"execution_count":null,"outputs":[]}]}