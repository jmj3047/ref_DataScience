{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Part4_8_Attentional_RNN_Seq2Seq_tensorflow.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPsNvbjU242WmBnN1rcMaio"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Tensorflow\n","- `Tensorflow`가 예전에는 쓰기 어려운 모델이었음 (코딩할 줄 아는 사람들만 사용)\n","- 그래서 `pytorch`가 많이 쓰이다 보니, `Tensorflow`에서도 쉽게 사용할 수 있는 `Keras` 만듦\n","- `Tensorflow 2.0`에서는 `keras`와 합쳐진 `tf.keras.Model`이나 `Sequential` 많이 사용\n","- `Tensorflow`에서 train step, test step을 사용하는 class 구조는 `pytorch lightening`과 비슷\n","  - `pytorch lightening` : `pytorch`를 더 쉽게 사용하기 위한 library\n","- Optimizer : Tensorflow addon\n","  - https://www.tensorflow.org/addons/overview?hl=ko\n","  - https://github.com/tensorflow/addons\n","    - 여러 tensorflow 개발자들이 다양한 optimizer 구현 코드 업로드"],"metadata":{"id":"8gmIaEsDowHC"}},{"cell_type":"markdown","source":["## Hydra\n","- Facebook에서 제공하는 범용적인 configuration management tool\n","- 'hydra config' 검색 : https://hydra.cc/docs/intro/\n","- Omegaconf library를 기반으로 만들어짐\n","  - Documentation : https://omegaconf.readthedocs.io/en/2.1_branch/\n","  - https://github.com/omry/omegaconf : 이 개발자가 facebook에 가서 만든 게 hydra\n","  - MLP 같은 작은 모델은 `__init__(self, input_dim: int, h1_dim: int, h2_dim: int, out_dim: int)` 이런 식으로 써도 되지만, 모델이 커질수록 `init` 안에 들어가야 할 *argument 많아지고 관리가 어려워짐\n","    - 그래서 configuration tool을 이용해서 관리하는 것이 권장\n","    - tensorflow에 hyperparameter도 같은 역할이고 이건 tensorflow와 연동이 되는 장점이 있지만 wandB 등 다른 tool과 연동이 잘 안 되는 단점\n","    - omegaconf가 structure 관리에도 유리\n","\n","## Efficient Network\n","- https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet\n","\n","## Tensorflow Text Generation\n","- https://www.tensorflow.org/text/tutorials/nmt_with_attention"],"metadata":{"id":"Tg5_VZBezJlZ"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"bfadOzkbuIB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","sys.path.append('/content/drive/MyDrive/#fastcampus')\n","drive_project_root = '/content/drive/MyDrive/#fastcampus'\n","!pip install -r '/content/drive/MyDrive/#fastcampus/requirements.txt'"],"metadata":{"id":"4AAPJkUPpFvb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip install tensorflow_addons"],"metadata":{"id":"WNUrJmSfA8Ll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip install wandb"],"metadata":{"id":"wVE8r_8EBA9l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip install omegaconf"],"metadata":{"id":"tp5T9_vf0XfV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Optional, List, Dict, Tuple\n","\n","import io\n","import re\n","import unicodedata\n","import time\n","from datetime import datetime\n","import random\n","\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import matplotlib.pyplot as ticker\n","from omegaconf import OmegaConf, DictConfig    # DictConfig is for time checking\n","\n","import hydra\n","from hydra.core.config_store import ConfigStore\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","import wandb"],"metadata":{"id":"wmIGtqQXpfJr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from config_utils_tf import flatten_dict, register_config, get_optimizer_element, get_callbacks"],"metadata":{"id":"T8mcCpw73M-i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["GPU 확인"],"metadata":{"id":"G8_oGfQKp2cT"}},{"cell_type":"code","source":["tf.config.list_physical_devices()"],"metadata":{"id":"NMr3t8-QpzX0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"L76O6F6_p3Ud"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["https://www.tensorflow.org/</br>\n","- https://www.tensorflow.org/overview/?hl=ko</br>\n","- 튜토리얼 : https://www.tensorflow.org/tutorials?hl=ko\n","- API > Tensorflow : 각 함수에 대한 설명\n","  - 구글에 'Tensorflow API 한글' 검색하면 번역본도 볼 수 있음\n","\n","초보자용 vs 전문가용\n","- 수업에서는 전문가용으로 할 예정\n","- 초보자용에서 사용하는 Sequential 버전(순차적으로 build 하는 방법)에는 한계가 있기 때문\n","- 실제 현업/연구에서는 Sequential 거의 안 씀"],"metadata":{"id":"eV6g35xTqKhF"}},{"cell_type":"markdown","source":["## define gpu\n","- https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy\n","- This strategy is typically used for training on one machine with multiple GPUs.\n","- 아래 코드 결과 보면 GPU 0번 잡아서 가져옴"],"metadata":{"id":"2lfmx_jAp5ac"}},{"cell_type":"code","source":["# mirrored_strategy = tf.distribute.MirroredStrategy()"],"metadata":{"id":"N0sq47Enq1fU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data download\n","\n","- code is from : https://www.tensorflow.org/text/tutorials/nmt_with_attention"],"metadata":{"id":"L7L9eTkdq1qI"}},{"cell_type":"code","source":["data_root = os.path.join(drive_project_root, \"data\", \"anki_spa_eng\")\n","# data_root = os.path.join(\"/drive/MyDrive/#fastcampus\", \"data\", \"anki_spa_eng\")\n","\n","if not os.path.exists(data_root):\n","    # os.mkdir(data_root)\n","    os.makedirs(data_root)\n","    \n","data_path = os.path.join(data_root, \"spa-eng.zip\")"],"metadata":{"id":"18ofA9fMDswE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_to_zip = tf.keras.utils.get_file(\n","    data_path,\n","    # 데이터 다운로드 받아진 거 보면 왼쪽은 영어 오른쪽은 스페인어\n","    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n","    extract=True,\n","    cache_dir = data_root  # Once you download the data, this would block to download the same data again\n",")\n","\n","path_to_file = os.path.join(\n","    os.path.dirname(path_to_zip),\n","    \"datasets\",\n","    \"spa-eng\",\n","    \"spa.txt\",\n",")\n","\n","print(path_to_file)"],"metadata":{"id":"oMYUxMWGnTi_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preprocessing\n","- Optional(int) : input integer or None"],"metadata":{"id":"7KskxT7Doo4z"}},{"cell_type":"code","source":["def unicode_to_ascii(s):\n","    # unicode normalize with NFD mode -> return list -> join : convert list to string\n","    # mn : https://www.compart.com/en/unicode/category/Mn\n","    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")\n","\n","def preprocess_sentence(w):\n","    # convert it to ascii \n","    w = unicode_to_ascii(w.lower().strip())\n","\n","    # make space between words and punctuation\n","    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","    w = re.sub(r'[\" \"]+', \" \", w)\n","    \n","    # replace every thing to space without \"a-z, A-Z, [.?!,¿]\"\n","    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n","    w = w.strip()\n","\n","    # add \"start\" and \"end\" token at the front and back of the model\n","    w = \"<start> \" + w + \" <end>\"  # warning! SPACE!!\n","    return w\n","\n","def create_dataset(path: str, num_examples: Optional[int]=None):\n","    lines = io.open(path, encoding=\"UTF-8\").read().strip().split(\"\\n\")\n","\n","    # 데이터에 tab(\\t)으로 나뉘어 영어-스페인어가 pair식으로 있었음\n","    word_pairs = [[preprocess_sentence(w) for w in l.split(\"\\t\")] for l in lines[:num_examples]]\n","\n","    return zip(*word_pairs)\n","\n","en, sp = create_dataset(path_to_file)\n","print(en[-1])\n","print(sp[-1])"],"metadata":{"id":"9SdXQsAror63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define Tokenizer & Final use data\n","\n","def tokenize(lang):\n","    lang_tokenizer = Tokenizer(filters=\"\")\n","    lang_tokenizer.fit_on_texts(lang)\n","\n","    # we cannot put string into model (neither pytorch nor tensorflow)\n","    # we should convert it to int or float type\n","    tensor = lang_tokenizer.texts_to_sequences(lang)\n","    tensor = pad_sequences(tensor, padding=\"post\")\n","\n","    return tensor, lang_tokenizer\n","\n","def load_dataset(path, num_examples=None):\n","    tar_lang, src_lang = create_dataset(path, num_examples)  # en, sp\n","\n","    src_tensor, src_tokenizer = tokenize(src_lang)\n","    tar_tensor, tar_tokenizer = tokenize(tar_lang)\n","\n","    return src_tensor, tar_tensor, src_tokenizer, tar_tokenizer\n","\n","# call language dataset\n","num_examples = 30000\n","src_tensor, tar_tensor, src_tokenizer, tar_tokenizer = load_dataset(\n","    path_to_file, num_examples\n",")\n","\n","max_tar_len, max_src_len = tar_tensor.shape[1], src_tensor.shape[1]\n","\n","src_vocab_size = len(src_tokenizer.word_index) + 1\n","tar_vocab_size = len(tar_tokenizer.word_index) + 1\n","\n","print(src_vocab_size, tar_vocab_size)"],"metadata":{"id":"mLMPEBAH5bK0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["check\n","- 1 : start\n","- 2 : end\n","- 0 : padding"],"metadata":{"id":"0cYKkYt6_AHn"}},{"cell_type":"code","source":["print(tar_tensor[-1])\n","print(tar_tokenizer.word_index)"],"metadata":{"id":"ayJCT8gi-vQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in tar_tensor[-1]:\n","    if i == 0:\n","        break\n","    print(tar_tokenizer.index_word[i])"],"metadata":{"id":"o9XxfFUp_FuJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Model"],"metadata":{"id":"b7K30vaZ_zRY"}},{"cell_type":"code","source":["class GRUEncoder(tf.keras.Model):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.enc_emb = tf.keras.layers.Embedding(\n","            cfg.data.src.vocab_size,\n","            cfg.model.enc.embed_size\n","        )\n","        self.enc_gru = tf.keras.layers.GRU(\n","            cfg.model.enc.rnn.units,\n","            return_state=True,\n","            return_sequences=True,\n","            recurrent_initializer=\"glorot_uniform\"\n","        )\n","    \n","    # state : RNN's state\n","    def call(self, src_tokens, state=None, training=False):\n","        embed_enc = self.enc_emb(src_tokens)\n","        enc_outputs, enc_states = self.enc_gru(\n","            embed_enc, initial_state=state\n","        )\n","        return enc_outputs, enc_states\n","\n","class GRUDecoder(tf.keras.Model):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.dec_emb = tf.keras.layers.Embedding(\n","            cfg.data.tar.vocab_size,\n","            cfg.model.dec.embed_size\n","        )\n","        self.dec_gru = tf.keras.layers.GRU(\n","            cfg.model.dec.rnn.units,\n","            return_state=True,\n","            return_sequences=True,\n","            recurrent_initializer=\"glorot_uniform\"\n","        )\n","        self.fc = tf.keras.layers.Dense(cfg.data.tar.vocab_size)\n","    \n","    # state : RNN's state\n","    def call(self, tar_tokens, state=None, training=False):\n","        embed_dec = self.dec_emb(tar_tokens)\n","        dec_outputs, dec_states = self.dec_gru(\n","            embed_dec, initial_state=state\n","        )\n","        final_outputs = self.fc(dec_outputs)\n","        return final_outputs, dec_states, None   # None은 추후 attention 등 추가 시 interface 통일 위함"],"metadata":{"id":"iwqYLh1s_2Eg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Attention 모델 정의"],"metadata":{"id":"YXqMlasHb208"}},{"cell_type":"code","source":["# attention은 decoder에 붙이는 것이기 때문에 layer로 정의\n","class BahdanauAttention(tf.keras.layers.Layer):\n","    def __init__(self, cfg:DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        # needs 3 different fully connected layers\n","        self.fc1 = tf.keras.layers.Dense(cfg.model.attention.latent_dim)   # fully connected for key\n","        self.fc2 = tf.keras.layers.Dense(cfg.model.attention.latent_dim)   # fully connected for query\n","        self.fc_score = tf.keras.layers.Dense(1)      # fully connected for weighted score\n","\n","    def call(self, query, value):\n","\n","        # querry = decoder hidden, value = encoder output\n","        # querry : hidden이기 때문에 차원을 맞춰주기 위해 expand dims 사용\n","        query_with_time_axis = tf.expand_dims(query, 1)   # [batch, 1(length), hidden_dim] -> 보통 decoder에서 length는 1\n","\n","        score = self.fc_score(\n","            tf.nn.tanh(\n","                self.fc1(query_with_time_axis) + self.fc2(value)  # score\n","            )\n","        )  # [batch, length, hidden_dim] -> [batch, length, 1]\n","\n","        attention_weights = tf.nn.softmax(score, axis=1)  # [batch_size, length, 1]\n","\n","        context_vector = attention_weights * value  # [batch_size, hidden]\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","        return context_vector, attention_weights\n","\n","class AttentionalGRUDecoder(tf.keras.Model):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.dec_emb = tf.keras.layers.Embedding(\n","            cfg.data.tar.vocab_size,\n","            cfg.model.dec.embed_size\n","        )\n","        self.dec_gru = tf.keras.layers.GRU(\n","            cfg.model.dec.rnn.units,\n","            return_state=True,\n","            return_sequences=True,\n","            recurrent_initializer=\"glorot_uniform\"\n","        )\n","        self.attention = BahdanauAttention(cfg)\n","        self.fc = tf.keras.layers.Dense(cfg.data.tar.vocab_size)\n","\n","    def call(self, tar_tokens, hidden, enc_output):\n","        # enc_output: [batch, length, hidden_dim]\n","        context_vector, attention_weights = self.attention(hidden, enc_output)\n","        \n","        x = self.dec_emb(tar_tokens)\n","\n","        # embedding된 target token과 context vecotr를 concat으로 합치기\n","        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","        # 이 때는 이미 결합이 되었었기 때문에 attention에서 반영되었다고 보고 굳이 state 넣지 않음\n","        dec_outputs, dec_states = self.dec_gru(x)\n","\n","        # [batch_size * 1, embedding_dim + hidden_dim]\n","        dec_outputs = tf.reshape(dec_outputs, (-1, dec_outputs.shape[2]))\n","\n","        # [batch_size, vocab_size]\n","        final_outputs = self.fc(dec_outputs)\n","\n","        return final_outputs, dec_states, attention_weights"],"metadata":{"id":"Ez1VW9R_cBVD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Configuration 정의"],"metadata":{"id":"uDuzP0sY4b0_"}},{"cell_type":"markdown","source":["### data configuration"],"metadata":{"id":"8r1ww_KV6p-r"}},{"cell_type":"code","source":["data_anki_spa_eng_cfg ={\n","    \"name\": \"anki_spa_eng_cfg\",\n","    \"src\":{\n","        \"vocab_size\": src_vocab_size,\n","        \"max_len\": max_src_len,\n","    },\n","    \"tar\":{\n","        \"vocab_size\": tar_vocab_size,\n","        \"max_len\": max_tar_len,\n","    },\n","    \"train_val_test_split_ratio\": [0.8, 0.1, 0.1],\n","    \"train_val_shuffle\": True,\n","}"],"metadata":{"id":"NGVZjvXZ6qAO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### model configuration"],"metadata":{"id":"LId0Hw-W6qJr"}},{"cell_type":"code","source":["model_translate_rnn_seq2seq_cfg = {\n","    \"name\": \"RNNSeq2Seq\",\n","    \"enc\": {\n","        \"embed_size\": 256,\n","        \"rnn\": {\n","            \"units\": 1024,\n","        }\n","    },\n","    \"dec\": {\n","        \"embed_size\": 256,\n","        \"rnn\": {\n","            \"units\": 1024,\n","        }\n","    }\n","}\n","\n","model_translate_attention_based_seq2seq_cfg = {\n","    \"name\": \"AttentionBasedSeq2Seq\",\n","    \"enc\": {\n","        \"embed_size\": 256,\n","        \"rnn\": {\n","            \"units\": 1024,\n","        }\n","    },\n","    \"dec\": {\n","        \"embed_size\": 256,\n","        \"rnn\": {\n","            \"units\": 1024,\n","        }\n","    },\n","    \"attention\": {\n","        \"latent_dim\" : 1024,\n","    }\n","}"],"metadata":{"id":"nALBOsFe3voa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### optimizer configuration"],"metadata":{"id":"DW0a1cVelHKl"}},{"cell_type":"code","source":["adam_warmup_lr_sch_opt_cfg = {\n","    \"optimizer\": {\n","        \"name\": \"Adam\",\n","        \"other_kwargs\": {},\n","    },\n","    \"lr_scheduler\": {\n","        \"name\": \"LinearWarmupLRSchedule\",\n","        \"kwargs\": {\n","            \"lr_peak\": 1e-3,\n","            \"warmup_end_steps\": 1500,\n","        }\n","    }\n","}\n","\n","# RAdam은 scheduler 필요 없었음\n","radam_no_lr_sch_opt_cfg = {\n","    \"optimizer\": {\n","        \"name\": \"RectifiedAdam\",\n","        \"learning_rate\": 1e-3,\n","        \"other_kwargs\": {},\n","    },\n","    \"lr_scheduler\": None\n","}\n","\n","# train_cfg\n","train_cfg: dict = {\n","    \"train_batch_size\": 128,\n","    \"val_batch_size\": 32,\n","    \"test_batch_size\": 32,\n","    \"max_epochs\": 50,\n","    \"distribute_strategy\": \"MirroredStrategy\",   # colab(notebook)이 아니고 다른 server에서 하면 다른 strategy 필요\n","    # teacher_forcing : 처음에 적용했다가 없애주는 게 가장 좋은 방법이라고 알려져 있음\n","    \"teacher_forcing_ratio\": 0.5,\n","}\n","\n","_merged_cfg_presets = {\n","    \"rnn_translate_spa_eng_radam\": {\n","        \"data\": data_anki_spa_eng_cfg,\n","        \"model\": model_translate_rnn_seq2seq_cfg,\n","        \"opt\": radam_no_lr_sch_opt_cfg,\n","        \"train\": train_cfg,\n","    },\n","    \"attention_based_translate_spa_eng_radam\": {\n","        \"data\": data_anki_spa_eng_cfg,\n","        \"model\": model_translate_attention_based_seq2seq_cfg,\n","        \"opt\": radam_no_lr_sch_opt_cfg,\n","        \"train\": train_cfg,      \n","    }\n","}\n","\n","### hydra composition ###\n","# clear hydra instance -> Jupyter 환경에서 할 때는 일단 instance clear 하기\n","hydra.core.global_hydra.GlobalHydra.instance().clear()\n","\n","# register preset configs\n","register_config(_merged_cfg_presets)\n","\n","# initialization\n","hydra.initialize(config_path=None)    # yaml을 쓰고 있고 외부에서 하면 config_path 지정해야 함\n","\n","# using_config_key = \"cnn_fashion_mnist_radam\"\n","using_config_key = \"attention_based_translate_spa_eng_radam\"\n","cfg = hydra.compose(using_config_key)\n","\n","# define & override log _cfg\n","model_name = cfg.model.name\n","run_dirname = \"dnn-tutorial-spa_eng-translate-runs-tf\"\n","run_name = f\"{datetime.now().isoformat(timespec='seconds')}-{using_config_key}-{model_name}\"\n","log_dir = os.path.join(drive_project_root, \"runs\", run_dirname, run_name)\n","\n","log_cfg = {\n","    \"run_name\": run_name,\n","    # callback을 못 쓰니 filepath 등 지정 필요\n","    \"checkpoint_filepath\": os.path.join(log_dir, \"model\"),\n","    \"tensorboard_log_dir\": log_dir,\n","    \"callbacks\": {\n","        \"TensorBoard\": {\n","            \"log_dir\": log_dir,\n","            \"update_freq\": 50,\n","        },\n","        \"EarlyStopping\": {\n","            \"patience\": 30,\n","            \"verbose\": True,\n","        }\n","    },\n","    \"wandb\": {\n","        \"project\": \"dnn-tutorial-spa_eng-translate-runs-tf\",\n","        \"name\": run_name,\n","        \"tags\": [\"dnn-tutorial-spa_eng-translate-runs-tf\"],\n","        \"reinit\": True,\n","        \"sync_tensorboard\": True,\n","    },\n","}\n","\n","# unlock struct of config & set log config\n","OmegaConf.set_struct(cfg, False)\n","cfg.log = log_cfg\n","\n","# relock config\n","OmegaConf.set_struct(cfg, True)\n","print(OmegaConf.to_yaml(cfg))\n","\n","# save yaml\n","# with open(os.path.join(log_dir, \"config.yaml\")) as f:\n","# with open(\"config.yaml\", \"w\") as f:\n","#     OmegaConf.save(cfg, f)\n","\n","# This would open the file we saved above\n","# and tell you the result of the model and its configs (weights, ...)\n","# You can check it whenever you want\n","# OmegaConf.load()"],"metadata":{"id":"StvxdanulHNa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_distribute_strategy(strategy_name: str, **kwargs):\n","    return getattr(tf.distribute, strategy_name)(**kwargs)\n","\n","distribute_strategy = get_distribute_strategy(cfg.train.distribute_strategy)"],"metadata":{"id":"hlbgAzj0lHQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dataset batchfy 및 train/val/test splits\n","# from_tensor_slices : numpy array 형태와 비슷\n","dataset = tf.data.Dataset.from_tensor_slices((src_tensor, tar_tensor))\n","total_n = len(src_tensor)\n","\n","print(cfg.data.train_val_test_split_ratio)\n","train_size = int(total_n * cfg.data.train_val_test_split_ratio[0])\n","val_size = int(total_n * cfg.data.train_val_test_split_ratio[1])\n","test_size = total_n - (train_size + val_size)\n","\n","# split (train, val), (test) dataset\n","test_dataset = dataset.skip(train_size + val_size)\n","train_val_dataset = dataset.take(train_size + val_size)\n","\n","if cfg.data.train_val_shuffle:  # True\n","    train_val_dataset = train_val_dataset.shuffle(buffer_size=1024)\n","\n","train_dataset = train_val_dataset.take(train_size)\n","val_dataset = train_val_dataset.skip(train_size)\n","\n","train_n, val_n, test_n = len(train_dataset), len(val_dataset), len(test_dataset)\n","print(train_n, val_n, test_n)\n","assert train_n + val_n + test_n == total_n   # 문제가 없는지 확인\n","\n","# batchfy (dataloader)\n","train_batch_size = cfg.train.train_batch_size\n","val_batch_size = cfg.train.val_batch_size \n","test_batch_size = cfg.train.test_batch_size\n","\n","train_dataloader = train_dataset.batch(train_batch_size, drop_remainder=True)\n","val_dataloader = val_dataset.batch(val_batch_size, drop_remainder=True)\n","test_dataloader = test_dataset.batch(test_batch_size, drop_remainder=True)"],"metadata":{"id":"dzDsYhtQ3vrS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## define model\n","\n","LinearWarmupLRScheduler 하는 이유\n","- SGD는 다른 optimizer 대비 learning rate 값에 매우 민감\n","  - learning rate를 잘 setting 해야 성능이 좋게 나옴 (Adam보다 더 좋게 나오기도 함)\n","- 따라서 optimizer와 함께 learning rate도 tuning 하는 게 원래는 좋음\n","- 그러나 학습 속도가 너무 느려지는 단점\n","\n","warmup을 하기 어려운 상황이면?\n","- Rectified Adam으로 먼저 테스트 해 보고, optimizer는 조절해도 거의 결과 비슷하게 나오니, 모델링 부분을 업데이트 해 보기\n","- Rectified Adam에도 tuning 할 수 있는 요소 많음\n","  - https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/RectifiedAdam"],"metadata":{"id":"04O0P4wLPmC2"}},{"cell_type":"code","source":["# 모델 정의\n","def get_seq2seq_model(cfg: DictConfig):\n","    if cfg.model.name == \"RNNSeq2Seq\":\n","        encoder = GRUEncoder(cfg)\n","        decoder = GRUDecoder(cfg)\n","        return encoder, decoder\n","    elif cfg.model.name == \"AttentionBasedSeq2Seq\":\n","        encoder = GRUEncoder(cfg)\n","        decoder = AttentionalGRUDecoder(cfg)\n","        return encoder, decoder\n","    else:\n","        raise NotImplementedError()"],"metadata":{"id":"P1kMS7uKq1wU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss 정의\n","def loss_function(\n","    real,\n","    pred,\n","    loss_object=tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction=\"none\"\n","    )\n","):\n","    # delete [pad] loss part with masks. \n","    mask = tf.math.logical_not(\n","        tf.math.equal(real, 0)\n","    )\n","    _loss = loss_object(real, pred)\n","\n","    mask = tf.cast(mask, dtype=_loss.dtype)\n","    _loss *= mask\n","\n","    return tf.reduce_mean(_loss)\n"],"metadata":{"id":"jMhwWH_rgyR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get model\n","encoder, decoder = get_seq2seq_model(cfg)\n","\n","# get optimizer\n","optimizer, scheduler = get_optimizer_element(\n","    cfg.opt.optimizer, cfg.opt.lr_scheduler\n",")\n","\n","# checkpoints\n","checkpoint_prefix = cfg.log.checkpoint_filepath\n","checkpoint = tf.train.Checkpoint(\n","    optimizer=optimizer,\n","    encoder=encoder,\n","    decoder=decoder,\n",")"],"metadata":{"id":"D116PxC6h9XS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# callbacks = get_callbacks(cfg.log)"],"metadata":{"id":"lSbWZOHRSsGW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Custom Train/Eval Steps"],"metadata":{"id":"Mp2knX5ltEqq"}},{"cell_type":"code","source":["@tf.function\n","def _step(src, tar, enc_hidden, teacher_forcing_ratio=0.5):\n","\n","    if cfg.model.name == \"RNNSeq2Seq\":\n","        return _rnn_step(src, tar, enc_hidden, teacher_forcing_ratio)\n","    elif cfg.model.name == \"AttentionBasedSeq2Seq\":\n","        return _attentional_rnn_step(src, tar, enc_hidden, teacher_forcing_ratio)\n","    else:\n","        raise NotImplementedError()\n","\n","@tf.function\n","def _attentional_rnn_step(src, tar, enc_hidden, teacher_forcing_ratio=0.5):\n","    enc_output, enc_hidden = encoder(src, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    # add start token\n","    dec_input = tf.expand_dims(\n","        [tar_tokenizer.word_index[\"<start>\"]] * src.shape[0],   # multiply with batch_size\n","        1\n","    )  # [Batch, 1]\n","\n","    outputs = []\n","    loss = 0\n","\n","    # sequence 길이만큼 루프! (autoregressive or teacher-forcing)\n","    for t in range(1, tar.shape[1]):\n","        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","        \n","        outputs.append(predictions)            # [batch_size, vocab_size]\n","        final_outs = tf.argmax(predictions, 1) # [batch_size]\n","        ground_truth = tar[:, t]               # [batch_size]\n","\n","        loss += loss_function(ground_truth, predictions)\n","\n","        # random.random() : pick random number between 0~1\n","        if random.random() < teacher_forcing_ratio:  # teacher forcing case\n","            dec_input = tf.expand_dims(ground_truth, 1)\n","        else:                                        # no teacher forcing case\n","            dec_input = tf.expand_dims(final_outs, 1)\n","    \n","    return loss, outputs\n","\n","# 최적화 이슈가 있는 경우 tensorflow에서는 @ decorator 사용\n","@tf.function\n","def _rnn_step(src, tar, enc_hidden, teacher_forcing_ratio=0.5):\n","\n","    enc_output, enc_hidden = encoder(src, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    # add start token\n","    dec_input = tf.expand_dims(\n","        [tar_tokenizer.word_index[\"<start>\"]] * src.shape[0], # multiply with batch_size\n","        1\n","    )  # [Batch, 1]\n","\n","    outputs = []\n","    loss = 0\n","\n","    # sequence 길이만큼 루프! (autoregressive or teacher-forcing)\n","    for t in range(1, tar.shape[1]):\n","        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden) # prediction : [Batch, 1, target voca size]\n","\n","        outputs.append(predictions[:, 0])   # [Batch, voca size]\n","        final_outs = tf.argmax(predictions, 2) # [Batch, 1]\n","\n","        ground_truth = tf.expand_dims(tar[:, t], 1)  # for teacher-forcing : [B] -> [B, 1]\n","\n","        loss += loss_function(ground_truth, predictions)\n","\n","        # random.random() : pick random number between 0~1\n","        if random.random() < teacher_forcing_ratio: # teacher forcing case\n","            dec_input = ground_truth\n","        else:                                        # no teacher forcing case\n","            dec_input = final_outs \n","    \n","    return loss, outputs\n","\n","@tf.function\n","def train_step(src, tar, enc_hidden, teacher_forcing_ratio=0.5):\n","    with tf.GradientTape() as tape:\n","        loss, outputs = _step(src, tar, enc_hidden, teacher_forcing_ratio)\n","    \n","    batch_loss = (loss / int(tar.shape[1])) # divide with seq_len\n","\n","    variables = encoder.trainable_variables + decoder.trainable_variables\n","    gradients = tape.gradient(loss, variables)\n","    optimizer.apply_gradients(zip(gradients, variables))\n","\n","    return batch_loss, outputs\n","\n","\n","# test에서는 teacher forcing이 있을 수 없음 - 순차적으로 적용해서 맞아야 하기 때문에 (test set은 순서 중요)\n","@tf.function\n","def eval_step(src, tar, enc_hidden):\n","    loss, outputs = _step(src, tar, enc_hidden, 0.0)\n","    batch_loss = (loss / int(tar.shape[1])) # divide with seq_len\n","    return batch_loss, outputs"],"metadata":{"id":"5RgOKjuJtLmn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## wandb setup\n","\n","- https://docs.wandb.ai/guides/integrations/tensorflow\n","- sync_tensorboard=True : tensorflow에 적혀있는 걸 wandb에 업로드"],"metadata":{"id":"W3kBknhvHV3r"}},{"cell_type":"code","source":["# flatten_dict(cfg)   # 전부 flatten 하게 바꿔주는 함수 -> nested 구조를 모두 under bar 형태로 바꿈"],"metadata":{"id":"SpD4-l8og5RW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wandb.init(\n","    config= flatten_dict(cfg),\n","    **cfg.log.wandb\n",")"],"metadata":{"id":"WxPeYZkVHWBV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["경로 잘 찾고 있는지 확인"],"metadata":{"id":"YGTecT2yVqp8"}},{"cell_type":"code","source":["! ls /content/drive/MyDrive/\\#fastcampus/runs/"],"metadata":{"id":"1u3ORwmUVijX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training/Eval Loop"],"metadata":{"id":"7DqEf8nV55P9"}},{"cell_type":"code","source":["# tensorboard load하기 : load extension\n","%load_ext tensorboard\n","\n","# 경로 지정 : terminal 문법이기 때문에 #을 # 그대로 인지하려면 앞에 '\\' 써줘야 함\n","%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/\n","\n","val_dataloader = iter(val_dataloader)\n","steps_per_epoch = train_n // cfg.train.train_batch_size   # epoch 별로 얼마나 갈 것인가\n","\n","# tensorboard summary writer\n","tb_writer = tf.summary.create_file_writer(\n","    cfg.log.tensorboard_log_dir\n",")\n","\n","# custom loop\n","# callback을 못 쓰니 최소한의 것 수동으로 지정\n","step = 0\n","for epoch in range(cfg.train.max_epochs):\n","    start = time.time()\n","\n","    total_epoch_loss = 0\n","\n","    # batch iteration\n","    for (batch, (cur_src, cur_tar)) in enumerate(train_dataloader.take(steps_per_epoch)):\n","\n","        enc_hidden = tf.zeros((\n","            cfg.train.train_batch_size,\n","            cfg.model.enc.rnn.units   # unit = hidden\n","        ))\n","        batch_loss, outputs = train_step(cur_src, cur_tar, enc_hidden)\n","        total_epoch_loss += batch_loss\n","\n","        if batch % 100 == 0 or steps_per_epoch == batch:\n","            print(\"Epoch {} Batch {} Train Loss {:.4f}\".format(\n","                epoch+1,\n","                batch,\n","                batch_loss.numpy()\n","            ))\n","        \n","        step += 1\n","\n","    # save model per 2 epoch\n","    if (epoch + 1) % 2 == 0:\n","        checkpoint.save(file_prefix=checkpoint_prefix)\n","\n","    train_loss = total_epoch_loss / steps_per_epoch\n","    print(\"Epoch {} Train Loss {:.4f}\".format(epoch+1, train_loss))\n","\n","    with tb_writer.as_default():\n","        tf.summary.scalar(\"train_loss\", train_loss, step=step)\n","\n","    # validation step\n","    enc_hidden = tf.zeros((\n","        cfg.train.val_batch_size,\n","        cfg.model.enc.rnn.units   # unit = hidden\n","        ))\n","    cur_src, cur_tar = next(val_dataloader)\n","    val_loss, outputs = eval_step(cur_src, cur_tar, enc_hidden)\n","    print(\"Epoch {} Val Loss {:.4f}\".format(epoch+1, val_loss))\n","\n","    # token -> text & logging\n","    preds = tf.stack(outputs, axis=1)\n","    preds = tf.argmax(preds, axis=2)   \n","    preds = [p.numpy() for p in preds]\n","\n","    src_texts = src_tokenizer.sequences_to_texts(cur_src.numpy())\n","    tar_texts = tar_tokenizer.sequences_to_texts(cur_tar.numpy())\n","    pred_texts = tar_tokenizer.sequences_to_texts(preds)\n","\n","    with tb_writer.as_default():\n","        tf.summary.scalar(\"val_loss\", val_loss, step=step)\n","        tf.summary.text(\"val_src_text\", src_texts[0], step=step)\n","        tf.summary.text(\"val_tar_text\", tar_texts[0], step=step)\n","        tf.summary.text(\"val_pred_text\", pred_texts[0], step=step)\n","\n","    print(f\"Time taken for 1 epoch {time.time() - start} sec\\n\")"],"metadata":{"id":"HubFa3A2Szm9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation Code Examples (Attentional RNN)"],"metadata":{"id":"F9Tx9Zu5Tg5Y"}},{"cell_type":"code","source":["def evaluate(\n","    sentence,  # input\n","    encoder,\n","    decoder,\n","    src_tokenizer,\n","    tar_tokenizer,\n","    max_src_len,\n","    max_tar_len,\n","):\n","    # preprocessing sentence\n","    sentence = preprocess_sentence(sentence)\n","\n","    inputs = [src_tokenizer.word_index[i] for i in sentence.split(\" \")]\n","    inputs = pad_sequences([inputs], maxlen=max_src_len, padding=\"post\")\n","\n","    inputs = tf.convert_to_tensor(inputs)\n","\n","    result = \"\"\n","\n","    # encoder forward\n","    hidden = [tf.zeros((1, encoder.cfg.model.enc.rnn.units))]  # 1 : batch size\n","    enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","    # autoregressive inference of decoder\n","    dec_hidden = enc_hidden\n","    dec_input = tf.expand_dims([tar_tokenizer.word_index[\"<start>\"]], 0)   # start token\n","\n","    # source와 target 간 상관관계 볼 plot\n","    attention_plot = np.zeros((max_tar_len, max_src_len))\n","\n","    for t in range(max_tar_len):\n","        predictions, dec_hidden, attention_weights = decoder(\n","            dec_input, dec_hidden, enc_out\n","        )\n","\n","        # for plotting of attention weights\n","        attention_weights = tf.reshape(attention_weights, (-1, ))\n","        attention_plot[t] = attention_weights.numpy()\n","\n","        predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","        result += tar_tokenizer.index_word[predicted_id] + \" \"\n","\n","        if tar_tokenizer.index_word[predicted_id] == \"<end>\":\n","            break\n","\n","        # predicted 된 id를 모델에 다시 넣기 위해 (autoregressive)\n","        dec_input = tf.expand_dims([predicted_id], 0)\n","\n","    return result, sentence, attention_plot"],"metadata":{"id":"2pWod1MIZILf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_attention(attention, sentence: List, predicted_sentence: List):\n","    fig = plt.figure(figsize=(15, 15))\n","    ax = fig.add_subplot(1, 1, 1)\n","\n","    ax.matshow(attention, cmap=\"viridis\")\n","\n","    fontdict = {\"fontsize\": 16}\n","\n","    # 부가적으로 보여줄 것 setting\n","    ax.set_xticklabels([\"\"] + sentence, fontdict=fontdict, rotation=90)\n","    ax.set_yticklabels([\"\"] + predicted_sentence, fontdict=fontdict)\n","\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()"],"metadata":{"id":"cppkvAERszyr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## checkpoint restore"],"metadata":{"id":"bh3WxpoFtQlR"}},{"cell_type":"code","source":["# best인 걸 불러올 수도 있는데 일단 가장 최신 거 불러옴 : latest_checkpoint\n","\n","checkpoint.restore(tf.train.latest_checkpoint(cfg.log.checkpoint_filepath))"],"metadata":{"id":"slHj7AOItQoD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result, sentence, attention_plot = evaluate(\n","    u\"Esta es mi vida.\", encoder, decoder, src_tokenizer, tar_tokenizer, max_src_len, max_tar_len\n",")\n","\n","attention_plot = attention_plot[:len(result.split(\" \")), :len(sentence.split(\" \"))]  # 일부만 가져오게 함\n","plot_attention(attention_plot, sentence.split(\" \"), result.split(\" \"))"],"metadata":{"id":"1JRX5yE9tlmQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Hn49-MrBtmpI"},"execution_count":null,"outputs":[]}]}